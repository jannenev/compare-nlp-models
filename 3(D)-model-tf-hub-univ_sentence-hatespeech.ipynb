{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0a4mTk9o1Qg"
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 Google Inc.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel classification with TF-HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "\n",
    "# predicted logits to distribution\n",
    "import numpy as np\n",
    "\n",
    "# confusion matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "\n",
    "# avoid printing e-notation, such as 9.9687493e-01 instead of 0.9968\n",
    "np.set_printoptions(suppress=True,\n",
    "   formatter={'float_kind':'{:0.4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to multilabel classification from binary example:\n",
    "# https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
    "\n",
    "# original way in example for metrics, F1, False Negatives etc does not work for multi lable. \n",
    "# They use tf.metric.recall etc. which cast labels to boolean, returning incorrect values for multi label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional, load local environment: source activate tf-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/max/git/newcombined/dataset_hatespeech/\n"
     ]
    }
   ],
   "source": [
    "dataset = 'hatespeech'\n",
    "\n",
    "current = os.getcwd()\n",
    "basefolder = current + '/dataset_'+ dataset+'/'\n",
    "datafolder = basefolder + 'data/'  # for example /dataset_businessnews/data/\n",
    "print(basefolder)\n",
    "\n",
    "infolder =  basefolder + 'input/'\n",
    "outfolder = basefolder + 'output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cp5wfXDx5SPH"
   },
   "source": [
    "In addition to the standard libraries we imported above, we'll need to install BERT's python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "jviywGyWyKsA",
    "outputId": "166f3005-d219-404f-b201-2a0b75480360"
   },
   "outputs": [],
   "source": [
    "#!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhbGEfwgdEtw"
   },
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVB3eOcjxxm1"
   },
   "source": [
    "Below, we'll set an output directory location to store our model output and checkpoints. This can be a local directory, in which case you'd set OUTPUT_DIR to the name of the directory you'd like to create. If you're running this code in Google's hosted Colab, the directory won't persist after the Colab session ends.\n",
    "\n",
    "Alternatively, if you're a GCP user, you can store output in a GCP bucket. To do that, set a directory name in OUTPUT_DIR and the name of the GCP bucket in the BUCKET field.\n",
    "\n",
    "Set DO_DELETE to rewrite the OUTPUT_DIR if it exists. Otherwise, Tensorflow will load existing model checkpoints from that directory (if they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory if need\n",
    "OUTPUT_DIR = 'tf-hub-output'#@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmFYvkylMwXn"
   },
   "source": [
    "#Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MC_w8SRqN0fr"
   },
   "source": [
    "First, let's download the dataset, hosted by Stanford. The code below, which downloads, extracts, and imports the IMDB Large Movie Review Dataset, is borrowed from [this Tensorflow tutorial](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(basefolder+'input/train.csv',sep='\\t', header = None)\n",
    "test = pd.read_csv(basefolder+'input/dev.csv'  ,sep='\\t', header = None)\n",
    "#test.to_csv('input/test.csv',sep='\\t', index = False, header = False)\n",
    "\n",
    "train.columns = ['id','label','text']\n",
    "test.columns  = ['id','label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test smaller\n",
    "train = train[0:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train.label = train.label.astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test.label = test.label.astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DAN\n",
    "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "\n",
    "# own\n",
    "embeddings = embed(train_df['text'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Input functions\n",
    "\n",
    "[Estimator framework](https://www.tensorflow.org/get_started/premade_estimators#overview_of_programming_with_estimators) provides [input functions](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn) that wrap Pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train\n",
    "test_df = test\n",
    "\n",
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_df, train_df[\"label\"], num_epochs=None, shuffle=True,  batch_size=32)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_df, train_df[\"label\"], shuffle=False, batch_size=32)\n",
    "\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    test_df, test_df[\"label\"], shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature columns\n",
    "\n",
    "TF-Hub provides a feature column that applies a module on the given text feature and passes further the outputs of the module. We will be using the nnlm-en-dim128 module. \n",
    "\n",
    "    The module takes a batch of sentences in a 1-D tensor of strings as input.\n",
    "    The module is responsible for preprocessing of sentences (e.g. removal of punctuation and splitting on spaces).\n",
    "    The module works with any input (e.g. nnlm-en-dim128 hashes words not present in vocabulary into  ~20.000 buckets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "    key=\"text\", \n",
    "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\",\n",
    "    trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column2 = hub.text_embedding_column(\n",
    "    key=\"text\", \n",
    "    module_spec=\"https://tfhub.dev/google/universal-sentence-encoder/2\", # DAN\n",
    "    trainable=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column3 = hub.text_embedding_column(\n",
    "    key=\"text\", \n",
    "    module_spec=\"https://tfhub.dev/google/universal-sentence-encoder-large/3\", # univ-3 is Transformer\n",
    "    trainable=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column_elmo = hub.text_embedding_column(\n",
    "    key=\"text\", \n",
    "    module_spec=\"https://tfhub.dev/google/elmo/2\", \n",
    "    trainable=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# not working as embedding\n",
    "embedded_text_feature_column4 = hub.text_embedding_column(\n",
    "    key=\"text\", \n",
    "    module_spec=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "    trainable=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setEmbedding(module = \"https://tfhub.dev/google/universal-sentence-encoder/2\"):\n",
    "    \n",
    "    return hub.text_embedding_column(\n",
    "    key=\"text\", \n",
    "    module_spec=module,\n",
    "    trainable=True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column = setEmbedding(\"https://tfhub.dev/google/universal-sentence-encoder/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedded_text_feature_column."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bert_module = hub.Module(\"https://tfhub.dev/google/bert.../1\", trainable=True)\n",
    "bert_inputs = dict(\n",
    "input_ids=input_ids,\n",
    "input_mask=input_mask,\n",
    "segment_ids=segment_ids)\n",
    "bert_outputs = bert_module(bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "pooled_output = bert_outputs[\"pooled_output\"]\n",
    "sequence_output = bert_outputs[\"sequence_output\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "\n",
    "For classification we can use a [DNN Classifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) (note further remarks about different modelling of the label function at the end of the tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpc48bqaz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpc48bqaz2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpc48bqaz2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd0b26ea668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpc48bqaz2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd0b26ea668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[500, 100],\n",
    "    #hidden_units=[1024, 512, 256],\n",
    "    feature_columns=[embedded_text_feature_column],\n",
    "    n_classes=3,\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Train the estimator for a reasonable amount of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpc48bqaz2/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpc48bqaz2/model.ckpt.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(32, 128), b.shape=(128, 500), m=32, n=500, k=128\n\t [[node dnn/hiddenlayer_0/MatMul (defined at <ipython-input-19-6db09b378193>:4)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/Reshape_1, dnn/hiddenlayer_0/kernel)]]\n\t [[{{node dnn/hiddenlayer_1/Relu/_65}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_115_dnn/hiddenlayer_1/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'dnn/hiddenlayer_0/MatMul', defined at:\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-6db09b378193>\", line 4, in <module>\n    estimator.train(input_fn=train_input_fn, steps=3000);\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1207, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1237, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 486, in _model_fn\n    shared_state_manager=shared_state_manager)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 300, in _dnn_model_fn\n    logits = logit_fn(features=features, mode=mode)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 109, in dnn_logit_fn\n    return dnn_model(features, mode)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 206, in call\n    net = self._hidden_layers[i](net)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 970, in call\n    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(32, 128), b.shape=(128, 500), m=32, n=500, k=128\n\t [[node dnn/hiddenlayer_0/MatMul (defined at <ipython-input-19-6db09b378193>:4)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/Reshape_1, dnn/hiddenlayer_0/kernel)]]\n\t [[{{node dnn/hiddenlayer_1/Relu/_65}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_115_dnn/hiddenlayer_1/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(32, 128), b.shape=(128, 500), m=32, n=500, k=128\n\t [[{{node dnn/hiddenlayer_0/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/Reshape_1, dnn/hiddenlayer_0/kernel)]]\n\t [[{{node dnn/hiddenlayer_1/Relu/_65}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_115_dnn/hiddenlayer_1/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6db09b378193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# batch size. This is roughly equivalent to 5 epochs since the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# contains 25,000 examples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1157\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(32, 128), b.shape=(128, 500), m=32, n=500, k=128\n\t [[node dnn/hiddenlayer_0/MatMul (defined at <ipython-input-19-6db09b378193>:4)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/Reshape_1, dnn/hiddenlayer_0/kernel)]]\n\t [[{{node dnn/hiddenlayer_1/Relu/_65}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_115_dnn/hiddenlayer_1/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'dnn/hiddenlayer_0/MatMul', defined at:\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-19-6db09b378193>\", line 4, in <module>\n    estimator.train(input_fn=train_input_fn, steps=3000);\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1207, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1237, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 486, in _model_fn\n    shared_state_manager=shared_state_manager)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 300, in _dnn_model_fn\n    logits = logit_fn(features=features, mode=mode)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 109, in dnn_logit_fn\n    return dnn_model(features, mode)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 206, in call\n    net = self._hidden_layers[i](net)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 374, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 970, in call\n    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(32, 128), b.shape=(128, 500), m=32, n=500, k=128\n\t [[node dnn/hiddenlayer_0/MatMul (defined at <ipython-input-19-6db09b378193>:4)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/Reshape_1, dnn/hiddenlayer_0/kernel)]]\n\t [[{{node dnn/hiddenlayer_1/Relu/_65}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_115_dnn/hiddenlayer_1/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Training for 1,000 steps means 128,000 training examples with the default\n",
    "# batch size. This is roughly equivalent to 5 epochs since the training dataset\n",
    "# contains 25,000 examples.\n",
    "estimator.train(input_fn=train_input_fn, steps=3000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Run predictions for both training and test set."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:55.890263 140411733964608 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:56.753264 140411733964608 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:57.985651 140411733964608 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:58.216483 140411733964608 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-11-10:47:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:58.244279 140411733964608 tf_logging.py:115] Starting evaluation at 2019-04-11-10:47:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:58.490012 140411733964608 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpvyderz7p/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:58.494348 140411733964608 tf_logging.py:115] Restoring parameters from /tmp/tmpvyderz7p/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:59.190602 140411733964608 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:47:59.775360 140411733964608 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-11-10:48:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:48:04.495506 140411733964608 tf_logging.py:115] Finished evaluation at 2019-04-11-10:48:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 0.9076667, average_loss = 0.50751317, global_step = 3000, loss = 8.098614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:48:04.497148 140411733964608 tf_logging.py:115] Saving dict for global step 3000: accuracy = 0.9076667, average_loss = 0.50751317, global_step = 3000, loss = 8.098614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: /tmp/tmpvyderz7p/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 13:48:05.644914 140411733964608 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 3000: /tmp/tmpvyderz7p/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9076666831970215\n"
     ]
    }
   ],
   "source": [
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# univ-2 DAN, only 3000 steps, not 5k\n",
    "Training set accuracy: 0.9677196145057678\n",
    "Test set accuracy: 0.8953456878662109\n",
    "\n",
    "# univ-2 DAN, 1.1 sec per 100 step\n",
    "Training set accuracy: 0.9911229014396667\n",
    "Test set accuracy: 0.8985741138458252\n",
    "\n",
    "\n",
    "# elmo - VERY slow to train, 18 sec per 100 step. (n 15 min for 5000)\n",
    "Training set accuracy: 0.8880562782287598\n",
    "Test set accuracy: 0.8679042458534241\n",
    "\n",
    "# smaller DNN, univ-3\n",
    "    hidden_units=[500, 100],\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "Training set accuracy: 0.9853585362434387\n",
    "Test set accuracy: 0.9106806516647339\n",
    "\n",
    "# univ-3, steps 5000, adagrad\n",
    "Training set accuracy: 0.9911805391311646\n",
    "Test set accuracy: 0.901264488697052\n",
    "\n",
    "# Transformer, universal-3\n",
    "Training set accuracy: 0.972100555896759\n",
    "Test set accuracy: 0.892924427986145\n",
    "\n",
    "# DNN 500, 100\n",
    "Training set accuracy: 0.9122089147567749\n",
    "Test set accuracy: 0.8714016675949097\n",
    "\n",
    "# DNN 1024, 512, 256\n",
    "Training set accuracy: 0.9992506504058838\n",
    "Test set accuracy: 0.8576809167861938"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(basefolder+'input/test.csv'  ,sep='\\t', header = None)\n",
    "test.columns  = ['id','label', 'text']\n",
    "\n",
    "final_test_df = test\n",
    "\n",
    "# Prediction on the final set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    final_test_df, final_test_df[\"label\"], shuffle=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = estimator.predict(input_fn=predict_test_input_fn)\n",
    "#[prediction for prediction in  predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(estimator, predict_test_input_fn):\n",
    "  #return [x for x in estimator.predict(input_fn=predict_test_input_fn)]\n",
    "  labels = [0,1,2]\n",
    "  predictions = estimator.predict(input_fn=predict_test_input_fn)\n",
    "  return [ (prediction['probabilities'], prediction['class_ids'][0])  for prediction in  predictions]\n",
    "    # class_ids is a list, such [1], use [0] to return just integer without surrounding list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 14:57:52.471598 140411733964608 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 14:57:53.334416 140411733964608 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 14:57:54.542077 140411733964608 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 14:57:54.717478 140411733964608 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 14:57:54.974824 140411733964608 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp5p51_vu0/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 14:57:54.977990 140411733964608 tf_logging.py:115] Restoring parameters from /tmp/tmp5p51_vu0/model.ckpt-3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 14:57:55.706377 140411733964608 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0411 14:57:56.329119 140411733964608 tf_logging.py:115] Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "res = get_predictions(estimator, predict_test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14206</td>\n",
       "      <td>[0.00014044867, 0.0005699134, 0.99928963]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16354</td>\n",
       "      <td>[0.0005789527, 0.0064157858, 0.99300534]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21621</td>\n",
       "      <td>[0.00025487362, 0.9996896, 5.5497745e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5899</td>\n",
       "      <td>[0.00021313019, 0.99969983, 8.711357e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19499</td>\n",
       "      <td>[0.00020131422, 0.00072864885, 0.9990701]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                      probs  label\n",
       "0  14206  [0.00014044867, 0.0005699134, 0.99928963]      2\n",
       "1  16354   [0.0005789527, 0.0064157858, 0.99300534]      2\n",
       "2  21621  [0.00025487362, 0.9996896, 5.5497745e-05]      1\n",
       "3   5899  [0.00021313019, 0.99969983, 8.711357e-05]      1\n",
       "4  19499  [0.00020131422, 0.00072864885, 0.9990701]      2"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(res)\n",
    "results.columns=['probs','label']\n",
    "# add id's\n",
    "results = pd.concat([test['id'], results], axis=1)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResults(df, name=\"defaultname\"):\n",
    "    df.to_json(basefolder+'output/'+name+'.json', orient='records')\n",
    "    df.to_csv(basefolder+'output/'+name+'.csv', header=True, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'univ3_18k'\n",
    "saveResults(results, name='predictions_'+modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14206</td>\n",
       "      <td>[0.00014044867, 0.0005699134, 0.99928963]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16354</td>\n",
       "      <td>[0.0005789527, 0.0064157858, 0.99300534]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21621</td>\n",
       "      <td>[0.00025487362, 0.9996896, 5.5497745e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5899</td>\n",
       "      <td>[0.00021313019, 0.99969983, 8.711357e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19499</td>\n",
       "      <td>[0.00020131422, 0.00072864885, 0.9990701]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6659</td>\n",
       "      <td>[0.00014100528, 0.99941206, 0.00044693804]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24999</td>\n",
       "      <td>[0.00014207677, 0.9997265, 0.00013143675]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9068</td>\n",
       "      <td>[0.00013567579, 0.9997669, 9.746551e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18454</td>\n",
       "      <td>[0.00019105988, 0.9991104, 0.00069855223]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14633</td>\n",
       "      <td>[0.00022559425, 0.0007601781, 0.99901426]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20377</td>\n",
       "      <td>[0.000908984, 0.9990404, 5.064923e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18468</td>\n",
       "      <td>[0.00029758402, 0.99960333, 9.912115e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4695</td>\n",
       "      <td>[0.00011754904, 0.99978226, 0.0001002291]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14723</td>\n",
       "      <td>[0.00012786698, 0.999742, 0.00013018739]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22427</td>\n",
       "      <td>[0.00021294515, 0.9997191, 6.793024e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16280</td>\n",
       "      <td>[0.007925751, 0.9918405, 0.00023371141]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16405</td>\n",
       "      <td>[0.00014379856, 0.9997714, 8.479407e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11449</td>\n",
       "      <td>[0.00015360725, 0.9997266, 0.000119775345]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3373</td>\n",
       "      <td>[0.00012053542, 0.999762, 0.00011747517]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5774</td>\n",
       "      <td>[0.00015283035, 0.9997898, 5.748376e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16240</td>\n",
       "      <td>[0.0001857549, 0.9997198, 9.437115e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24321</td>\n",
       "      <td>[0.0003569419, 0.99940526, 0.00023781469]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21598</td>\n",
       "      <td>[0.00017783928, 0.99965847, 0.00016379009]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10378</td>\n",
       "      <td>[0.00017746906, 0.9997156, 0.00010686431]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10110</td>\n",
       "      <td>[0.0001487266, 0.99975735, 9.387499e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10646</td>\n",
       "      <td>[0.00054027076, 0.9977702, 0.0016895889]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4784</td>\n",
       "      <td>[0.00017643449, 0.99960345, 0.00022013798]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13608</td>\n",
       "      <td>[0.0001789721, 0.999754, 6.697521e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>17238</td>\n",
       "      <td>[0.00043446454, 0.9981856, 0.0013799164]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11438</td>\n",
       "      <td>[0.00014797851, 0.9997471, 0.000104865445]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>280</td>\n",
       "      <td>[0.00017599504, 0.9996282, 0.0001958058]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>22199</td>\n",
       "      <td>[0.00018059743, 0.9997365, 8.300207e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>3473</td>\n",
       "      <td>[0.00013349901, 0.99969566, 0.00017085143]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>17267</td>\n",
       "      <td>[0.000118745105, 0.9997874, 9.3929746e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>12942</td>\n",
       "      <td>[0.00031920982, 0.99938667, 0.00029420646]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>1838</td>\n",
       "      <td>[0.00038475555, 0.99950826, 0.00010694948]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>10420</td>\n",
       "      <td>[0.0002028662, 0.99974364, 5.3477877e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>17012</td>\n",
       "      <td>[0.00017195365, 0.9997652, 6.285021e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>8210</td>\n",
       "      <td>[0.0002455909, 0.99969244, 6.19821e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>7765</td>\n",
       "      <td>[0.00030215396, 0.9979626, 0.0017352956]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>9203</td>\n",
       "      <td>[0.00021397282, 0.99971265, 7.346041e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>3027</td>\n",
       "      <td>[0.00016277876, 0.99979526, 4.1918345e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>4277</td>\n",
       "      <td>[0.0006880464, 0.0018995922, 0.9974124]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>14684</td>\n",
       "      <td>[0.00012983805, 0.99966145, 0.00020863202]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>19413</td>\n",
       "      <td>[0.00012924739, 0.9997615, 0.00010927456]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>16315</td>\n",
       "      <td>[0.00014076072, 0.99976546, 9.3795556e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>12766</td>\n",
       "      <td>[0.00019346124, 0.99972993, 7.6623735e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>6128</td>\n",
       "      <td>[0.012767858, 0.9870608, 0.00017136984]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>17540</td>\n",
       "      <td>[0.00024034533, 0.9994616, 0.00029805585]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>6763</td>\n",
       "      <td>[0.0001716992, 0.99967766, 0.00015063674]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>16582</td>\n",
       "      <td>[0.00015504271, 0.9997204, 0.00012454315]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>5170</td>\n",
       "      <td>[0.00016087462, 0.9996309, 0.00020818404]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>24973</td>\n",
       "      <td>[0.9432449, 0.055559866, 0.0011952872]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>9722</td>\n",
       "      <td>[0.00047430972, 0.021596085, 0.97792965]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>13733</td>\n",
       "      <td>[0.00019795781, 0.9997136, 8.839478e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>20528</td>\n",
       "      <td>[0.00016743204, 0.9994947, 0.0003379109]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>13359</td>\n",
       "      <td>[0.0011435205, 0.00357944, 0.99527705]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>23576</td>\n",
       "      <td>[0.00025064452, 0.9996524, 9.700935e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>13536</td>\n",
       "      <td>[0.00014739526, 0.9997298, 0.00012272518]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>1302</td>\n",
       "      <td>[0.00025827094, 0.9996737, 6.804762e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       probs  label\n",
       "0     14206   [0.00014044867, 0.0005699134, 0.99928963]      2\n",
       "1     16354    [0.0005789527, 0.0064157858, 0.99300534]      2\n",
       "2     21621   [0.00025487362, 0.9996896, 5.5497745e-05]      1\n",
       "3      5899   [0.00021313019, 0.99969983, 8.711357e-05]      1\n",
       "4     19499   [0.00020131422, 0.00072864885, 0.9990701]      2\n",
       "5      6659  [0.00014100528, 0.99941206, 0.00044693804]      1\n",
       "6     24999   [0.00014207677, 0.9997265, 0.00013143675]      1\n",
       "7      9068    [0.00013567579, 0.9997669, 9.746551e-05]      1\n",
       "8     18454   [0.00019105988, 0.9991104, 0.00069855223]      1\n",
       "9     14633   [0.00022559425, 0.0007601781, 0.99901426]      2\n",
       "10    20377      [0.000908984, 0.9990404, 5.064923e-05]      1\n",
       "11    18468   [0.00029758402, 0.99960333, 9.912115e-05]      1\n",
       "12     4695   [0.00011754904, 0.99978226, 0.0001002291]      1\n",
       "13    14723    [0.00012786698, 0.999742, 0.00013018739]      1\n",
       "14    22427    [0.00021294515, 0.9997191, 6.793024e-05]      1\n",
       "15    16280     [0.007925751, 0.9918405, 0.00023371141]      1\n",
       "16    16405    [0.00014379856, 0.9997714, 8.479407e-05]      1\n",
       "17    11449  [0.00015360725, 0.9997266, 0.000119775345]      1\n",
       "18     3373    [0.00012053542, 0.999762, 0.00011747517]      1\n",
       "19     5774    [0.00015283035, 0.9997898, 5.748376e-05]      1\n",
       "20    16240     [0.0001857549, 0.9997198, 9.437115e-05]      1\n",
       "21    24321   [0.0003569419, 0.99940526, 0.00023781469]      1\n",
       "22    21598  [0.00017783928, 0.99965847, 0.00016379009]      1\n",
       "23    10378   [0.00017746906, 0.9997156, 0.00010686431]      1\n",
       "24    10110    [0.0001487266, 0.99975735, 9.387499e-05]      1\n",
       "25    10646    [0.00054027076, 0.9977702, 0.0016895889]      1\n",
       "26     4784  [0.00017643449, 0.99960345, 0.00022013798]      1\n",
       "27    13608      [0.0001789721, 0.999754, 6.697521e-05]      1\n",
       "28    17238    [0.00043446454, 0.9981856, 0.0013799164]      1\n",
       "29    11438  [0.00014797851, 0.9997471, 0.000104865445]      1\n",
       "...     ...                                         ...    ...\n",
       "2970    280    [0.00017599504, 0.9996282, 0.0001958058]      1\n",
       "2971  22199    [0.00018059743, 0.9997365, 8.300207e-05]      1\n",
       "2972   3473  [0.00013349901, 0.99969566, 0.00017085143]      1\n",
       "2973  17267  [0.000118745105, 0.9997874, 9.3929746e-05]      1\n",
       "2974  12942  [0.00031920982, 0.99938667, 0.00029420646]      1\n",
       "2975   1838  [0.00038475555, 0.99950826, 0.00010694948]      1\n",
       "2976  10420   [0.0002028662, 0.99974364, 5.3477877e-05]      1\n",
       "2977  17012    [0.00017195365, 0.9997652, 6.285021e-05]      1\n",
       "2978   8210     [0.0002455909, 0.99969244, 6.19821e-05]      1\n",
       "2979   7765    [0.00030215396, 0.9979626, 0.0017352956]      1\n",
       "2980   9203   [0.00021397282, 0.99971265, 7.346041e-05]      1\n",
       "2981   3027  [0.00016277876, 0.99979526, 4.1918345e-05]      1\n",
       "2982   4277     [0.0006880464, 0.0018995922, 0.9974124]      2\n",
       "2983  14684  [0.00012983805, 0.99966145, 0.00020863202]      1\n",
       "2984  19413   [0.00012924739, 0.9997615, 0.00010927456]      1\n",
       "2985  16315  [0.00014076072, 0.99976546, 9.3795556e-05]      1\n",
       "2986  12766  [0.00019346124, 0.99972993, 7.6623735e-05]      1\n",
       "2987   6128     [0.012767858, 0.9870608, 0.00017136984]      1\n",
       "2988  17540   [0.00024034533, 0.9994616, 0.00029805585]      1\n",
       "2989   6763   [0.0001716992, 0.99967766, 0.00015063674]      1\n",
       "2990  16582   [0.00015504271, 0.9997204, 0.00012454315]      1\n",
       "2991   5170   [0.00016087462, 0.9996309, 0.00020818404]      1\n",
       "2992  24973      [0.9432449, 0.055559866, 0.0011952872]      0\n",
       "2993   9722    [0.00047430972, 0.021596085, 0.97792965]      2\n",
       "2994  13733    [0.00019795781, 0.9997136, 8.839478e-05]      1\n",
       "2995  20528    [0.00016743204, 0.9994947, 0.0003379109]      1\n",
       "2996  13359      [0.0011435205, 0.00357944, 0.99527705]      2\n",
       "2997  23576    [0.00025064452, 0.9996524, 9.700935e-05]      1\n",
       "2998  13536   [0.00014739526, 0.9997298, 0.00012272518]      1\n",
       "2999   1302    [0.00025827094, 0.9996737, 6.804762e-05]      1\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose embed\n",
    "create model\n",
    "train\n",
    "produce predictions\n",
    "addPredictions\n",
    "\n",
    "repeat for n models and train size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column = setEmbedding(\"https://tfhub.dev/google/universal-sentence-encoder/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "\n",
    "model_name = modelname\n",
    "\n",
    "all.append({'model': model_name,\n",
    "                'labels': results['label'],\n",
    "                'probs': results['probs']\n",
    "               }\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-6e00df62eec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_pickle'"
     ]
    }
   ],
   "source": [
    "all.to_pickle('all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import shelve\n",
    "# file to be used\n",
    "shelf = shelve.open(\"all.shlf\")\n",
    "# serializing\n",
    "shelf[\"all\"] = all\n",
    "shelf.close() # you must close the shelve file!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read\n",
    "import shelve\n",
    "shelf = shelve.open(\"all.shlf\") # the same filename that you used before, please\n",
    "new = shelf[\"all\"]\n",
    "shelf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'univ3_18k', 'labels': 0       2\n",
       "  1       2\n",
       "  2       1\n",
       "  3       1\n",
       "  4       2\n",
       "  5       1\n",
       "  6       1\n",
       "  7       1\n",
       "  8       1\n",
       "  9       2\n",
       "  10      1\n",
       "  11      1\n",
       "  12      1\n",
       "  13      1\n",
       "  14      1\n",
       "  15      1\n",
       "  16      1\n",
       "  17      1\n",
       "  18      1\n",
       "  19      1\n",
       "  20      1\n",
       "  21      1\n",
       "  22      1\n",
       "  23      1\n",
       "  24      1\n",
       "  25      1\n",
       "  26      1\n",
       "  27      1\n",
       "  28      1\n",
       "  29      1\n",
       "         ..\n",
       "  2970    1\n",
       "  2971    1\n",
       "  2972    1\n",
       "  2973    1\n",
       "  2974    1\n",
       "  2975    1\n",
       "  2976    1\n",
       "  2977    1\n",
       "  2978    1\n",
       "  2979    1\n",
       "  2980    1\n",
       "  2981    1\n",
       "  2982    2\n",
       "  2983    1\n",
       "  2984    1\n",
       "  2985    1\n",
       "  2986    1\n",
       "  2987    1\n",
       "  2988    1\n",
       "  2989    1\n",
       "  2990    1\n",
       "  2991    1\n",
       "  2992    0\n",
       "  2993    2\n",
       "  2994    1\n",
       "  2995    1\n",
       "  2996    2\n",
       "  2997    1\n",
       "  2998    1\n",
       "  2999    1\n",
       "  Name: label, Length: 3000, dtype: int64, 'probs': 0        [0.00014044867, 0.0005699134, 0.99928963]\n",
       "  1         [0.0005789527, 0.0064157858, 0.99300534]\n",
       "  2        [0.00025487362, 0.9996896, 5.5497745e-05]\n",
       "  3        [0.00021313019, 0.99969983, 8.711357e-05]\n",
       "  4        [0.00020131422, 0.00072864885, 0.9990701]\n",
       "  5       [0.00014100528, 0.99941206, 0.00044693804]\n",
       "  6        [0.00014207677, 0.9997265, 0.00013143675]\n",
       "  7         [0.00013567579, 0.9997669, 9.746551e-05]\n",
       "  8        [0.00019105988, 0.9991104, 0.00069855223]\n",
       "  9        [0.00022559425, 0.0007601781, 0.99901426]\n",
       "  10          [0.000908984, 0.9990404, 5.064923e-05]\n",
       "  11       [0.00029758402, 0.99960333, 9.912115e-05]\n",
       "  12       [0.00011754904, 0.99978226, 0.0001002291]\n",
       "  13        [0.00012786698, 0.999742, 0.00013018739]\n",
       "  14        [0.00021294515, 0.9997191, 6.793024e-05]\n",
       "  15         [0.007925751, 0.9918405, 0.00023371141]\n",
       "  16        [0.00014379856, 0.9997714, 8.479407e-05]\n",
       "  17      [0.00015360725, 0.9997266, 0.000119775345]\n",
       "  18        [0.00012053542, 0.999762, 0.00011747517]\n",
       "  19        [0.00015283035, 0.9997898, 5.748376e-05]\n",
       "  20         [0.0001857549, 0.9997198, 9.437115e-05]\n",
       "  21       [0.0003569419, 0.99940526, 0.00023781469]\n",
       "  22      [0.00017783928, 0.99965847, 0.00016379009]\n",
       "  23       [0.00017746906, 0.9997156, 0.00010686431]\n",
       "  24        [0.0001487266, 0.99975735, 9.387499e-05]\n",
       "  25        [0.00054027076, 0.9977702, 0.0016895889]\n",
       "  26      [0.00017643449, 0.99960345, 0.00022013798]\n",
       "  27          [0.0001789721, 0.999754, 6.697521e-05]\n",
       "  28        [0.00043446454, 0.9981856, 0.0013799164]\n",
       "  29      [0.00014797851, 0.9997471, 0.000104865445]\n",
       "                             ...                    \n",
       "  2970      [0.00017599504, 0.9996282, 0.0001958058]\n",
       "  2971      [0.00018059743, 0.9997365, 8.300207e-05]\n",
       "  2972    [0.00013349901, 0.99969566, 0.00017085143]\n",
       "  2973    [0.000118745105, 0.9997874, 9.3929746e-05]\n",
       "  2974    [0.00031920982, 0.99938667, 0.00029420646]\n",
       "  2975    [0.00038475555, 0.99950826, 0.00010694948]\n",
       "  2976     [0.0002028662, 0.99974364, 5.3477877e-05]\n",
       "  2977      [0.00017195365, 0.9997652, 6.285021e-05]\n",
       "  2978       [0.0002455909, 0.99969244, 6.19821e-05]\n",
       "  2979      [0.00030215396, 0.9979626, 0.0017352956]\n",
       "  2980     [0.00021397282, 0.99971265, 7.346041e-05]\n",
       "  2981    [0.00016277876, 0.99979526, 4.1918345e-05]\n",
       "  2982       [0.0006880464, 0.0018995922, 0.9974124]\n",
       "  2983    [0.00012983805, 0.99966145, 0.00020863202]\n",
       "  2984     [0.00012924739, 0.9997615, 0.00010927456]\n",
       "  2985    [0.00014076072, 0.99976546, 9.3795556e-05]\n",
       "  2986    [0.00019346124, 0.99972993, 7.6623735e-05]\n",
       "  2987       [0.012767858, 0.9870608, 0.00017136984]\n",
       "  2988     [0.00024034533, 0.9994616, 0.00029805585]\n",
       "  2989     [0.0001716992, 0.99967766, 0.00015063674]\n",
       "  2990     [0.00015504271, 0.9997204, 0.00012454315]\n",
       "  2991     [0.00016087462, 0.9996309, 0.00020818404]\n",
       "  2992        [0.9432449, 0.055559866, 0.0011952872]\n",
       "  2993      [0.00047430972, 0.021596085, 0.97792965]\n",
       "  2994      [0.00019795781, 0.9997136, 8.839478e-05]\n",
       "  2995      [0.00016743204, 0.9994947, 0.0003379109]\n",
       "  2996        [0.0011435205, 0.00357944, 0.99527705]\n",
       "  2997      [0.00025064452, 0.9996524, 9.700935e-05]\n",
       "  2998     [0.00014739526, 0.9997298, 0.00012272518]\n",
       "  2999      [0.00025827094, 0.9996737, 6.804762e-05]\n",
       "  Name: probs, Length: 3000, dtype: object}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'univ3_18k'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all[0]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       2\n",
       "2       1\n",
       "3       1\n",
       "4       2\n",
       "5       1\n",
       "6       1\n",
       "7       1\n",
       "8       1\n",
       "9       2\n",
       "10      1\n",
       "11      1\n",
       "12      1\n",
       "13      1\n",
       "14      1\n",
       "15      1\n",
       "16      1\n",
       "17      1\n",
       "18      1\n",
       "19      1\n",
       "20      1\n",
       "21      1\n",
       "22      1\n",
       "23      1\n",
       "24      1\n",
       "25      1\n",
       "26      1\n",
       "27      1\n",
       "28      1\n",
       "29      1\n",
       "       ..\n",
       "2970    1\n",
       "2971    1\n",
       "2972    1\n",
       "2973    1\n",
       "2974    1\n",
       "2975    1\n",
       "2976    1\n",
       "2977    1\n",
       "2978    1\n",
       "2979    1\n",
       "2980    1\n",
       "2981    1\n",
       "2982    2\n",
       "2983    1\n",
       "2984    1\n",
       "2985    1\n",
       "2986    1\n",
       "2987    1\n",
       "2988    1\n",
       "2989    1\n",
       "2990    1\n",
       "2991    1\n",
       "2992    0\n",
       "2993    2\n",
       "2994    1\n",
       "2995    1\n",
       "2996    2\n",
       "2997    1\n",
       "2998    1\n",
       "2999    1\n",
       "Name: label, Length: 3000, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Predicting Movie Reviews with BERT on TF Hub.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
