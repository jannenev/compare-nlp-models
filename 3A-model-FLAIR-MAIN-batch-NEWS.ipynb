{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train number of different models from Flair framework.\n",
    "# With different sized trainin data\n",
    "# save predictions of each model to file\n",
    "\n",
    "# Notice - 1st run may take long as model weights are downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version for dataset business news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = 'hatespeech'\n",
    "dataset = 'businessnews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "# https://github.com/t-davidson/hate-speech-and-offensive-language\n",
    "\n",
    "# Paper\n",
    "# https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15665\n",
    "\n",
    "# Their code\n",
    "# https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/src/Automated%20Hate%20Speech%20Detection%20and%20the%20Problem%20of%20Offensive%20Language%20Python%203.6.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code based on https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm-multi-forward-v0.1.pt-tmp-cache.sqllite   up to 40,8 GB!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.stem.porter import *\n",
    "import time\n",
    "\n",
    "from collections import deque\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Display whole text of dataframe field and don't cut it\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f'torch version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(f'torch version: {torch.__version__}')\n",
    "torch version: 1.0.1.post2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.4'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flair\n",
    "flair.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/max/git/newcombined/dataset_businessnews/\n"
     ]
    }
   ],
   "source": [
    "#dataset = 'hatespeech'\n",
    "\n",
    "current = os.getcwd()\n",
    "basefolder = current + '/dataset_'+ dataset+'/'\n",
    "datafolder = basefolder + 'data/'  # for example /dataset_businessnews/data/\n",
    "print(basefolder)\n",
    "\n",
    "infolder =  basefolder + 'input/'\n",
    "outfolder = basefolder + 'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "\n",
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.embeddings import DocumentPoolEmbeddings\n",
    "from flair.embeddings import FlairEmbeddings, BertEmbeddings, ELMoEmbeddings\n",
    "from flair.embeddings import BytePairEmbeddings\n",
    "\n",
    "from flair.embeddings import OpenAIGPTEmbeddings\n",
    "from flair.embeddings import OpenAIGPT2Embeddings\n",
    "\n",
    "# New DocumentRNNEmbeddings, deprecates DocumentLSTMembeddings\n",
    "# from flair.embeddings import #DocumentLSTMEmbeddings\n",
    "\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "\n",
    "# new ones: GPT-1 and GPT-2\n",
    "# https://github.com/flairNLP/flair/tree/master/resources/docs/embeddings\n",
    "# https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/TRANSFORMER_EMBEDDINGS.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "# REPEATABILITY\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=1) # also called here\n",
    "\n",
    "# TEXT PREPROCESS\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        if punct in x: # comparison makes faster\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "quotes = ['″', '′', '\"'] # apostrophe \"'\"\n",
    "def mark_quotes(x):\n",
    "    x = str(x)\n",
    "    for quote in quotes:\n",
    "        if quote in x: # comparison makes faster\n",
    "            x = x.replace(quote, f'quote')\n",
    "    return x\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    \n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    \n",
    "    #add #, mention, e.g. &#8120     \n",
    "    mention_regex2  =   '&#[0-9]*' \n",
    "    \n",
    "    \n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, ' URL ', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, ' MENTION', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex2, ' MENTION', parsed_text)    \n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", tweet.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "    # *needed to be removed or outputs a list of letters\n",
    "    #tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]\", tweet.lower())).strip()  \n",
    "    #tweet = \" \".join(re.split(r'\\s+', tweet.lower())).strip()\n",
    "    return tweet.split()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test-cases\n",
    "print(basic_tokenize('aaa'))\n",
    "print(re.split(\"[^a-zA-Z.,!?]\", 'aaa aa'))\n",
    "\n",
    "# test, @-reference and url\n",
    "# still misses this ''#8221;food' (;text continuing on end without space)\n",
    "preprocess('&#8220;@_CiaraaaS: What things do you love? &#8212; Myself http://t.co/D23mKPgMxu&#8221;food weed pussy life &#128129')\n",
    "\n",
    "preprocess('http://t.co/D23mKPgMxu&#8221;food')\n",
    "\n",
    "giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "re.sub(giant_url_regex, ' URL ', 'http://t.co/D23mKPgMxu&#8221;food')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Dataset - hatespeech\n",
    "# count: nr of users who coded item\n",
    "# middle: nr who coded as hate speech / offecinve / neither\n",
    "# class: majority label of users \n",
    "#  0 - hate speech\n",
    "#  1 - ONLY offensive  language\n",
    "#  2 - neither\n",
    "\n",
    "mydata = pd.read_csv('data/labeled_data.csv', index_col=0)\n",
    "mydata.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    train = pd.read_csv(basefolder+'input/train.csv',sep='\\t', header = None)\n",
    "    dev = pd.read_csv(basefolder+'input/dev.csv'  ,sep='\\t', header = None)\n",
    "    test = pd.read_csv(basefolder+'input/test.csv'  ,sep='\\t', header = None)    \n",
    "    train.columns = ['id','label','text']\n",
    "    dev.columns  = ['id','label', 'text']\n",
    "    test.columns  = ['id','label', 'text']   \n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprosess_hatespeech(df):\n",
    "    df.text = df.text.apply(lambda x: preprocess(x)) #URL, @mention etc\n",
    "    df[\"text\"] = df[\"text\"].apply(lambda x: clean_text(x))\n",
    "    df[\"text\"] = df[\"text\"].apply(lambda x: mark_quotes(x))\n",
    "    #df.text = df.text.apply(lambda x: basic_tokenize(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprosess(df):\n",
    "    df.text = df.text.apply(lambda x: preprocess(x)) #URL, @mention etc\n",
    "    df[\"text\"] = df[\"text\"].apply(lambda x: clean_text(x))\n",
    "    df[\"text\"] = df[\"text\"].apply(lambda x: mark_quotes(x))\n",
    "    #df.text = df.text.apply(lambda x: basic_tokenize(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn label from digit into Fasttext format __label__.  \"1\" into \"__label__1\"\n",
    "def toFasttext(df):\n",
    "    df['label'] = '__label__' + df['label'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = infolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13718"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max len of training data is 13718\n",
    "13718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train, dev, test = loadData()\n",
    "\n",
    "# train = train.iloc[np.random.permutation(len(train))]\n",
    "\n",
    "\n",
    "#Test smaller\n",
    "trainsize = len(train)\n",
    "\n",
    "'''SET TRAINSIZE HERE'''\n",
    "# 100, 200, 500, 1k, 3k, 7k, 18k\n",
    "\n",
    "# 100,100   200,200  500,200    1k,200     3k,500    7k, 1k\n",
    "\n",
    "# 1k,200 (gpt-1 failed, used copy of glove) glove was 0.55 but 2nd of it got 0.45\n",
    "# 3k,500 gpt-1 failed again, copy of glove\n",
    "# 7k,1k gpt-1 copy of glove\n",
    "\n",
    "# 13k\n",
    "\n",
    "trainsize = 200\n",
    "devsize = 500\n",
    "\n",
    "\n",
    "# pick trainsize from train, keeping class ratios\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed_everything(seed=1)\n",
    "\n",
    "#train = train[0:trainsize]\n",
    "# slice only part of train to use, discard rest\n",
    "if trainsize < len(train):\n",
    "    train, _ = train_test_split(train, stratify=train['label'], train_size=trainsize)\n",
    "if devsize < len(dev):\n",
    "    dev, _ = train_test_split(dev, stratify=dev['label'], train_size=devsize)\n",
    "\n",
    "\n",
    "# testsize = 100  needs to match 3k and same ordering as in final test set\n",
    "testsize=500 #1000\n",
    "seed_everything(seed=1)\n",
    "test, _ = train_test_split(test, stratify=test['label'], train_size=testsize)\n",
    "\n",
    "print(len(train))\n",
    "print(len(dev))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>13356</td>\n",
       "      <td>4</td>\n",
       "      <td>Hybrids: ENTITY Toyota Motor reaches 10 million cars sold\\ntoday in 07:41\\nENTITY Toyota Motor h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>15397</td>\n",
       "      <td>1</td>\n",
       "      <td>BMW reportedly ends its self-driving car partnership with Chinese tech giant ENTITY Baidu\\nAfter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>4294</td>\n",
       "      <td>0</td>\n",
       "      <td>The Head of Samsung Is Again Being Questioned Behind Closed Doors\\nA South Korean judge question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>18544</td>\n",
       "      <td>4</td>\n",
       "      <td>China launches $11 billion fund for Central, Eastern Europe - Reuters\\nBEIJING China has set up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>7648</td>\n",
       "      <td>2</td>\n",
       "      <td>Alaska Air-Virgin America merger gets US nod\\nThe US Department of Justice (DOJ) has approved Al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  label  \\\n",
       "1061  13356      4   \n",
       "1397  15397      1   \n",
       "159    4294      0   \n",
       "2065  18544      4   \n",
       "1300   7648      2   \n",
       "\n",
       "                                                                                                     text  \n",
       "1061  Hybrids: ENTITY Toyota Motor reaches 10 million cars sold\\ntoday in 07:41\\nENTITY Toyota Motor h...  \n",
       "1397  BMW reportedly ends its self-driving car partnership with Chinese tech giant ENTITY Baidu\\nAfter...  \n",
       "159   The Head of Samsung Is Again Being Questioned Behind Closed Doors\\nA South Korean judge question...  \n",
       "2065  China launches $11 billion fund for Central, Eastern Europe - Reuters\\nBEIJING China has set up ...  \n",
       "1300  Alaska Air-Virgin America merger gets US nod\\nThe US Department of Justice (DOJ) has approved Al...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# train = preprosess_hatespeech(train)\n",
    "# dev = preprosess_hatespeech(dev)\n",
    "# test = preprosess_hatespeech(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprosess_hatespeech(train)\n",
    "dev = preprosess_hatespeech(dev)\n",
    "test = preprosess_hatespeech(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = toFasttext(train)\n",
    "dev = toFasttext(dev)\n",
    "test = toFasttext(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Coke ' s profit hit by weak developing markets ENTITY Coca - Cola ' s profit fell by more than half in the final quarter of the year ,  hurt by weakness in developing markets ,  but the company pointed to signs in North America and elsewhere that its shift to lower - calorie beverages and smaller ,  higher - priced packages is working .  Coke has been divesting from its bottling operations to focus on its more profitable concentrate business ,  a process it expects to accelerate in 2017 to meet a self - imposed December deadline .  That contributed to the 56 %  decline in fourth - quarter net income ,  to  $ 550 million ,  compared with  $ 1 . 24 billion a year earlier .  The company expects adjusted earnings per share to decline 1 %  to 4 %  in 2017 .  In the U . S .  ,  Coke is shifting from a volume - based model to one in which the company shares profit with its bottlers ,  selling smaller cans and bottles at higher prices .  Smaller packages in the U . S .  grew almost 10 %  in the quarter ,  said Chief Operating Officer James Quincey ,  who will become CEO of the company in May .  North America offered a brighter picture of Coke ' s operations in general :  Higher pricing and smaller packages drove revenue growth of 8 %  ,  even as volume grew just 1 %  .  Global volumes fell 1 %  in the quarter ,  dragged down by declines in Latin America .  Coke is reformulating its beverages and offering more zero - calorie options as governments in the U . S .  and elsewhere weigh special taxes on sugary drinks to fight rising obesity and diabetes rates .  Coca - Cola Zero Sugar ,  a new version launched last summer in the U . K .  ,  saw double - digit volume growth in Western Europe ,  boosted by expansion into France ,  Belgium ,  Netherlands and Ireland .  The soda tastes closer to original Coke ,  and its name is intended to better communicate to consumers that it contains no sugar .  The company continued the global expansion of its premium smartwater brand ,  which saw double - digit volume growth in North America in 2016 .  Rival PepsiCo Inc .  last month launched a competing product called LIFEWTR .  Coke ' s revenue has declined in each of the past four years .  Despite a diversification push into juices ,  bottled waters and other beverages ,  soda still represents about 70 %  of company sales .  Mr .  Quincey has said that he would like to go faster in diversifying Coke ' s beverage portfolio .  In a conference call with analysts Thursday ,  he noted that the company has done a few bolt - on acquisitions each year and  quote hopefully we will do a few in 2017 .  quote  Soda volumes world - wide fell 2 %  in the quarter ,  while noncarbonated drinks ,  which include tea ,  coffee and juice ,  grew 2 %  .  Revenue slipped 5 . 9 %  to  $ 9 . 41 billion ,  but stayed above analysts '  prediction for  $ 9 . 13 billion .  The company said foreign exchange shaved 2 %  off its revenue in the quarter .  PepsiCo is scheduled to report its results next week .  Write to Jennifer Maloney at jennifer . maloney MENTION . com and Anne Steele at Anne . Steele MENTION . com\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3117"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11637</th>\n",
       "      <td>6406</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>Coke ' s profit hit by weak developing markets ENTITY Coca - Cola ' s profit fell by more than h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11694</th>\n",
       "      <td>4446</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>Patent - holding company ’ s  $ 533M verdict against Apple is dust on appeal Enlarge  /  A repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>14702</td>\n",
       "      <td>__label__0</td>\n",
       "      <td>Greylock just hired Josh McFarland ,  who sold his Greylock - backed company to ENTITY Twitter J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>4947</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>Carrier gets state incentives ,  Trump pledge for keeping US jobs WASHINGTON ENTITY United Techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>11601</td>\n",
       "      <td>__label__4</td>\n",
       "      <td>The Private Capital Management Inc .  Increases Stake in ENTITY Nikeke Private Capital Managemen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       label  \\\n",
       "11637   6406  __label__1   \n",
       "11694   4446  __label__0   \n",
       "1964   14702  __label__0   \n",
       "9935    4947  __label__1   \n",
       "10386  11601  __label__4   \n",
       "\n",
       "                                                                                                      text  \n",
       "11637  Coke ' s profit hit by weak developing markets ENTITY Coca - Cola ' s profit fell by more than h...  \n",
       "11694  Patent - holding company ’ s  $ 533M verdict against Apple is dust on appeal Enlarge  /  A repre...  \n",
       "1964   Greylock just hired Josh McFarland ,  who sold his Greylock - backed company to ENTITY Twitter J...  \n",
       "9935   Carrier gets state incentives ,  Trump pledge for keeping US jobs WASHINGTON ENTITY United Techn...  \n",
       "10386  The Private Capital Management Inc .  Increases Stake in ENTITY Nikeke Private Capital Managemen...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible truncate of data fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2ea76a6588>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].map(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5690"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longest text in data set by characters\n",
    "longest = train['text'].map(len).max()\n",
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate to 3K for faster processing\n",
    "maxlen = 1500\n",
    "#maxlen = 1000\n",
    "#maxlen = 500\n",
    "\n",
    "# at 7k, down from 500 to 400\n",
    "#maxlen = 400\n",
    "\n",
    "# 11k again 500 - elmo hanged\n",
    "#maxlen = 300\n",
    "\n",
    "train['text'] = train.apply(lambda row: row['text'][0:maxlen], axis=1 )\n",
    "dev['text']   =   dev.apply(lambda row: row['text'][0:maxlen], axis=1 )\n",
    "test['text']  =  test.apply(lambda row: row['text'][0:maxlen], axis=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id in start of line is not Fasttext format: remove id\n",
    "train.drop(['id'], axis=1, inplace=True)\n",
    "dev.drop(['id'], axis=1, inplace=True)\n",
    "test.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Write to Flairs input csv files\n",
    "train.to_csv(basefolder+'input/flair_train.csv',sep='\\t', index = False, header = False)\n",
    "dev.to_csv(basefolder+'input/flair_dev.csv'  ,sep='\\t', index = False, header = False)\n",
    "test.to_csv(basefolder+'input/flair_test.csv',sep='\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flair"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# init Flair embeddings\n",
    "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
    "\n",
    "# init multilingual BERT\n",
    "#bert_embedding = BertEmbeddings('bert-base-multilingual-cased')\n",
    "\n",
    "embedding_flair = FlairEmbeddings('news-forward')\n",
    "sentence = Sentence('I love Austin')\n",
    "flair_forward_embedding.embed(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "# https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md\n",
    "\n",
    "# 'multi-forward', multi-lang English, German, French, Italian, Dutch, Polish, \n",
    "#        Mix of corpora (Web, Wikipedia, Subtitles, News)\n",
    "\n",
    "# 'mix-forward'English,   Forward LM embeddings over mixed corpus (Web, Wikipedia, Subtitles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StackedEmbeddings` are currently a `WordEmbeddings` class, so they cannot directly be used to classify \n",
    "documents. They can only be used for sequence labeling.\n",
    "\n",
    "However, you can put a stack of word embeddings into one of the `DocumentEmbeddings` classes such as `DocumentPoolEmbeddings` or `DocumentLSTMEmbeddings`. This way, you are specifying how to aggregate word embeddings for text classification\n",
    "\n",
    "So `DocumentPoolEmbeddings` will simply average them, while `DocumentLSTMEmbeddings` will train an LSTM over them.\n",
    "\n",
    " https://github.com/zalandoresearch/flair/issues/414\n",
    " \n",
    " *update depracated: DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create a StackedEmbedding object that combines glove and forward/backward flair embeddings\n",
    "stacked_embeddings = StackedEmbeddings([\n",
    "                                        WordEmbeddings('glove'), \n",
    "                                        #FlairEmbeddings('news-forward'), \n",
    "                                        #FlairEmbeddings('news-backward'),\n",
    "                                        FlairEmbeddings('multi-forward'), \n",
    "                                        #FlairEmbeddings('multi-backward'),    \n",
    "\n",
    "                                        # init multilingual BERT\n",
    "                                        BertEmbeddings('bert-base-cased'),   \n",
    "                                        # 'bert-base-cased'\n",
    "                                        # BertEmbeddings('bert-base-multilingual-cased'),   \n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Word embeddings in Flair\n",
    "# https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md\n",
    "\n",
    "WordEmbeddings('en')   English Fasttext. Only country-code is Fasttext\n",
    "\n",
    "'en-glove' (or 'glove') \tEnglish \tGloVe embeddings\n",
    "'en-extvec' (or 'extvec') \tEnglish \tKomninos embeddings\n",
    "'en-crawl' (or 'crawl') \tEnglish \tFastText embeddings over Web crawls\n",
    "'en-twitter' (or 'twitter') English \tTwitter embeddings\n",
    "\n",
    "'fi' \tFinnish \tFinnish FastText embeddings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word_embeddings = [WordEmbeddings('glove'),                    \n",
    "                  ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 0.9242\n",
    "word_embeddings = [WordEmbeddings('glove'), \n",
    " \n",
    "                   WordEmbeddings('en-twitter'),\n",
    "                     #WordEmbeddings('en'),    FastText embeddings over news and wikipedia data                \n",
    "                   WordEmbeddings('en-crawl'), # English FastText embeddings over Web crawls\n",
    "                   # WordEmbeddings('en-extvec') #Komnios embeddings\n",
    "                   #FlairEmbeddings('news-forward-fast'), \n",
    "                   #FlairEmbeddings('news-backward-fast'),\n",
    "                   \n",
    "                #FlairEmbeddings('multi-forward'), \n",
    "                   # FlairEmbeddings('multi-backward'), 17 GB each!\n",
    "                   #BertEmbeddings('bert-base-cased'),  \n",
    "                   #ELMoEmbeddings('original')\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR average \n",
    "# document_embeddings = DocumentPoolEmbeddings(word_embeddings)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# initialize the document embeddings, mode = mean\n",
    "document_embeddings = DocumentPoolEmbeddings([WordEmbeddings('glove'),\n",
    "                                               WordEmbeddings('en-crawl')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f\n",
    "\n",
    "# https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/max/git/newcombined/dataset_businessnews/input/'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/max/git/newcombined/dataset_businessnews/input/'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = infolder\n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:00:33,922 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-18 16:00:33,923 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-18 16:00:33,924 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-18 16:00:33,925 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    }
   ],
   "source": [
    "corpus = NLPTaskDataFetcher.load_classification_corpus(data_folder=infolder, test_file='flair_test.csv', dev_file='flair_dev.csv', train_file='flair_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: 200 train + 500 dev + 500 test sentences\n",
      "2020-05-18 16:00:37,934 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 99039.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:00:37,953 [b'1', b'0', b'4', b'3', b'2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)\n",
    "#print(len(corpus.train))\n",
    "\n",
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "#print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Individual model only, skip when in batch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(),\n",
    "                            multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = TextClassifier(stacked_embeddings, label_dictionary=corpus.make_label_dictionary(),\n",
    "#                            multi_label=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "\n",
    "# max epochs 5 for testing\n",
    "trainer.train('./', \n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32, # 32  # BERT OOM even with 16 batch -> need 8. others run on 32 or even more\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,     \n",
    "              max_epochs=5,  #15\n",
    "              ) #max_epochs=150\n",
    "\n",
    "duration = time.time()-start\n",
    "print(f'Duration {duration:.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove alone 0.902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flair multi takes a lot of disk space\n",
    "# Flair-multi can take 20-40 GB for each direction!\n",
    "# \n",
    "\n",
    "#NEW BEST adding preprocess puncts+quotes, glove, en-twitter, en-crawl:   test_score': 0.9242,\n",
    "\n",
    "# Winners: Fasttext: en-crawl, 0.9129 solo\n",
    "\n",
    "# word embeddings pooled:glove+fasttext 'test_score': 0.8892,\n",
    "\n",
    "#                   WordEmbeddings('en'),       # FastText embeddings over news and wikipedia data                \n",
    "#                   WordEmbeddings('en-crawl'), # FastText embeddings over Web crawls\n",
    "# Good ones\n",
    "# glove, en-twitter, en-crawl  0.9242\n",
    "# Fasttext: en-crawl, 0.9129 solo\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs to 15 from 5        - train time abotu 3x, f1 +0.003\n",
    "Duration 433.72 s\n",
    "MICRO_AVG: acc 0.8428 - f1-score 0.9147\n",
    "\n",
    "# BATCH SIZE 128\n",
    "MICRO_AVG: acc 0.7953 - f1-score 0.886\n",
    "Duration 388.62 s\n",
    "en-crawl\n",
    "Huge drop when raising batch from 16 to 128: 0.91 to 0.886, both 15 epoch\n",
    "\n",
    "# BI DIRECTIONAL. not increasin, might require larger model and/or more epochs.\n",
    "bi-direcitonal\n",
    "Duration 525.53 s\n",
    "MICRO_AVG: acc 0.8365 - f1-score 0.911 \n",
    "# ANOTHER 15 EPOCHS RAISES F1 by 0.002. still not as good as uni-directional was!\n",
    "# if cont another 15 epochs: MICRO_AVG: acc 0.8411 - f1-score 0.9137\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResults(savelist, name='all_default'):\n",
    "    import shelve\n",
    "    # file to be used\n",
    "    filename= name+'.shlf'\n",
    "    shelf = shelve.open(outfolder+filename)\n",
    "    #shelf = shelve.open(\"all_flair.shlf\")\n",
    "    # serializing\n",
    "    #shelf[\"all_flair\"] = all_flair\n",
    "    shelf[name] = savelist\n",
    "    shelf.close() # you must close the shelve file!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadResults(name='all_default'):\n",
    "    import shelve\n",
    "    filename= name+'.shlf'\n",
    "    shelf = shelve.open(outfolder+filename) \n",
    "    new = shelf[name]\n",
    "    shelf.close()\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Train with each embedding in the list, predict, add results to the list\n",
    "\n",
    "Parameters: word_embeddings,    eg   WordEmbeddings('glove')\n",
    "            modelname and modeldesc - text to be added in results\n",
    "            savelist : list where results are appended. Can be empty or already including results\n",
    "            epohcs: epochs to run\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def train_and_predict_single(embeddings, modelname, modeldesc, savelist, epochs=15, \n",
    "                             batch_size=32, embeddings_storage_mode='cpu'):\n",
    "    \n",
    "    print(modelname)\n",
    "    start = time.time()\n",
    "    \n",
    "# PREPARE\n",
    "    document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512,\n",
    "                                           bidirectional = False,\n",
    "                                           rnn_type='LSTM', \n",
    "                                           reproject_words=True, reproject_words_dimension=256                                                    \n",
    "                                           )\n",
    "\n",
    "    seed_everything(SEED)\n",
    "    corpus = NLPTaskDataFetcher.load_classification_corpus(data_folder, test_file='flair_test.csv', dev_file='flair_dev.csv', train_file='flair_train.csv')\n",
    "\n",
    "    seed_everything(SEED)\n",
    "    label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "    seed_everything(SEED)\n",
    "    classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(),\n",
    "                            multi_label=False)\n",
    "    trainer = ModelTrainer(classifier, corpus)\n",
    "    \n",
    "# TRAINING\n",
    "    seed_everything(SEED)\n",
    "    trainer.train('./', \n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=batch_size, # 32  # BERT OOM even with 16 batch -> need 8. others run on 32 or even more\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,     \n",
    "              max_epochs=epochs,  #15\n",
    "              #embeddings_storage_mode='cpu',\n",
    "              embeddings_storage_mode= embeddings_storage_mode,                  \n",
    "              #embeddings_storage_mode='gpu'\n",
    "              ) #max_epochs=150\n",
    "\n",
    "    duration_train = time.time()-start\n",
    "\n",
    "    # should this be set? embeddings_storage_mode='gpu'\n",
    "    \n",
    "    \n",
    "# PREDICT - INDIVIDUAL, SLOWER, but more robust\n",
    "    print('starting prediction')\n",
    "    start_pred = time.time()\n",
    "\n",
    "    # turn text into Flairs \"Sentence object\"\n",
    "    test['flair_sentence'] = test['text'].apply(lambda x: Sentence(x))\n",
    "\n",
    "    # discard output, result is put into object itself\n",
    "    _ = test['flair_sentence'].apply(lambda x: classifier.predict(x))\n",
    "\n",
    "    # sentence.labels returns a list containing flairs Label object that includes a dict. \n",
    "    # dig the values for predicted label + confidence from within the dict\n",
    "    # the 'value' returns a str, cast it to int\n",
    "    test['yhat'] = test['flair_sentence'].apply(lambda x: int(x.labels[0].to_dict()['value']))\n",
    "\n",
    "    test['confidence'] = test['flair_sentence'].apply(lambda x: x.labels[0].to_dict()['confidence'])\n",
    "\n",
    "    results = pd.DataFrame(test[['yhat', 'confidence']])\n",
    "    results.columns=['label','confidence']\n",
    "    results.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "# ADD RESULTS TO LIST\n",
    "\n",
    "    duration_predict = time.time() - start_pred\n",
    "    #print(f'Duration {duration:.2f} s')\n",
    "\n",
    "    savelist.append({'model': modelname,\n",
    "                'labels': results['label'],\n",
    "                'confidence': results['confidence'],\n",
    "                'traintime': duration_train,\n",
    "                'predtime3k': duration_predict,\n",
    "                'modeldesc': modeldesc\n",
    "               }\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' BATCH VERSION OF PREDICTION\n",
    "Train with each embedding in the list, predict, add results to the list\n",
    "\n",
    "Parameters: word_embeddings,    eg   WordEmbeddings('glove')\n",
    "            modelname and modeldesc - text to be added in results\n",
    "            savelist : list where results are appended. Can be empty or already including results\n",
    "            epohcs: epochs to run\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def train_and_predict(embeddings, modelname, modeldesc, savelist, epochs=15, batch_size=32):\n",
    "    \n",
    "    print(modelname)\n",
    "    start = time.time()\n",
    "    \n",
    "# PREPARE\n",
    "    document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512,\n",
    "                                           bidirectional = False,\n",
    "                                           rnn_type='LSTM', \n",
    "                                           reproject_words=True, reproject_words_dimension=256                                                    \n",
    "                                           )\n",
    "\n",
    "    seed_everything(SEED)\n",
    "    corpus = NLPTaskDataFetcher.load_classification_corpus(data_folder, test_file='flair_test.csv', dev_file='flair_dev.csv', train_file='flair_train.csv')\n",
    "\n",
    "    seed_everything(SEED)\n",
    "    label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "    seed_everything(SEED)\n",
    "    classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(),\n",
    "                            multi_label=False)\n",
    "    trainer = ModelTrainer(classifier, corpus)\n",
    "    \n",
    "# TRAINING\n",
    "    seed_everything(SEED)\n",
    "    trainer.train('./', \n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=batch_size, # 32  # BERT OOM even with 16 batch -> need 8. others run on 32 or even more\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,     \n",
    "              max_epochs=epochs,  #15\n",
    "              #embeddings_storage_mode='gpu'\n",
    "              embeddings_storage_mode='cpu'                  \n",
    "              ) #max_epochs=150\n",
    "\n",
    "    duration_train = time.time()-start\n",
    "\n",
    "    # should this be set? embeddings_storage_mode='gpu'\n",
    "    \n",
    "    \n",
    "#  PREDICT BATCH - FASTER\n",
    "#  https://github.com/flairNLP/flair/issues/1443\n",
    "\n",
    "    print('starting prediction')\n",
    "    start_pred = time.time()\n",
    "    \n",
    "    # place for sentences\n",
    "    sentences1 = deque() # deque is list with access on both ends\n",
    "    \n",
    "    # turn text into Flairs \"Sentence object\"\n",
    "    test['flair_sentence'] = test['text'].apply(lambda x: Sentence(x))\n",
    "    \n",
    "    # add them to list\n",
    "    for i in range(len(test)):\n",
    "        sentences1.append(test.iloc[i]['flair_sentence'])\n",
    "        \n",
    "    # initialize values for loop\n",
    "    scores = defaultdict(float)\n",
    "    values = defaultdict(str)\n",
    "    confidences = defaultdict(float)\n",
    "    i = 0\n",
    "\n",
    "    # predict for all sentences (mini_batch_size=32 worked with 1000 reviews on Colab)\n",
    "    #classifier.predict(sentences1, mini_batch_size=32)    \n",
    "    classifier.predict(sentences1, mini_batch_size=16)    \n",
    "        \n",
    "    # deque version to save memory\n",
    "    while len(sentences1) > 0:\n",
    "        sentence = sentences1.popleft()\n",
    "        \n",
    "        # is the dict value of 'score' same as 'condifence' in individual?\n",
    "        #scores[i] = sentence.labels[0].score\n",
    "        values[i] = int(sentence.labels[0].value)\n",
    "        confidences[i] = sentence.labels[0].score\n",
    "        i+=1\n",
    "\n",
    "    # convert to dataframe\n",
    "    results = pd.DataFrame({'label': values, 'confidence': confidences})        \n",
    "        \n",
    "    #test['yhat'] = values\n",
    "    #test['confidence'] = confidences\n",
    "        \n",
    "\n",
    "    # discard output, result is put into object itself\n",
    "    #_ = test['flair_sentence'].apply(lambda x: classifier.predict(x))\n",
    "\n",
    "    # sentence.labels returns a list containing flairs Label object that includes a dict. \n",
    "    # dig the values for predicted label + confidence from within the dict\n",
    "    # the 'value' returns a str, cast it to int\n",
    "    #test['yhat'] = test['flair_sentence'].apply(lambda x: int(x.labels[0].to_dict()['value']))\n",
    "\n",
    "    #test['confidence'] = test['flair_sentence'].apply(lambda x: x.labels[0].to_dict()['confidence'])\n",
    "\n",
    "    #results = pd.DataFrame(test[['yhat', 'confidence']])\n",
    "    #results.columns=['label','confidence']\n",
    "    #results.head()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# ADD RESULTS TO LIST\n",
    "\n",
    "    duration_predict = time.time() - start_pred\n",
    "    #print(f'Duration {duration:.2f} s')\n",
    "\n",
    "    savelist.append({'model': modelname,\n",
    "                'labels': results['label'],\n",
    "                'confidence': results['confidence'],\n",
    "                'traintime': duration_train,\n",
    "                'predtime3k': duration_predict,\n",
    "                'modeldesc': modeldesc\n",
    "               }\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `predict` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Using flairs Label object\n",
    "\n",
    "sentence.labels returns a flairs Label object:  flair.data.Label, type of [1 (1.0)]\n",
    "to access its values, use .to_dict()\n",
    "\n",
    "sentence.labels[0].to_dict()\n",
    "sent.labels[0].to_dict()['value']\n",
    "sent.labels[0].to_dict()['confidence']\n",
    "\n",
    "Label object is returned inside a list, so need to use [0] first to access it. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This adds the results into the Sentence-object itself!\n",
    "classifier.predict(sentence)\n",
    "\n",
    "sentence.labels\n",
    "[1 (1.0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "savelist = []\n",
    "modeldesc = '512LSTM_15epoch_non-bi'\n",
    "BATCH_SIZE=32\n",
    "#BATCH_SIZE=64\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EPOCHS = 60 # very fast on small models\n",
    "# skip 3k and over?\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "# Bert processes about 4 samples/second in training\n",
    "# smaller ones 800 samples per second"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word_embeddings = [ WordEmbeddings('en-crawl'),                 ]\n",
    "modelname = 'fasttext web-crawl'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To use ELMoEmbeddings, please first install with \"pip install allennlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove\n",
      "2020-05-17 10:08:14,933 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 10:08:14,934 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 10:08:14,934 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 10:08:14,934 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 10:08:21,970 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 237162.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 10:08:21,986 [b'0', b'3', b'1', b'4', b'2']\n",
      "2020-05-17 10:08:21,987 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 214341.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 10:08:22,005 [b'0', b'3', b'1', b'4', b'2']\n",
      "2020-05-17 10:08:22,009 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:22,011 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 10:08:22,012 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:22,013 Corpus: \"Corpus: 3000 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 10:08:22,014 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:22,016 Parameters:\n",
      "2020-05-17 10:08:22,016  - learning_rate: \"0.1\"\n",
      "2020-05-17 10:08:22,017  - mini_batch_size: \"32\"\n",
      "2020-05-17 10:08:22,018  - patience: \"5\"\n",
      "2020-05-17 10:08:22,019  - anneal_factor: \"0.5\"\n",
      "2020-05-17 10:08:22,019  - max_epochs: \"20\"\n",
      "2020-05-17 10:08:22,020  - shuffle: \"True\"\n",
      "2020-05-17 10:08:22,021  - train_with_dev: \"False\"\n",
      "2020-05-17 10:08:22,024  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 10:08:22,025 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:22,026 Model training base path: \".\"\n",
      "2020-05-17 10:08:22,027 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:22,027 Device: cuda:0\n",
      "2020-05-17 10:08:22,028 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:22,029 Embeddings storage mode: cpu\n",
      "2020-05-17 10:08:22,031 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 10:08:22,261 epoch 1 - iter 0/94 - loss 1.59496295 - samples/sec: 1267.10\n",
      "2020-05-17 10:08:23,956 epoch 1 - iter 9/94 - loss 1.51577960 - samples/sec: 170.68\n",
      "2020-05-17 10:08:25,313 epoch 1 - iter 18/94 - loss 1.50560645 - samples/sec: 213.37\n",
      "2020-05-17 10:08:26,648 epoch 1 - iter 27/94 - loss 1.50031741 - samples/sec: 216.80\n",
      "2020-05-17 10:08:28,262 epoch 1 - iter 36/94 - loss 1.48409058 - samples/sec: 179.31\n",
      "2020-05-17 10:08:29,583 epoch 1 - iter 45/94 - loss 1.47157822 - samples/sec: 219.23\n",
      "2020-05-17 10:08:30,890 epoch 1 - iter 54/94 - loss 1.46278243 - samples/sec: 221.62\n",
      "2020-05-17 10:08:32,203 epoch 1 - iter 63/94 - loss 1.45844254 - samples/sec: 220.67\n",
      "2020-05-17 10:08:33,484 epoch 1 - iter 72/94 - loss 1.45734484 - samples/sec: 226.05\n",
      "2020-05-17 10:08:34,790 epoch 1 - iter 81/94 - loss 1.45714777 - samples/sec: 221.59\n",
      "2020-05-17 10:08:36,095 epoch 1 - iter 90/94 - loss 1.45742075 - samples/sec: 221.96\n",
      "2020-05-17 10:08:36,523 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:36,525 EPOCH 1 done: loss 1.4572 - lr 0.1000\n",
      "2020-05-17 10:08:40,172 DEV : loss 1.4445219039916992 - score 0.318\n",
      "2020-05-17 10:08:40,280 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 10:08:43,930 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:44,038 epoch 2 - iter 0/94 - loss 1.43055642 - samples/sec: 2732.62\n",
      "2020-05-17 10:08:44,918 epoch 2 - iter 9/94 - loss 1.40463394 - samples/sec: 330.23\n",
      "2020-05-17 10:08:45,819 epoch 2 - iter 18/94 - loss 1.43121862 - samples/sec: 321.92\n",
      "2020-05-17 10:08:46,707 epoch 2 - iter 27/94 - loss 1.43193663 - samples/sec: 327.14\n",
      "2020-05-17 10:08:47,796 epoch 2 - iter 36/94 - loss 1.42722055 - samples/sec: 266.01\n",
      "2020-05-17 10:08:48,892 epoch 2 - iter 45/94 - loss 1.42128887 - samples/sec: 264.56\n",
      "2020-05-17 10:08:49,784 epoch 2 - iter 54/94 - loss 1.42119730 - samples/sec: 325.25\n",
      "2020-05-17 10:08:50,686 epoch 2 - iter 63/94 - loss 1.41948917 - samples/sec: 321.82\n",
      "2020-05-17 10:08:51,592 epoch 2 - iter 72/94 - loss 1.42336605 - samples/sec: 320.34\n",
      "2020-05-17 10:08:52,495 epoch 2 - iter 81/94 - loss 1.42612645 - samples/sec: 321.62\n",
      "2020-05-17 10:08:53,401 epoch 2 - iter 90/94 - loss 1.42556074 - samples/sec: 320.26\n",
      "2020-05-17 10:08:53,755 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:53,757 EPOCH 2 done: loss 1.4243 - lr 0.1000\n",
      "2020-05-17 10:08:55,118 DEV : loss 1.4261611700057983 - score 0.306\n",
      "2020-05-17 10:08:55,219 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 10:08:55,220 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:08:55,326 epoch 3 - iter 0/94 - loss 1.39430654 - samples/sec: 2761.49\n",
      "2020-05-17 10:08:56,268 epoch 3 - iter 9/94 - loss 1.46867095 - samples/sec: 307.97\n",
      "2020-05-17 10:08:57,264 epoch 3 - iter 18/94 - loss 1.44133677 - samples/sec: 291.20\n",
      "2020-05-17 10:08:58,210 epoch 3 - iter 27/94 - loss 1.43308726 - samples/sec: 306.61\n",
      "2020-05-17 10:08:59,108 epoch 3 - iter 36/94 - loss 1.42369184 - samples/sec: 323.38\n",
      "2020-05-17 10:08:59,981 epoch 3 - iter 45/94 - loss 1.41799903 - samples/sec: 332.60\n",
      "2020-05-17 10:09:00,876 epoch 3 - iter 54/94 - loss 1.41412725 - samples/sec: 324.19\n",
      "2020-05-17 10:09:01,796 epoch 3 - iter 63/94 - loss 1.41423548 - samples/sec: 316.04\n",
      "2020-05-17 10:09:02,676 epoch 3 - iter 72/94 - loss 1.41441477 - samples/sec: 332.02\n",
      "2020-05-17 10:09:03,578 epoch 3 - iter 81/94 - loss 1.41667176 - samples/sec: 321.93\n",
      "2020-05-17 10:09:04,488 epoch 3 - iter 90/94 - loss 1.41164056 - samples/sec: 320.93\n",
      "2020-05-17 10:09:04,778 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:04,779 EPOCH 3 done: loss 1.4094 - lr 0.1000\n",
      "2020-05-17 10:09:05,955 DEV : loss 1.4368653297424316 - score 0.312\n",
      "2020-05-17 10:09:06,057 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 10:09:06,058 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:06,163 epoch 4 - iter 0/94 - loss 1.42712772 - samples/sec: 2801.33\n",
      "2020-05-17 10:09:07,068 epoch 4 - iter 9/94 - loss 1.40582656 - samples/sec: 320.72\n",
      "2020-05-17 10:09:07,969 epoch 4 - iter 18/94 - loss 1.41741534 - samples/sec: 322.08\n",
      "2020-05-17 10:09:08,870 epoch 4 - iter 27/94 - loss 1.40022429 - samples/sec: 321.97\n",
      "2020-05-17 10:09:09,757 epoch 4 - iter 36/94 - loss 1.39449576 - samples/sec: 327.30\n",
      "2020-05-17 10:09:10,655 epoch 4 - iter 45/94 - loss 1.38771407 - samples/sec: 322.82\n",
      "2020-05-17 10:09:11,548 epoch 4 - iter 54/94 - loss 1.38993614 - samples/sec: 325.09\n",
      "2020-05-17 10:09:12,435 epoch 4 - iter 63/94 - loss 1.39243827 - samples/sec: 326.88\n",
      "2020-05-17 10:09:13,320 epoch 4 - iter 72/94 - loss 1.39366786 - samples/sec: 327.92\n",
      "2020-05-17 10:09:14,203 epoch 4 - iter 81/94 - loss 1.39581425 - samples/sec: 328.53\n",
      "2020-05-17 10:09:15,092 epoch 4 - iter 90/94 - loss 1.39679421 - samples/sec: 326.56\n",
      "2020-05-17 10:09:15,377 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:15,378 EPOCH 4 done: loss 1.3958 - lr 0.1000\n",
      "2020-05-17 10:09:16,547 DEV : loss 1.402854084968567 - score 0.392\n",
      "2020-05-17 10:09:16,650 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 10:09:20,033 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:20,142 epoch 5 - iter 0/94 - loss 1.39053404 - samples/sec: 2709.30\n",
      "2020-05-17 10:09:21,036 epoch 5 - iter 9/94 - loss 1.38370953 - samples/sec: 324.65\n",
      "2020-05-17 10:09:21,919 epoch 5 - iter 18/94 - loss 1.37405822 - samples/sec: 328.54\n",
      "2020-05-17 10:09:22,804 epoch 5 - iter 27/94 - loss 1.37223642 - samples/sec: 327.83\n",
      "2020-05-17 10:09:23,687 epoch 5 - iter 36/94 - loss 1.37486787 - samples/sec: 328.68\n",
      "2020-05-17 10:09:24,567 epoch 5 - iter 45/94 - loss 1.36380043 - samples/sec: 329.70\n",
      "2020-05-17 10:09:25,461 epoch 5 - iter 54/94 - loss 1.36899788 - samples/sec: 324.58\n",
      "2020-05-17 10:09:26,357 epoch 5 - iter 63/94 - loss 1.36843788 - samples/sec: 323.79\n",
      "2020-05-17 10:09:27,263 epoch 5 - iter 72/94 - loss 1.37516969 - samples/sec: 320.17\n",
      "2020-05-17 10:09:28,156 epoch 5 - iter 81/94 - loss 1.37738930 - samples/sec: 324.96\n",
      "2020-05-17 10:09:29,055 epoch 5 - iter 90/94 - loss 1.38165215 - samples/sec: 322.57\n",
      "2020-05-17 10:09:29,345 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:29,347 EPOCH 5 done: loss 1.3819 - lr 0.1000\n",
      "2020-05-17 10:09:30,533 DEV : loss 1.4017781019210815 - score 0.35\n",
      "2020-05-17 10:09:30,636 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 10:09:30,638 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:30,743 epoch 6 - iter 0/94 - loss 1.34217083 - samples/sec: 2777.22\n",
      "2020-05-17 10:09:31,655 epoch 6 - iter 9/94 - loss 1.39524231 - samples/sec: 320.37\n",
      "2020-05-17 10:09:32,581 epoch 6 - iter 18/94 - loss 1.38178041 - samples/sec: 313.99\n",
      "2020-05-17 10:09:33,484 epoch 6 - iter 27/94 - loss 1.38603533 - samples/sec: 321.98\n",
      "2020-05-17 10:09:34,405 epoch 6 - iter 36/94 - loss 1.38634723 - samples/sec: 315.55\n",
      "2020-05-17 10:09:35,319 epoch 6 - iter 45/94 - loss 1.39394252 - samples/sec: 317.33\n",
      "2020-05-17 10:09:36,216 epoch 6 - iter 54/94 - loss 1.39343031 - samples/sec: 323.30\n",
      "2020-05-17 10:09:37,117 epoch 6 - iter 63/94 - loss 1.38492846 - samples/sec: 322.21\n",
      "2020-05-17 10:09:38,012 epoch 6 - iter 72/94 - loss 1.38517570 - samples/sec: 324.09\n",
      "2020-05-17 10:09:38,904 epoch 6 - iter 81/94 - loss 1.38642562 - samples/sec: 325.26\n",
      "2020-05-17 10:09:39,801 epoch 6 - iter 90/94 - loss 1.38719774 - samples/sec: 324.07\n",
      "2020-05-17 10:09:40,093 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:40,094 EPOCH 6 done: loss 1.3873 - lr 0.1000\n",
      "2020-05-17 10:09:41,272 DEV : loss 1.3939441442489624 - score 0.388\n",
      "2020-05-17 10:09:41,375 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 10:09:41,377 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:41,482 epoch 7 - iter 0/94 - loss 1.28331327 - samples/sec: 2799.68\n",
      "2020-05-17 10:09:42,371 epoch 7 - iter 9/94 - loss 1.38189350 - samples/sec: 326.17\n",
      "2020-05-17 10:09:43,272 epoch 7 - iter 18/94 - loss 1.37046431 - samples/sec: 322.28\n",
      "2020-05-17 10:09:44,177 epoch 7 - iter 27/94 - loss 1.36497718 - samples/sec: 320.76\n",
      "2020-05-17 10:09:45,079 epoch 7 - iter 36/94 - loss 1.36470367 - samples/sec: 321.65\n",
      "2020-05-17 10:09:45,991 epoch 7 - iter 45/94 - loss 1.37532230 - samples/sec: 317.89\n",
      "2020-05-17 10:09:46,879 epoch 7 - iter 54/94 - loss 1.36863686 - samples/sec: 326.89\n",
      "2020-05-17 10:09:47,787 epoch 7 - iter 63/94 - loss 1.36880864 - samples/sec: 319.60\n",
      "2020-05-17 10:09:48,692 epoch 7 - iter 72/94 - loss 1.36973708 - samples/sec: 320.51\n",
      "2020-05-17 10:09:49,593 epoch 7 - iter 81/94 - loss 1.36911620 - samples/sec: 322.20\n",
      "2020-05-17 10:09:50,492 epoch 7 - iter 90/94 - loss 1.36796141 - samples/sec: 322.70\n",
      "2020-05-17 10:09:50,785 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:50,786 EPOCH 7 done: loss 1.3664 - lr 0.1000\n",
      "2020-05-17 10:09:51,966 DEV : loss 1.36984384059906 - score 0.41\n",
      "2020-05-17 10:09:52,068 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 10:09:55,381 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:09:55,492 epoch 8 - iter 0/94 - loss 1.22088397 - samples/sec: 2657.98\n",
      "2020-05-17 10:09:56,386 epoch 8 - iter 9/94 - loss 1.34370215 - samples/sec: 324.48\n",
      "2020-05-17 10:09:57,283 epoch 8 - iter 18/94 - loss 1.31373597 - samples/sec: 323.65\n",
      "2020-05-17 10:09:58,176 epoch 8 - iter 27/94 - loss 1.32437493 - samples/sec: 324.84\n",
      "2020-05-17 10:09:59,072 epoch 8 - iter 36/94 - loss 1.33341572 - samples/sec: 323.99\n",
      "2020-05-17 10:09:59,967 epoch 8 - iter 45/94 - loss 1.33867406 - samples/sec: 323.95\n",
      "2020-05-17 10:10:00,872 epoch 8 - iter 54/94 - loss 1.34700135 - samples/sec: 320.69\n",
      "2020-05-17 10:10:01,779 epoch 8 - iter 63/94 - loss 1.34930859 - samples/sec: 320.00\n",
      "2020-05-17 10:10:02,684 epoch 8 - iter 72/94 - loss 1.35194235 - samples/sec: 320.48\n",
      "2020-05-17 10:10:03,579 epoch 8 - iter 81/94 - loss 1.35200613 - samples/sec: 324.45\n",
      "2020-05-17 10:10:04,475 epoch 8 - iter 90/94 - loss 1.34702244 - samples/sec: 323.67\n",
      "2020-05-17 10:10:04,764 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:04,766 EPOCH 8 done: loss 1.3464 - lr 0.1000\n",
      "2020-05-17 10:10:05,947 DEV : loss 1.3218961954116821 - score 0.41\n",
      "2020-05-17 10:10:06,052 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 10:10:09,429 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:09,536 epoch 9 - iter 0/94 - loss 1.37064648 - samples/sec: 2751.23\n",
      "2020-05-17 10:10:10,431 epoch 9 - iter 9/94 - loss 1.30725843 - samples/sec: 324.08\n",
      "2020-05-17 10:10:11,340 epoch 9 - iter 18/94 - loss 1.35719139 - samples/sec: 319.33\n",
      "2020-05-17 10:10:12,243 epoch 9 - iter 27/94 - loss 1.34477586 - samples/sec: 321.40\n",
      "2020-05-17 10:10:13,148 epoch 9 - iter 36/94 - loss 1.34138733 - samples/sec: 320.63\n",
      "2020-05-17 10:10:14,040 epoch 9 - iter 45/94 - loss 1.34536768 - samples/sec: 325.40\n",
      "2020-05-17 10:10:14,938 epoch 9 - iter 54/94 - loss 1.34846810 - samples/sec: 323.42\n",
      "2020-05-17 10:10:15,847 epoch 9 - iter 63/94 - loss 1.34546003 - samples/sec: 319.26\n",
      "2020-05-17 10:10:16,751 epoch 9 - iter 72/94 - loss 1.33926435 - samples/sec: 321.21\n",
      "2020-05-17 10:10:17,652 epoch 9 - iter 81/94 - loss 1.33738378 - samples/sec: 322.31\n",
      "2020-05-17 10:10:18,548 epoch 9 - iter 90/94 - loss 1.34130224 - samples/sec: 323.69\n",
      "2020-05-17 10:10:18,840 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:18,841 EPOCH 9 done: loss 1.3391 - lr 0.1000\n",
      "2020-05-17 10:10:20,026 DEV : loss 1.4360896348953247 - score 0.398\n",
      "2020-05-17 10:10:20,130 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 10:10:20,131 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:20,235 epoch 10 - iter 0/94 - loss 1.46713459 - samples/sec: 2832.65\n",
      "2020-05-17 10:10:21,135 epoch 10 - iter 9/94 - loss 1.33182684 - samples/sec: 322.24\n",
      "2020-05-17 10:10:22,037 epoch 10 - iter 18/94 - loss 1.32803817 - samples/sec: 321.62\n",
      "2020-05-17 10:10:22,938 epoch 10 - iter 27/94 - loss 1.35096845 - samples/sec: 322.42\n",
      "2020-05-17 10:10:23,852 epoch 10 - iter 36/94 - loss 1.34868271 - samples/sec: 318.14\n",
      "2020-05-17 10:10:24,738 epoch 10 - iter 45/94 - loss 1.35882422 - samples/sec: 327.30\n",
      "2020-05-17 10:10:25,639 epoch 10 - iter 54/94 - loss 1.36956887 - samples/sec: 322.80\n",
      "2020-05-17 10:10:26,544 epoch 10 - iter 63/94 - loss 1.37001786 - samples/sec: 320.76\n",
      "2020-05-17 10:10:27,450 epoch 10 - iter 72/94 - loss 1.35652092 - samples/sec: 319.93\n",
      "2020-05-17 10:10:28,340 epoch 10 - iter 81/94 - loss 1.35556128 - samples/sec: 326.37\n",
      "2020-05-17 10:10:29,244 epoch 10 - iter 90/94 - loss 1.35567405 - samples/sec: 320.99\n",
      "2020-05-17 10:10:29,536 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:29,537 EPOCH 10 done: loss 1.3511 - lr 0.1000\n",
      "2020-05-17 10:10:30,734 DEV : loss 1.322692632675171 - score 0.424\n",
      "2020-05-17 10:10:30,838 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 10:10:34,155 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:34,268 epoch 11 - iter 0/94 - loss 1.36714983 - samples/sec: 2602.35\n",
      "2020-05-17 10:10:35,164 epoch 11 - iter 9/94 - loss 1.37937005 - samples/sec: 323.66\n",
      "2020-05-17 10:10:36,067 epoch 11 - iter 18/94 - loss 1.34996058 - samples/sec: 321.22\n",
      "2020-05-17 10:10:36,973 epoch 11 - iter 27/94 - loss 1.32613104 - samples/sec: 320.41\n",
      "2020-05-17 10:10:37,865 epoch 11 - iter 36/94 - loss 1.35849620 - samples/sec: 325.19\n",
      "2020-05-17 10:10:38,760 epoch 11 - iter 45/94 - loss 1.34990767 - samples/sec: 324.04\n",
      "2020-05-17 10:10:39,671 epoch 11 - iter 54/94 - loss 1.34459530 - samples/sec: 321.14\n",
      "2020-05-17 10:10:40,573 epoch 11 - iter 63/94 - loss 1.33604246 - samples/sec: 322.58\n",
      "2020-05-17 10:10:41,477 epoch 11 - iter 72/94 - loss 1.33855082 - samples/sec: 321.38\n",
      "2020-05-17 10:10:42,377 epoch 11 - iter 81/94 - loss 1.33452759 - samples/sec: 322.96\n",
      "2020-05-17 10:10:43,263 epoch 11 - iter 90/94 - loss 1.32556641 - samples/sec: 327.52\n",
      "2020-05-17 10:10:43,554 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:43,555 EPOCH 11 done: loss 1.3240 - lr 0.1000\n",
      "2020-05-17 10:10:44,747 DEV : loss 1.3406645059585571 - score 0.434\n",
      "2020-05-17 10:10:44,851 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 10:10:48,411 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:48,518 epoch 12 - iter 0/94 - loss 1.07683742 - samples/sec: 2743.56\n",
      "2020-05-17 10:10:49,418 epoch 12 - iter 9/94 - loss 1.26858938 - samples/sec: 322.37\n",
      "2020-05-17 10:10:50,319 epoch 12 - iter 18/94 - loss 1.28978603 - samples/sec: 322.30\n",
      "2020-05-17 10:10:51,204 epoch 12 - iter 27/94 - loss 1.27841880 - samples/sec: 327.57\n",
      "2020-05-17 10:10:52,099 epoch 12 - iter 36/94 - loss 1.29187812 - samples/sec: 324.15\n",
      "2020-05-17 10:10:52,996 epoch 12 - iter 45/94 - loss 1.30437198 - samples/sec: 323.63\n",
      "2020-05-17 10:10:53,907 epoch 12 - iter 54/94 - loss 1.30812118 - samples/sec: 318.53\n",
      "2020-05-17 10:10:54,801 epoch 12 - iter 63/94 - loss 1.31728718 - samples/sec: 324.62\n",
      "2020-05-17 10:10:55,717 epoch 12 - iter 72/94 - loss 1.32917837 - samples/sec: 316.59\n",
      "2020-05-17 10:10:56,625 epoch 12 - iter 81/94 - loss 1.34399532 - samples/sec: 320.24\n",
      "2020-05-17 10:10:57,540 epoch 12 - iter 90/94 - loss 1.34504611 - samples/sec: 317.28\n",
      "2020-05-17 10:10:57,834 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:57,835 EPOCH 12 done: loss 1.3433 - lr 0.1000\n",
      "2020-05-17 10:10:59,039 DEV : loss 1.4225733280181885 - score 0.394\n",
      "2020-05-17 10:10:59,143 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 10:10:59,144 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:10:59,257 epoch 13 - iter 0/94 - loss 1.28969169 - samples/sec: 2586.74\n",
      "2020-05-17 10:11:00,164 epoch 13 - iter 9/94 - loss 1.28310403 - samples/sec: 319.94\n",
      "2020-05-17 10:11:01,064 epoch 13 - iter 18/94 - loss 1.33831573 - samples/sec: 322.27\n",
      "2020-05-17 10:11:01,980 epoch 13 - iter 27/94 - loss 1.34682389 - samples/sec: 317.13\n",
      "2020-05-17 10:11:02,890 epoch 13 - iter 36/94 - loss 1.31696305 - samples/sec: 319.29\n",
      "2020-05-17 10:11:03,790 epoch 13 - iter 45/94 - loss 1.33214780 - samples/sec: 322.55\n",
      "2020-05-17 10:11:04,668 epoch 13 - iter 54/94 - loss 1.32498982 - samples/sec: 330.54\n",
      "2020-05-17 10:11:05,567 epoch 13 - iter 63/94 - loss 1.31920311 - samples/sec: 322.40\n",
      "2020-05-17 10:11:06,472 epoch 13 - iter 72/94 - loss 1.33093444 - samples/sec: 320.70\n",
      "2020-05-17 10:11:07,371 epoch 13 - iter 81/94 - loss 1.33020790 - samples/sec: 322.61\n",
      "2020-05-17 10:11:08,278 epoch 13 - iter 90/94 - loss 1.33468927 - samples/sec: 320.46\n",
      "2020-05-17 10:11:08,574 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:08,575 EPOCH 13 done: loss 1.3327 - lr 0.1000\n",
      "2020-05-17 10:11:09,774 DEV : loss 1.28177809715271 - score 0.468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 10:11:09,875 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 10:11:13,279 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:13,391 epoch 14 - iter 0/94 - loss 1.42073476 - samples/sec: 2628.20\n",
      "2020-05-17 10:11:14,302 epoch 14 - iter 9/94 - loss 1.42645644 - samples/sec: 318.68\n",
      "2020-05-17 10:11:15,199 epoch 14 - iter 18/94 - loss 1.37679923 - samples/sec: 323.17\n",
      "2020-05-17 10:11:16,114 epoch 14 - iter 27/94 - loss 1.36944697 - samples/sec: 317.29\n",
      "2020-05-17 10:11:17,015 epoch 14 - iter 36/94 - loss 1.34815915 - samples/sec: 321.79\n",
      "2020-05-17 10:11:17,919 epoch 14 - iter 45/94 - loss 1.35436088 - samples/sec: 321.02\n",
      "2020-05-17 10:11:18,821 epoch 14 - iter 54/94 - loss 1.35801115 - samples/sec: 321.86\n",
      "2020-05-17 10:11:19,744 epoch 14 - iter 63/94 - loss 1.34375231 - samples/sec: 314.18\n",
      "2020-05-17 10:11:20,651 epoch 14 - iter 72/94 - loss 1.32846655 - samples/sec: 320.06\n",
      "2020-05-17 10:11:21,549 epoch 14 - iter 81/94 - loss 1.32902970 - samples/sec: 323.08\n",
      "2020-05-17 10:11:22,466 epoch 14 - iter 90/94 - loss 1.33558377 - samples/sec: 318.88\n",
      "2020-05-17 10:11:22,754 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:22,755 EPOCH 14 done: loss 1.3351 - lr 0.1000\n",
      "2020-05-17 10:11:23,946 DEV : loss 1.3822141885757446 - score 0.372\n",
      "2020-05-17 10:11:24,048 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 10:11:24,049 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:24,155 epoch 15 - iter 0/94 - loss 1.33605731 - samples/sec: 2733.39\n",
      "2020-05-17 10:11:25,065 epoch 15 - iter 9/94 - loss 1.24853213 - samples/sec: 318.63\n",
      "2020-05-17 10:11:25,972 epoch 15 - iter 18/94 - loss 1.35829330 - samples/sec: 319.67\n",
      "2020-05-17 10:11:26,879 epoch 15 - iter 27/94 - loss 1.34442766 - samples/sec: 319.89\n",
      "2020-05-17 10:11:27,789 epoch 15 - iter 36/94 - loss 1.36493456 - samples/sec: 318.64\n",
      "2020-05-17 10:11:28,693 epoch 15 - iter 45/94 - loss 1.35099202 - samples/sec: 321.43\n",
      "2020-05-17 10:11:29,589 epoch 15 - iter 54/94 - loss 1.34222845 - samples/sec: 324.36\n",
      "2020-05-17 10:11:30,466 epoch 15 - iter 63/94 - loss 1.32686090 - samples/sec: 331.10\n",
      "2020-05-17 10:11:31,359 epoch 15 - iter 72/94 - loss 1.31574602 - samples/sec: 325.77\n",
      "2020-05-17 10:11:32,300 epoch 15 - iter 81/94 - loss 1.32246281 - samples/sec: 308.41\n",
      "2020-05-17 10:11:33,194 epoch 15 - iter 90/94 - loss 1.32507728 - samples/sec: 324.59\n",
      "2020-05-17 10:11:33,485 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:33,487 EPOCH 15 done: loss 1.3240 - lr 0.1000\n",
      "2020-05-17 10:11:34,690 DEV : loss 1.2331252098083496 - score 0.518\n",
      "2020-05-17 10:11:34,791 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 10:11:38,191 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:38,296 epoch 16 - iter 0/94 - loss 1.09819591 - samples/sec: 2791.16\n",
      "2020-05-17 10:11:39,203 epoch 16 - iter 9/94 - loss 1.30176060 - samples/sec: 319.96\n",
      "2020-05-17 10:11:41,679 epoch 16 - iter 18/94 - loss 1.33560201 - samples/sec: 116.61\n",
      "2020-05-17 10:11:42,586 epoch 16 - iter 27/94 - loss 1.34706080 - samples/sec: 320.44\n",
      "2020-05-17 10:11:43,499 epoch 16 - iter 36/94 - loss 1.32736238 - samples/sec: 318.61\n",
      "2020-05-17 10:11:44,393 epoch 16 - iter 45/94 - loss 1.34560430 - samples/sec: 324.51\n",
      "2020-05-17 10:11:45,291 epoch 16 - iter 54/94 - loss 1.34692462 - samples/sec: 322.83\n",
      "2020-05-17 10:11:46,188 epoch 16 - iter 63/94 - loss 1.32807333 - samples/sec: 323.62\n",
      "2020-05-17 10:11:47,076 epoch 16 - iter 72/94 - loss 1.34130049 - samples/sec: 326.90\n",
      "2020-05-17 10:11:47,979 epoch 16 - iter 81/94 - loss 1.33643548 - samples/sec: 321.33\n",
      "2020-05-17 10:11:48,880 epoch 16 - iter 90/94 - loss 1.33406505 - samples/sec: 322.06\n",
      "2020-05-17 10:11:49,172 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:49,174 EPOCH 16 done: loss 1.3322 - lr 0.1000\n",
      "2020-05-17 10:11:50,358 DEV : loss 1.2321969270706177 - score 0.484\n",
      "2020-05-17 10:11:50,460 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 10:11:50,461 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:50,567 epoch 17 - iter 0/94 - loss 1.36682630 - samples/sec: 2792.41\n",
      "2020-05-17 10:11:51,473 epoch 17 - iter 9/94 - loss 1.22731857 - samples/sec: 320.26\n",
      "2020-05-17 10:11:52,365 epoch 17 - iter 18/94 - loss 1.25227658 - samples/sec: 325.04\n",
      "2020-05-17 10:11:53,271 epoch 17 - iter 27/94 - loss 1.26776962 - samples/sec: 320.54\n",
      "2020-05-17 10:11:54,175 epoch 17 - iter 36/94 - loss 1.28192628 - samples/sec: 320.85\n",
      "2020-05-17 10:11:55,080 epoch 17 - iter 45/94 - loss 1.28540241 - samples/sec: 320.76\n",
      "2020-05-17 10:11:55,960 epoch 17 - iter 54/94 - loss 1.27783243 - samples/sec: 329.78\n",
      "2020-05-17 10:11:56,863 epoch 17 - iter 63/94 - loss 1.27832711 - samples/sec: 321.96\n",
      "2020-05-17 10:11:57,767 epoch 17 - iter 72/94 - loss 1.28351227 - samples/sec: 321.05\n",
      "2020-05-17 10:11:58,678 epoch 17 - iter 81/94 - loss 1.28984766 - samples/sec: 318.58\n",
      "2020-05-17 10:11:59,571 epoch 17 - iter 90/94 - loss 1.29135216 - samples/sec: 324.82\n",
      "2020-05-17 10:11:59,866 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:11:59,867 EPOCH 17 done: loss 1.2924 - lr 0.1000\n",
      "2020-05-17 10:12:01,051 DEV : loss 1.2561883926391602 - score 0.488\n",
      "2020-05-17 10:12:01,154 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 10:12:01,156 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:12:01,262 epoch 18 - iter 0/94 - loss 1.18745208 - samples/sec: 2765.48\n",
      "2020-05-17 10:12:02,170 epoch 18 - iter 9/94 - loss 1.28475887 - samples/sec: 319.64\n",
      "2020-05-17 10:12:03,076 epoch 18 - iter 18/94 - loss 1.28914185 - samples/sec: 320.33\n",
      "2020-05-17 10:12:03,975 epoch 18 - iter 27/94 - loss 1.32267907 - samples/sec: 322.75\n",
      "2020-05-17 10:12:04,871 epoch 18 - iter 36/94 - loss 1.32221948 - samples/sec: 324.44\n",
      "2020-05-17 10:12:05,768 epoch 18 - iter 45/94 - loss 1.34070201 - samples/sec: 323.41\n",
      "2020-05-17 10:12:06,667 epoch 18 - iter 54/94 - loss 1.34624468 - samples/sec: 322.91\n",
      "2020-05-17 10:12:07,552 epoch 18 - iter 63/94 - loss 1.35389246 - samples/sec: 327.96\n",
      "2020-05-17 10:12:08,448 epoch 18 - iter 72/94 - loss 1.35519869 - samples/sec: 324.08\n",
      "2020-05-17 10:12:09,344 epoch 18 - iter 81/94 - loss 1.33660651 - samples/sec: 323.67\n",
      "2020-05-17 10:12:10,239 epoch 18 - iter 90/94 - loss 1.32456809 - samples/sec: 324.25\n",
      "2020-05-17 10:12:10,526 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:12:10,528 EPOCH 18 done: loss 1.3299 - lr 0.1000\n",
      "2020-05-17 10:12:11,720 DEV : loss 1.3650623559951782 - score 0.396\n",
      "2020-05-17 10:12:11,823 BAD EPOCHS (no improvement): 3\n",
      "2020-05-17 10:12:11,824 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:12:11,923 epoch 19 - iter 0/94 - loss 1.50270152 - samples/sec: 2953.79\n",
      "2020-05-17 10:12:12,807 epoch 19 - iter 9/94 - loss 1.40082226 - samples/sec: 328.70\n",
      "2020-05-17 10:12:13,691 epoch 19 - iter 18/94 - loss 1.36890327 - samples/sec: 328.15\n",
      "2020-05-17 10:12:14,592 epoch 19 - iter 27/94 - loss 1.36517497 - samples/sec: 322.26\n",
      "2020-05-17 10:12:15,488 epoch 19 - iter 36/94 - loss 1.38507017 - samples/sec: 323.85\n",
      "2020-05-17 10:12:16,404 epoch 19 - iter 45/94 - loss 1.37266356 - samples/sec: 316.82\n",
      "2020-05-17 10:12:17,320 epoch 19 - iter 54/94 - loss 1.36821994 - samples/sec: 316.88\n",
      "2020-05-17 10:12:18,231 epoch 19 - iter 63/94 - loss 1.36586516 - samples/sec: 319.00\n",
      "2020-05-17 10:12:19,186 epoch 19 - iter 72/94 - loss 1.35586859 - samples/sec: 304.40\n",
      "2020-05-17 10:12:20,104 epoch 19 - iter 81/94 - loss 1.34657798 - samples/sec: 316.60\n",
      "2020-05-17 10:12:21,179 epoch 19 - iter 90/94 - loss 1.34229112 - samples/sec: 270.13\n",
      "2020-05-17 10:12:21,490 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:12:21,492 EPOCH 19 done: loss 1.3408 - lr 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 10:12:22,727 DEV : loss 1.22150456905365 - score 0.508\n",
      "2020-05-17 10:12:22,830 BAD EPOCHS (no improvement): 4\n",
      "2020-05-17 10:12:22,832 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:12:22,935 epoch 20 - iter 0/94 - loss 1.20622087 - samples/sec: 2836.30\n",
      "2020-05-17 10:12:23,863 epoch 20 - iter 9/94 - loss 1.27646676 - samples/sec: 312.81\n",
      "2020-05-17 10:12:24,824 epoch 20 - iter 18/94 - loss 1.24721436 - samples/sec: 301.65\n",
      "2020-05-17 10:12:25,740 epoch 20 - iter 27/94 - loss 1.26739571 - samples/sec: 316.62\n",
      "2020-05-17 10:12:26,680 epoch 20 - iter 36/94 - loss 1.28710094 - samples/sec: 309.02\n",
      "2020-05-17 10:12:27,662 epoch 20 - iter 45/94 - loss 1.29483097 - samples/sec: 295.41\n",
      "2020-05-17 10:12:28,600 epoch 20 - iter 54/94 - loss 1.28565171 - samples/sec: 309.45\n",
      "2020-05-17 10:12:29,488 epoch 20 - iter 63/94 - loss 1.28401827 - samples/sec: 326.81\n",
      "2020-05-17 10:12:30,385 epoch 20 - iter 72/94 - loss 1.29490304 - samples/sec: 323.71\n",
      "2020-05-17 10:12:31,285 epoch 20 - iter 81/94 - loss 1.30090506 - samples/sec: 322.59\n",
      "2020-05-17 10:12:32,205 epoch 20 - iter 90/94 - loss 1.29124100 - samples/sec: 315.54\n",
      "2020-05-17 10:12:32,512 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:12:32,513 EPOCH 20 done: loss 1.2906 - lr 0.1000\n",
      "2020-05-17 10:12:33,922 DEV : loss 1.2455295324325562 - score 0.494\n",
      "2020-05-17 10:12:34,031 BAD EPOCHS (no improvement): 5\n",
      "2020-05-17 10:12:37,552 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 10:12:37,554 Testing using best model ...\n",
      "2020-05-17 10:12:37,555 loading file best-model.pt\n",
      "2020-05-17 10:12:38,854 0.512\t0.512\t0.512\n",
      "2020-05-17 10:12:38,856 \n",
      "MICRO_AVG: acc 0.3441 - f1-score 0.512\n",
      "MACRO_AVG: acc 0.2114 - f1-score 0.30013999999999996\n",
      "0          tp: 124 - fp: 103 - fn: 22 - tn: 251 - precision: 0.5463 - recall: 0.8493 - accuracy: 0.4980 - f1-score: 0.6649\n",
      "1          tp: 0 - fp: 1 - fn: 88 - tn: 411 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2          tp: 0 - fp: 0 - fn: 10 - tn: 490 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "3          tp: 115 - fp: 116 - fn: 43 - tn: 226 - precision: 0.4978 - recall: 0.7278 - accuracy: 0.4197 - f1-score: 0.5912\n",
      "4          tp: 17 - fp: 24 - fn: 81 - tn: 378 - precision: 0.4146 - recall: 0.1735 - accuracy: 0.1393 - f1-score: 0.2446\n",
      "2020-05-17 10:12:38,857 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "265.5224142074585\n"
     ]
    }
   ],
   "source": [
    "# test time with single\n",
    "total_time = time.time()\n",
    "\n",
    "word_embeddings = [ WordEmbeddings('glove'),              ]\n",
    "modelname = 'glove'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "# word_embeddings = [ ELMoEmbeddings('original')              ]\n",
    "# modelname = 'elmo'\n",
    "# train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "\n",
    "print(time.time() - total_time)\n",
    "\n",
    "# training time 2k char, test 3k sample , batch 64\n",
    "# train, dev: 100 + 100 , time: 69 s glove\n",
    "#                                  s elmo: very long - 10min+ then stopped with break\n",
    "\n",
    "# test-set to 100 also, char to 1.5k\n",
    "# elmo only 82 sec   embedding_storagemode = gpu  -> 84.7 sec. 3 sec more than cpu\n",
    "\n",
    "\n",
    "\n",
    "# prediction takes longer time than training of model itself.\n",
    "\n",
    "# test set back to 3k:   \n",
    "# batch prediciton: 166 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove\n",
      "2020-05-17 14:32:07,967 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 14:32:07,968 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 14:32:07,969 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 14:32:07,970 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:32:19,461 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 268876.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:32:19,515 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 14:32:19,516 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 267239.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:32:19,571 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 14:32:19,575 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:32:19,576 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 14:32:19,577 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:32:19,578 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 14:32:19,578 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:32:19,579 Parameters:\n",
      "2020-05-17 14:32:19,580  - learning_rate: \"0.1\"\n",
      "2020-05-17 14:32:19,580  - mini_batch_size: \"32\"\n",
      "2020-05-17 14:32:19,581  - patience: \"5\"\n",
      "2020-05-17 14:32:19,582  - anneal_factor: \"0.5\"\n",
      "2020-05-17 14:32:19,583  - max_epochs: \"15\"\n",
      "2020-05-17 14:32:19,583  - shuffle: \"True\"\n",
      "2020-05-17 14:32:19,584  - train_with_dev: \"False\"\n",
      "2020-05-17 14:32:19,585  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 14:32:19,585 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:32:19,586 Model training base path: \".\"\n",
      "2020-05-17 14:32:19,586 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:32:19,587 Device: cuda:0\n",
      "2020-05-17 14:32:19,588 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:32:19,588 Embeddings storage mode: cpu\n",
      "2020-05-17 14:32:19,589 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:32:19,832 epoch 1 - iter 0/429 - loss 1.60230374 - samples/sec: 5605.66\n",
      "2020-05-17 14:32:24,998 epoch 1 - iter 42/429 - loss 1.47056235 - samples/sec: 260.57\n",
      "2020-05-17 14:32:30,367 epoch 1 - iter 84/429 - loss 1.46664594 - samples/sec: 250.67\n",
      "2020-05-17 14:32:35,594 epoch 1 - iter 126/429 - loss 1.46051915 - samples/sec: 257.53\n",
      "2020-05-17 14:32:42,115 epoch 1 - iter 168/429 - loss 1.45670071 - samples/sec: 206.32\n",
      "2020-05-17 14:32:47,677 epoch 1 - iter 210/429 - loss 1.44830669 - samples/sec: 241.95\n",
      "2020-05-17 14:32:53,029 epoch 1 - iter 252/429 - loss 1.44123269 - samples/sec: 251.49\n",
      "2020-05-17 14:32:58,381 epoch 1 - iter 294/429 - loss 1.43721635 - samples/sec: 251.46\n",
      "2020-05-17 14:33:03,925 epoch 1 - iter 336/429 - loss 1.43126203 - samples/sec: 242.78\n",
      "2020-05-17 14:33:09,539 epoch 1 - iter 378/429 - loss 1.42520460 - samples/sec: 239.74\n",
      "2020-05-17 14:33:15,205 epoch 1 - iter 420/429 - loss 1.41864967 - samples/sec: 237.53\n",
      "2020-05-17 14:33:16,206 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:33:16,207 EPOCH 1 done: loss 1.4183 - lr 0.1000\n",
      "2020-05-17 14:33:17,988 DEV : loss 1.3825790882110596 - score 0.378\n",
      "2020-05-17 14:33:18,046 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:33:21,182 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:33:21,253 epoch 2 - iter 0/429 - loss 1.31067395 - samples/sec: 19857.91\n",
      "2020-05-17 14:33:23,882 epoch 2 - iter 42/429 - loss 1.36308493 - samples/sec: 512.78\n",
      "2020-05-17 14:33:26,674 epoch 2 - iter 84/429 - loss 1.36795719 - samples/sec: 482.45\n",
      "2020-05-17 14:33:29,513 epoch 2 - iter 126/429 - loss 1.35717346 - samples/sec: 475.46\n",
      "2020-05-17 14:33:33,742 epoch 2 - iter 168/429 - loss 1.35454781 - samples/sec: 318.36\n",
      "2020-05-17 14:33:36,489 epoch 2 - iter 210/429 - loss 1.35187551 - samples/sec: 490.87\n",
      "2020-05-17 14:33:39,473 epoch 2 - iter 252/429 - loss 1.34743849 - samples/sec: 451.46\n",
      "2020-05-17 14:33:42,315 epoch 2 - iter 294/429 - loss 1.34670688 - samples/sec: 474.08\n",
      "2020-05-17 14:33:45,266 epoch 2 - iter 336/429 - loss 1.35577561 - samples/sec: 457.18\n",
      "2020-05-17 14:33:48,082 epoch 2 - iter 378/429 - loss 1.35480325 - samples/sec: 478.69\n",
      "2020-05-17 14:33:51,044 epoch 2 - iter 420/429 - loss 1.35090264 - samples/sec: 454.89\n",
      "2020-05-17 14:33:51,613 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:33:51,615 EPOCH 2 done: loss 1.3517 - lr 0.1000\n",
      "2020-05-17 14:33:52,343 DEV : loss 1.2313474416732788 - score 0.494\n",
      "2020-05-17 14:33:52,402 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:33:55,512 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:33:55,591 epoch 3 - iter 0/429 - loss 1.23335469 - samples/sec: 17799.41\n",
      "2020-05-17 14:33:58,395 epoch 3 - iter 42/429 - loss 1.32509932 - samples/sec: 480.78\n",
      "2020-05-17 14:34:01,275 epoch 3 - iter 84/429 - loss 1.31664747 - samples/sec: 467.89\n",
      "2020-05-17 14:34:04,127 epoch 3 - iter 126/429 - loss 1.30376438 - samples/sec: 472.57\n",
      "2020-05-17 14:34:06,947 epoch 3 - iter 168/429 - loss 1.30815974 - samples/sec: 477.81\n",
      "2020-05-17 14:34:09,847 epoch 3 - iter 210/429 - loss 1.30816773 - samples/sec: 464.62\n",
      "2020-05-17 14:34:12,678 epoch 3 - iter 252/429 - loss 1.30547398 - samples/sec: 476.16\n",
      "2020-05-17 14:34:15,448 epoch 3 - iter 294/429 - loss 1.29885085 - samples/sec: 486.53\n",
      "2020-05-17 14:34:18,240 epoch 3 - iter 336/429 - loss 1.30232748 - samples/sec: 483.03\n",
      "2020-05-17 14:34:21,104 epoch 3 - iter 378/429 - loss 1.29788370 - samples/sec: 471.01\n",
      "2020-05-17 14:34:23,939 epoch 3 - iter 420/429 - loss 1.29112541 - samples/sec: 475.43\n",
      "2020-05-17 14:34:24,507 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:34:24,509 EPOCH 3 done: loss 1.2925 - lr 0.1000\n",
      "2020-05-17 14:34:25,273 DEV : loss 1.193892240524292 - score 0.534\n",
      "2020-05-17 14:34:25,332 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:34:28,480 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:34:28,562 epoch 4 - iter 0/429 - loss 1.07775354 - samples/sec: 17204.83\n",
      "2020-05-17 14:34:31,489 epoch 4 - iter 42/429 - loss 1.24564571 - samples/sec: 460.29\n",
      "2020-05-17 14:34:34,433 epoch 4 - iter 84/429 - loss 1.23742902 - samples/sec: 457.71\n",
      "2020-05-17 14:34:37,304 epoch 4 - iter 126/429 - loss 1.23636475 - samples/sec: 469.50\n",
      "2020-05-17 14:34:40,106 epoch 4 - iter 168/429 - loss 1.24178309 - samples/sec: 480.99\n",
      "2020-05-17 14:34:42,937 epoch 4 - iter 210/429 - loss 1.24940039 - samples/sec: 476.09\n",
      "2020-05-17 14:34:45,780 epoch 4 - iter 252/429 - loss 1.24887383 - samples/sec: 474.17\n",
      "2020-05-17 14:34:48,682 epoch 4 - iter 294/429 - loss 1.24964770 - samples/sec: 464.29\n",
      "2020-05-17 14:34:51,618 epoch 4 - iter 336/429 - loss 1.24912923 - samples/sec: 459.09\n",
      "2020-05-17 14:34:54,458 epoch 4 - iter 378/429 - loss 1.24383994 - samples/sec: 474.54\n",
      "2020-05-17 14:34:57,297 epoch 4 - iter 420/429 - loss 1.24392756 - samples/sec: 474.66\n",
      "2020-05-17 14:34:57,842 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:34:57,843 EPOCH 4 done: loss 1.2461 - lr 0.1000\n",
      "2020-05-17 14:34:58,610 DEV : loss 1.144034743309021 - score 0.53\n",
      "2020-05-17 14:34:58,675 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:34:58,677 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:34:58,747 epoch 5 - iter 0/429 - loss 1.29288340 - samples/sec: 19637.10\n",
      "2020-05-17 14:35:01,730 epoch 5 - iter 42/429 - loss 1.24736156 - samples/sec: 451.77\n",
      "2020-05-17 14:35:04,691 epoch 5 - iter 84/429 - loss 1.23189903 - samples/sec: 455.13\n",
      "2020-05-17 14:35:07,605 epoch 5 - iter 126/429 - loss 1.22974533 - samples/sec: 462.40\n",
      "2020-05-17 14:35:10,755 epoch 5 - iter 168/429 - loss 1.22865306 - samples/sec: 427.91\n",
      "2020-05-17 14:35:13,715 epoch 5 - iter 210/429 - loss 1.22222396 - samples/sec: 455.22\n",
      "2020-05-17 14:35:16,689 epoch 5 - iter 252/429 - loss 1.21158309 - samples/sec: 453.04\n",
      "2020-05-17 14:35:19,594 epoch 5 - iter 294/429 - loss 1.20653208 - samples/sec: 463.98\n",
      "2020-05-17 14:35:22,461 epoch 5 - iter 336/429 - loss 1.20743226 - samples/sec: 470.96\n",
      "2020-05-17 14:35:25,323 epoch 5 - iter 378/429 - loss 1.20539612 - samples/sec: 471.32\n",
      "2020-05-17 14:35:28,226 epoch 5 - iter 420/429 - loss 1.20806820 - samples/sec: 464.49\n",
      "2020-05-17 14:35:28,771 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:35:28,773 EPOCH 5 done: loss 1.2073 - lr 0.1000\n",
      "2020-05-17 14:35:29,524 DEV : loss 1.2831910848617554 - score 0.496\n",
      "2020-05-17 14:35:29,583 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 14:35:29,584 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:35:29,655 epoch 6 - iter 0/429 - loss 1.29205894 - samples/sec: 19537.33\n",
      "2020-05-17 14:35:32,478 epoch 6 - iter 42/429 - loss 1.17118507 - samples/sec: 477.33\n",
      "2020-05-17 14:35:35,295 epoch 6 - iter 84/429 - loss 1.17510651 - samples/sec: 478.45\n",
      "2020-05-17 14:35:38,126 epoch 6 - iter 126/429 - loss 1.18804843 - samples/sec: 476.15\n",
      "2020-05-17 14:35:40,957 epoch 6 - iter 168/429 - loss 1.19235129 - samples/sec: 476.15\n",
      "2020-05-17 14:35:43,854 epoch 6 - iter 210/429 - loss 1.18495110 - samples/sec: 465.12\n",
      "2020-05-17 14:35:46,693 epoch 6 - iter 252/429 - loss 1.18834647 - samples/sec: 474.65\n",
      "2020-05-17 14:35:49,467 epoch 6 - iter 294/429 - loss 1.18513317 - samples/sec: 485.96\n",
      "2020-05-17 14:35:52,295 epoch 6 - iter 336/429 - loss 1.18544023 - samples/sec: 476.55\n",
      "2020-05-17 14:35:55,225 epoch 6 - iter 378/429 - loss 1.18410373 - samples/sec: 459.91\n",
      "2020-05-17 14:35:58,073 epoch 6 - iter 420/429 - loss 1.18456794 - samples/sec: 473.15\n",
      "2020-05-17 14:35:58,657 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:35:58,659 EPOCH 6 done: loss 1.1849 - lr 0.1000\n",
      "2020-05-17 14:35:59,408 DEV : loss 1.1719413995742798 - score 0.548\n",
      "2020-05-17 14:35:59,466 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:36:02,597 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:36:02,682 epoch 7 - iter 0/429 - loss 1.18112683 - samples/sec: 16274.03\n",
      "2020-05-17 14:36:05,519 epoch 7 - iter 42/429 - loss 1.17385251 - samples/sec: 475.14\n",
      "2020-05-17 14:36:08,330 epoch 7 - iter 84/429 - loss 1.17485693 - samples/sec: 479.46\n",
      "2020-05-17 14:36:11,159 epoch 7 - iter 126/429 - loss 1.16298651 - samples/sec: 476.55\n",
      "2020-05-17 14:36:13,994 epoch 7 - iter 168/429 - loss 1.16565673 - samples/sec: 475.40\n",
      "2020-05-17 14:36:16,798 epoch 7 - iter 210/429 - loss 1.16940165 - samples/sec: 480.63\n",
      "2020-05-17 14:36:19,626 epoch 7 - iter 252/429 - loss 1.16260810 - samples/sec: 476.57\n",
      "2020-05-17 14:36:22,454 epoch 7 - iter 294/429 - loss 1.16253845 - samples/sec: 476.71\n",
      "2020-05-17 14:36:25,251 epoch 7 - iter 336/429 - loss 1.16698151 - samples/sec: 481.98\n",
      "2020-05-17 14:36:28,058 epoch 7 - iter 378/429 - loss 1.16269422 - samples/sec: 480.00\n",
      "2020-05-17 14:36:30,897 epoch 7 - iter 420/429 - loss 1.16199907 - samples/sec: 474.82\n",
      "2020-05-17 14:36:31,434 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:36:31,436 EPOCH 7 done: loss 1.1620 - lr 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:36:32,185 DEV : loss 1.1603419780731201 - score 0.52\n",
      "2020-05-17 14:36:32,244 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:36:32,246 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:36:32,316 epoch 8 - iter 0/429 - loss 0.96004170 - samples/sec: 19811.36\n",
      "2020-05-17 14:36:35,144 epoch 8 - iter 42/429 - loss 1.14324293 - samples/sec: 476.62\n",
      "2020-05-17 14:36:37,963 epoch 8 - iter 84/429 - loss 1.14310255 - samples/sec: 478.24\n",
      "2020-05-17 14:36:40,809 epoch 8 - iter 126/429 - loss 1.14638663 - samples/sec: 473.50\n",
      "2020-05-17 14:36:43,638 epoch 8 - iter 168/429 - loss 1.14470754 - samples/sec: 476.34\n",
      "2020-05-17 14:36:46,469 epoch 8 - iter 210/429 - loss 1.13912979 - samples/sec: 476.17\n",
      "2020-05-17 14:36:49,327 epoch 8 - iter 252/429 - loss 1.14251198 - samples/sec: 471.48\n",
      "2020-05-17 14:36:52,155 epoch 8 - iter 294/429 - loss 1.14037308 - samples/sec: 476.59\n",
      "2020-05-17 14:36:54,957 epoch 8 - iter 336/429 - loss 1.13781201 - samples/sec: 481.05\n",
      "2020-05-17 14:36:57,754 epoch 8 - iter 378/429 - loss 1.13905581 - samples/sec: 482.06\n",
      "2020-05-17 14:37:00,763 epoch 8 - iter 420/429 - loss 1.13567849 - samples/sec: 447.86\n",
      "2020-05-17 14:37:01,310 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:37:01,311 EPOCH 8 done: loss 1.1351 - lr 0.1000\n",
      "2020-05-17 14:37:02,157 DEV : loss 1.143132209777832 - score 0.538\n",
      "2020-05-17 14:37:02,218 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 14:37:02,220 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:37:02,295 epoch 9 - iter 0/429 - loss 1.29840899 - samples/sec: 18319.13\n",
      "2020-05-17 14:37:05,273 epoch 9 - iter 42/429 - loss 1.15826957 - samples/sec: 453.39\n",
      "2020-05-17 14:37:08,161 epoch 9 - iter 84/429 - loss 1.14415303 - samples/sec: 466.68\n",
      "2020-05-17 14:37:10,999 epoch 9 - iter 126/429 - loss 1.13107466 - samples/sec: 475.18\n",
      "2020-05-17 14:37:13,837 epoch 9 - iter 168/429 - loss 1.11906902 - samples/sec: 474.93\n",
      "2020-05-17 14:37:16,658 epoch 9 - iter 210/429 - loss 1.12201276 - samples/sec: 477.75\n",
      "2020-05-17 14:37:19,489 epoch 9 - iter 252/429 - loss 1.12529707 - samples/sec: 476.13\n",
      "2020-05-17 14:37:22,282 epoch 9 - iter 294/429 - loss 1.12663154 - samples/sec: 482.53\n",
      "2020-05-17 14:37:25,125 epoch 9 - iter 336/429 - loss 1.12966726 - samples/sec: 474.06\n",
      "2020-05-17 14:37:27,998 epoch 9 - iter 378/429 - loss 1.12568510 - samples/sec: 469.13\n",
      "2020-05-17 14:37:30,915 epoch 9 - iter 420/429 - loss 1.11817869 - samples/sec: 462.17\n",
      "2020-05-17 14:37:31,447 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:37:31,448 EPOCH 9 done: loss 1.1181 - lr 0.1000\n",
      "2020-05-17 14:37:32,189 DEV : loss 1.023280143737793 - score 0.598\n",
      "2020-05-17 14:37:32,249 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:37:35,485 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:37:35,562 epoch 10 - iter 0/429 - loss 1.18322551 - samples/sec: 18143.60\n",
      "2020-05-17 14:37:38,390 epoch 10 - iter 42/429 - loss 1.12951306 - samples/sec: 476.71\n",
      "2020-05-17 14:37:41,215 epoch 10 - iter 84/429 - loss 1.10978981 - samples/sec: 477.05\n",
      "2020-05-17 14:37:44,095 epoch 10 - iter 126/429 - loss 1.10262300 - samples/sec: 467.89\n",
      "2020-05-17 14:37:46,917 epoch 10 - iter 168/429 - loss 1.09710473 - samples/sec: 477.72\n",
      "2020-05-17 14:37:49,882 epoch 10 - iter 210/429 - loss 1.10571909 - samples/sec: 454.61\n",
      "2020-05-17 14:37:52,773 epoch 10 - iter 252/429 - loss 1.10279826 - samples/sec: 466.11\n",
      "2020-05-17 14:37:55,582 epoch 10 - iter 294/429 - loss 1.10471065 - samples/sec: 479.79\n",
      "2020-05-17 14:37:58,392 epoch 10 - iter 336/429 - loss 1.10024017 - samples/sec: 479.49\n",
      "2020-05-17 14:38:01,222 epoch 10 - iter 378/429 - loss 1.10199260 - samples/sec: 476.28\n",
      "2020-05-17 14:38:04,094 epoch 10 - iter 420/429 - loss 1.09859531 - samples/sec: 469.42\n",
      "2020-05-17 14:38:04,629 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:38:04,630 EPOCH 10 done: loss 1.0993 - lr 0.1000\n",
      "2020-05-17 14:38:05,376 DEV : loss 1.0457050800323486 - score 0.588\n",
      "2020-05-17 14:38:05,440 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:38:05,442 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:38:05,510 epoch 11 - iter 0/429 - loss 1.12393439 - samples/sec: 20211.48\n",
      "2020-05-17 14:38:08,302 epoch 11 - iter 42/429 - loss 1.08583876 - samples/sec: 482.65\n",
      "2020-05-17 14:38:11,110 epoch 11 - iter 84/429 - loss 1.06701884 - samples/sec: 480.06\n",
      "2020-05-17 14:38:14,003 epoch 11 - iter 126/429 - loss 1.06624374 - samples/sec: 466.00\n",
      "2020-05-17 14:38:16,845 epoch 11 - iter 168/429 - loss 1.07998577 - samples/sec: 474.24\n",
      "2020-05-17 14:38:19,687 epoch 11 - iter 210/429 - loss 1.07437131 - samples/sec: 474.27\n",
      "2020-05-17 14:38:22,610 epoch 11 - iter 252/429 - loss 1.07153424 - samples/sec: 461.03\n",
      "2020-05-17 14:38:25,387 epoch 11 - iter 294/429 - loss 1.07356405 - samples/sec: 485.37\n",
      "2020-05-17 14:38:28,280 epoch 11 - iter 336/429 - loss 1.07388995 - samples/sec: 465.89\n",
      "2020-05-17 14:38:31,105 epoch 11 - iter 378/429 - loss 1.07645201 - samples/sec: 477.12\n",
      "2020-05-17 14:38:33,962 epoch 11 - iter 420/429 - loss 1.07595789 - samples/sec: 472.39\n",
      "2020-05-17 14:38:34,492 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:38:34,493 EPOCH 11 done: loss 1.0758 - lr 0.1000\n",
      "2020-05-17 14:38:35,253 DEV : loss 1.0881966352462769 - score 0.57\n",
      "2020-05-17 14:38:35,312 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 14:38:35,314 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:38:35,383 epoch 12 - iter 0/429 - loss 1.05639529 - samples/sec: 20019.26\n",
      "2020-05-17 14:38:38,232 epoch 12 - iter 42/429 - loss 1.04539619 - samples/sec: 472.98\n",
      "2020-05-17 14:38:41,055 epoch 12 - iter 84/429 - loss 1.05600452 - samples/sec: 477.49\n",
      "2020-05-17 14:38:43,886 epoch 12 - iter 126/429 - loss 1.06017020 - samples/sec: 476.54\n",
      "2020-05-17 14:38:46,686 epoch 12 - iter 168/429 - loss 1.06546799 - samples/sec: 481.50\n",
      "2020-05-17 14:38:49,499 epoch 12 - iter 210/429 - loss 1.05853434 - samples/sec: 479.06\n",
      "2020-05-17 14:38:52,307 epoch 12 - iter 252/429 - loss 1.05771594 - samples/sec: 480.01\n",
      "2020-05-17 14:38:55,305 epoch 12 - iter 294/429 - loss 1.06182932 - samples/sec: 449.64\n",
      "2020-05-17 14:38:58,242 epoch 12 - iter 336/429 - loss 1.06221453 - samples/sec: 458.76\n",
      "2020-05-17 14:39:01,226 epoch 12 - iter 378/429 - loss 1.05852764 - samples/sec: 451.67\n",
      "2020-05-17 14:39:04,149 epoch 12 - iter 420/429 - loss 1.05714764 - samples/sec: 461.13\n",
      "2020-05-17 14:39:04,681 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:39:04,683 EPOCH 12 done: loss 1.0584 - lr 0.1000\n",
      "2020-05-17 14:39:05,433 DEV : loss 1.0619523525238037 - score 0.592\n",
      "2020-05-17 14:39:05,492 BAD EPOCHS (no improvement): 3\n",
      "2020-05-17 14:39:05,494 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:39:05,568 epoch 13 - iter 0/429 - loss 1.12135339 - samples/sec: 18612.18\n",
      "2020-05-17 14:39:08,502 epoch 13 - iter 42/429 - loss 1.06338189 - samples/sec: 459.30\n",
      "2020-05-17 14:39:11,420 epoch 13 - iter 84/429 - loss 1.03976291 - samples/sec: 461.85\n",
      "2020-05-17 14:39:14,290 epoch 13 - iter 126/429 - loss 1.03786837 - samples/sec: 469.74\n",
      "2020-05-17 14:39:17,157 epoch 13 - iter 168/429 - loss 1.03316187 - samples/sec: 470.10\n",
      "2020-05-17 14:39:20,137 epoch 13 - iter 210/429 - loss 1.04021884 - samples/sec: 452.30\n",
      "2020-05-17 14:39:23,007 epoch 13 - iter 252/429 - loss 1.04174881 - samples/sec: 469.56\n",
      "2020-05-17 14:39:25,929 epoch 13 - iter 294/429 - loss 1.04473221 - samples/sec: 461.53\n",
      "2020-05-17 14:39:28,815 epoch 13 - iter 336/429 - loss 1.04400506 - samples/sec: 467.59\n",
      "2020-05-17 14:39:31,662 epoch 13 - iter 378/429 - loss 1.04242953 - samples/sec: 473.23\n",
      "2020-05-17 14:39:34,582 epoch 13 - iter 420/429 - loss 1.03959918 - samples/sec: 461.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:39:35,128 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:39:35,129 EPOCH 13 done: loss 1.0364 - lr 0.1000\n",
      "2020-05-17 14:39:35,935 DEV : loss 1.0511728525161743 - score 0.62\n",
      "2020-05-17 14:39:35,996 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:39:39,177 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:39:39,263 epoch 14 - iter 0/429 - loss 0.75632226 - samples/sec: 18592.78\n",
      "2020-05-17 14:39:42,073 epoch 14 - iter 42/429 - loss 1.03423427 - samples/sec: 479.56\n",
      "2020-05-17 14:39:44,951 epoch 14 - iter 84/429 - loss 1.01081554 - samples/sec: 468.23\n",
      "2020-05-17 14:39:47,791 epoch 14 - iter 126/429 - loss 1.00596304 - samples/sec: 474.69\n",
      "2020-05-17 14:39:50,629 epoch 14 - iter 168/429 - loss 1.01613706 - samples/sec: 474.81\n",
      "2020-05-17 14:39:53,493 epoch 14 - iter 210/429 - loss 1.02071031 - samples/sec: 470.57\n",
      "2020-05-17 14:39:56,481 epoch 14 - iter 252/429 - loss 1.01550980 - samples/sec: 450.86\n",
      "2020-05-17 14:39:59,350 epoch 14 - iter 294/429 - loss 1.01636061 - samples/sec: 469.75\n",
      "2020-05-17 14:40:02,236 epoch 14 - iter 336/429 - loss 1.01443208 - samples/sec: 467.15\n",
      "2020-05-17 14:40:05,123 epoch 14 - iter 378/429 - loss 1.01381673 - samples/sec: 466.81\n",
      "2020-05-17 14:40:08,023 epoch 14 - iter 420/429 - loss 1.01139461 - samples/sec: 464.77\n",
      "2020-05-17 14:40:08,558 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:40:08,560 EPOCH 14 done: loss 1.0129 - lr 0.1000\n",
      "2020-05-17 14:40:09,328 DEV : loss 0.9508970975875854 - score 0.614\n",
      "2020-05-17 14:40:09,387 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:40:09,388 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:40:09,454 epoch 15 - iter 0/429 - loss 1.05875099 - samples/sec: 20895.26\n",
      "2020-05-17 14:40:12,333 epoch 15 - iter 42/429 - loss 0.98697068 - samples/sec: 468.22\n",
      "2020-05-17 14:40:15,246 epoch 15 - iter 84/429 - loss 0.99812868 - samples/sec: 462.59\n",
      "2020-05-17 14:40:18,173 epoch 15 - iter 126/429 - loss 0.98963567 - samples/sec: 460.55\n",
      "2020-05-17 14:40:21,129 epoch 15 - iter 168/429 - loss 0.98631734 - samples/sec: 455.83\n",
      "2020-05-17 14:40:24,054 epoch 15 - iter 210/429 - loss 0.98381371 - samples/sec: 460.66\n",
      "2020-05-17 14:40:26,927 epoch 15 - iter 252/429 - loss 0.97711284 - samples/sec: 469.04\n",
      "2020-05-17 14:40:29,862 epoch 15 - iter 294/429 - loss 0.97827803 - samples/sec: 459.21\n",
      "2020-05-17 14:40:32,787 epoch 15 - iter 336/429 - loss 0.98192663 - samples/sec: 460.76\n",
      "2020-05-17 14:40:35,679 epoch 15 - iter 378/429 - loss 0.98378316 - samples/sec: 466.14\n",
      "2020-05-17 14:40:38,622 epoch 15 - iter 420/429 - loss 0.98690690 - samples/sec: 457.82\n",
      "2020-05-17 14:40:39,180 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:40:39,182 EPOCH 15 done: loss 0.9872 - lr 0.1000\n",
      "2020-05-17 14:40:39,938 DEV : loss 1.1520023345947266 - score 0.57\n",
      "2020-05-17 14:40:39,997 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 14:40:43,193 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:40:43,195 Testing using best model ...\n",
      "2020-05-17 14:40:43,196 loading file best-model.pt\n",
      "2020-05-17 14:40:44,252 0.69\t0.69\t0.69\n",
      "2020-05-17 14:40:44,252 \n",
      "MICRO_AVG: acc 0.5267 - f1-score 0.69\n",
      "MACRO_AVG: acc 0.3976 - f1-score 0.51902\n",
      "0          tp: 116 - fp: 25 - fn: 30 - tn: 329 - precision: 0.8227 - recall: 0.7945 - accuracy: 0.6784 - f1-score: 0.8084\n",
      "1          tp: 27 - fp: 10 - fn: 61 - tn: 402 - precision: 0.7297 - recall: 0.3068 - accuracy: 0.2755 - f1-score: 0.4320\n",
      "2          tp: 0 - fp: 0 - fn: 10 - tn: 490 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "3          tp: 140 - fp: 74 - fn: 18 - tn: 268 - precision: 0.6542 - recall: 0.8861 - accuracy: 0.6034 - f1-score: 0.7527\n",
      "4          tp: 62 - fp: 46 - fn: 36 - tn: 356 - precision: 0.5741 - recall: 0.6327 - accuracy: 0.4306 - f1-score: 0.6020\n",
      "2020-05-17 14:40:44,253 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "fasttext web-crawl\n",
      "2020-05-17 14:40:52,616 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 14:40:52,617 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 14:40:52,618 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 14:40:52,619 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:41:02,857 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 266977.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:41:02,911 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 14:41:02,912 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 236155.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:41:02,975 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 14:41:02,979 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:41:02,980 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('en-crawl')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=300, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 14:41:02,982 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:41:02,983 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 14:41:02,984 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:41:02,985 Parameters:\n",
      "2020-05-17 14:41:02,985  - learning_rate: \"0.1\"\n",
      "2020-05-17 14:41:02,986  - mini_batch_size: \"32\"\n",
      "2020-05-17 14:41:02,987  - patience: \"5\"\n",
      "2020-05-17 14:41:02,987  - anneal_factor: \"0.5\"\n",
      "2020-05-17 14:41:02,988  - max_epochs: \"15\"\n",
      "2020-05-17 14:41:02,988  - shuffle: \"True\"\n",
      "2020-05-17 14:41:02,989  - train_with_dev: \"False\"\n",
      "2020-05-17 14:41:02,989  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 14:41:02,990 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:41:02,990 Model training base path: \".\"\n",
      "2020-05-17 14:41:02,990 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:41:02,991 Device: cuda:0\n",
      "2020-05-17 14:41:02,992 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:41:02,992 Embeddings storage mode: cpu\n",
      "2020-05-17 14:41:02,994 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:41:03,127 epoch 1 - iter 0/429 - loss 1.61723661 - samples/sec: 10310.26\n",
      "2020-05-17 14:41:10,386 epoch 1 - iter 42/429 - loss 1.47664226 - samples/sec: 185.36\n",
      "2020-05-17 14:41:16,295 epoch 1 - iter 84/429 - loss 1.46764976 - samples/sec: 227.75\n",
      "2020-05-17 14:41:22,416 epoch 1 - iter 126/429 - loss 1.45863838 - samples/sec: 219.82\n",
      "2020-05-17 14:41:28,607 epoch 1 - iter 168/429 - loss 1.45404386 - samples/sec: 217.36\n",
      "2020-05-17 14:41:34,542 epoch 1 - iter 210/429 - loss 1.44682326 - samples/sec: 226.78\n",
      "2020-05-17 14:41:40,379 epoch 1 - iter 252/429 - loss 1.43909471 - samples/sec: 230.56\n",
      "2020-05-17 14:41:46,215 epoch 1 - iter 294/429 - loss 1.43461333 - samples/sec: 230.57\n",
      "2020-05-17 14:41:52,192 epoch 1 - iter 336/429 - loss 1.42887211 - samples/sec: 225.16\n",
      "2020-05-17 14:41:59,853 epoch 1 - iter 378/429 - loss 1.42299350 - samples/sec: 175.62\n",
      "2020-05-17 14:42:05,873 epoch 1 - iter 420/429 - loss 1.41584192 - samples/sec: 223.54\n",
      "2020-05-17 14:42:06,947 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:42:06,949 EPOCH 1 done: loss 1.4155 - lr 0.1000\n",
      "2020-05-17 14:42:08,875 DEV : loss 1.3618515729904175 - score 0.394\n",
      "2020-05-17 14:42:08,934 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:42:19,401 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:42:19,478 epoch 2 - iter 0/429 - loss 1.30463672 - samples/sec: 18244.78\n",
      "2020-05-17 14:42:22,351 epoch 2 - iter 42/429 - loss 1.34041547 - samples/sec: 468.97\n",
      "2020-05-17 14:42:25,241 epoch 2 - iter 84/429 - loss 1.34866471 - samples/sec: 466.35\n",
      "2020-05-17 14:42:28,295 epoch 2 - iter 126/429 - loss 1.33701020 - samples/sec: 441.69\n",
      "2020-05-17 14:42:31,391 epoch 2 - iter 168/429 - loss 1.33589731 - samples/sec: 436.02\n",
      "2020-05-17 14:42:34,421 epoch 2 - iter 210/429 - loss 1.32843123 - samples/sec: 444.73\n",
      "2020-05-17 14:42:37,383 epoch 2 - iter 252/429 - loss 1.31560871 - samples/sec: 455.87\n",
      "2020-05-17 14:42:40,386 epoch 2 - iter 294/429 - loss 1.31022782 - samples/sec: 448.81\n",
      "2020-05-17 14:42:43,521 epoch 2 - iter 336/429 - loss 1.31360439 - samples/sec: 429.84\n",
      "2020-05-17 14:42:46,590 epoch 2 - iter 378/429 - loss 1.30416620 - samples/sec: 439.34\n",
      "2020-05-17 14:42:49,570 epoch 2 - iter 420/429 - loss 1.29821349 - samples/sec: 452.28\n",
      "2020-05-17 14:42:50,126 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:42:50,128 EPOCH 2 done: loss 1.2960 - lr 0.1000\n",
      "2020-05-17 14:42:50,919 DEV : loss 1.1416571140289307 - score 0.522\n",
      "2020-05-17 14:42:50,979 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:43:01,390 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:43:01,467 epoch 3 - iter 0/429 - loss 1.03831780 - samples/sec: 18237.99\n",
      "2020-05-17 14:43:04,505 epoch 3 - iter 42/429 - loss 1.26558857 - samples/sec: 443.72\n",
      "2020-05-17 14:43:07,485 epoch 3 - iter 84/429 - loss 1.22864879 - samples/sec: 452.28\n",
      "2020-05-17 14:43:10,539 epoch 3 - iter 126/429 - loss 1.22905134 - samples/sec: 442.29\n",
      "2020-05-17 14:43:13,522 epoch 3 - iter 168/429 - loss 1.22399550 - samples/sec: 451.98\n",
      "2020-05-17 14:43:16,551 epoch 3 - iter 210/429 - loss 1.22071229 - samples/sec: 444.83\n",
      "2020-05-17 14:43:19,510 epoch 3 - iter 252/429 - loss 1.21682146 - samples/sec: 455.43\n",
      "2020-05-17 14:43:22,529 epoch 3 - iter 294/429 - loss 1.21593936 - samples/sec: 447.51\n",
      "2020-05-17 14:43:25,586 epoch 3 - iter 336/429 - loss 1.21420130 - samples/sec: 440.91\n",
      "2020-05-17 14:43:28,581 epoch 3 - iter 378/429 - loss 1.21510483 - samples/sec: 450.07\n",
      "2020-05-17 14:43:31,645 epoch 3 - iter 420/429 - loss 1.21147732 - samples/sec: 440.65\n",
      "2020-05-17 14:43:32,237 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:43:32,239 EPOCH 3 done: loss 1.2102 - lr 0.1000\n",
      "2020-05-17 14:43:33,148 DEV : loss 1.202916145324707 - score 0.49\n",
      "2020-05-17 14:43:33,214 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:43:33,216 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:43:33,295 epoch 4 - iter 0/429 - loss 1.06605625 - samples/sec: 17373.87\n",
      "2020-05-17 14:43:36,439 epoch 4 - iter 42/429 - loss 1.15447530 - samples/sec: 428.59\n",
      "2020-05-17 14:43:39,688 epoch 4 - iter 84/429 - loss 1.13470032 - samples/sec: 414.87\n",
      "2020-05-17 14:43:42,972 epoch 4 - iter 126/429 - loss 1.14379640 - samples/sec: 410.66\n",
      "2020-05-17 14:43:46,011 epoch 4 - iter 168/429 - loss 1.16323833 - samples/sec: 444.15\n",
      "2020-05-17 14:43:48,996 epoch 4 - iter 210/429 - loss 1.17307980 - samples/sec: 451.73\n",
      "2020-05-17 14:43:52,011 epoch 4 - iter 252/429 - loss 1.17334685 - samples/sec: 446.96\n",
      "2020-05-17 14:43:55,165 epoch 4 - iter 294/429 - loss 1.16995785 - samples/sec: 427.47\n",
      "2020-05-17 14:43:58,144 epoch 4 - iter 336/429 - loss 1.16447488 - samples/sec: 452.71\n",
      "2020-05-17 14:44:01,169 epoch 4 - iter 378/429 - loss 1.16222125 - samples/sec: 445.38\n",
      "2020-05-17 14:44:04,269 epoch 4 - iter 420/429 - loss 1.15936992 - samples/sec: 434.91\n",
      "2020-05-17 14:44:04,848 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:44:04,849 EPOCH 4 done: loss 1.1619 - lr 0.1000\n",
      "2020-05-17 14:44:05,701 DEV : loss 1.0959625244140625 - score 0.54\n",
      "2020-05-17 14:44:05,764 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:44:16,544 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:44:16,626 epoch 5 - iter 0/429 - loss 1.09279084 - samples/sec: 17137.25\n",
      "2020-05-17 14:44:19,962 epoch 5 - iter 42/429 - loss 1.15181972 - samples/sec: 404.02\n",
      "2020-05-17 14:44:23,126 epoch 5 - iter 84/429 - loss 1.15864104 - samples/sec: 426.38\n",
      "2020-05-17 14:44:26,353 epoch 5 - iter 126/429 - loss 1.13784964 - samples/sec: 417.62\n",
      "2020-05-17 14:44:29,626 epoch 5 - iter 168/429 - loss 1.13971290 - samples/sec: 411.88\n",
      "2020-05-17 14:44:32,784 epoch 5 - iter 210/429 - loss 1.14362216 - samples/sec: 427.10\n",
      "2020-05-17 14:44:35,911 epoch 5 - iter 252/429 - loss 1.13390845 - samples/sec: 431.00\n",
      "2020-05-17 14:44:39,006 epoch 5 - iter 294/429 - loss 1.13258850 - samples/sec: 435.63\n",
      "2020-05-17 14:44:42,062 epoch 5 - iter 336/429 - loss 1.13316421 - samples/sec: 441.19\n",
      "2020-05-17 14:44:45,063 epoch 5 - iter 378/429 - loss 1.12739363 - samples/sec: 449.19\n",
      "2020-05-17 14:44:48,094 epoch 5 - iter 420/429 - loss 1.12605804 - samples/sec: 444.83\n",
      "2020-05-17 14:44:48,668 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:44:48,669 EPOCH 5 done: loss 1.1256 - lr 0.1000\n",
      "2020-05-17 14:44:49,451 DEV : loss 1.0547770261764526 - score 0.562\n",
      "2020-05-17 14:44:49,510 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:45:00,052 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:45:00,134 epoch 6 - iter 0/429 - loss 1.10901666 - samples/sec: 17258.50\n",
      "2020-05-17 14:45:03,279 epoch 6 - iter 42/429 - loss 1.09209234 - samples/sec: 428.57\n",
      "2020-05-17 14:45:06,269 epoch 6 - iter 84/429 - loss 1.09584623 - samples/sec: 450.86\n",
      "2020-05-17 14:45:09,338 epoch 6 - iter 126/429 - loss 1.10696981 - samples/sec: 439.16\n",
      "2020-05-17 14:45:12,324 epoch 6 - iter 168/429 - loss 1.10704130 - samples/sec: 451.31\n",
      "2020-05-17 14:45:15,302 epoch 6 - iter 210/429 - loss 1.10441234 - samples/sec: 452.88\n",
      "2020-05-17 14:45:18,323 epoch 6 - iter 252/429 - loss 1.10500568 - samples/sec: 446.37\n",
      "2020-05-17 14:45:21,277 epoch 6 - iter 294/429 - loss 1.10466433 - samples/sec: 456.60\n",
      "2020-05-17 14:45:24,227 epoch 6 - iter 336/429 - loss 1.09993710 - samples/sec: 457.01\n",
      "2020-05-17 14:45:27,263 epoch 6 - iter 378/429 - loss 1.09663647 - samples/sec: 445.08\n",
      "2020-05-17 14:45:30,215 epoch 6 - iter 420/429 - loss 1.09331514 - samples/sec: 456.82\n",
      "2020-05-17 14:45:30,825 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:45:30,826 EPOCH 6 done: loss 1.0932 - lr 0.1000\n",
      "2020-05-17 14:45:31,709 DEV : loss 1.0791798830032349 - score 0.54\n",
      "2020-05-17 14:45:31,771 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:45:31,773 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:45:31,848 epoch 7 - iter 0/429 - loss 1.05542552 - samples/sec: 18229.74\n",
      "2020-05-17 14:45:34,811 epoch 7 - iter 42/429 - loss 1.06109030 - samples/sec: 454.96\n",
      "2020-05-17 14:45:37,747 epoch 7 - iter 84/429 - loss 1.06735808 - samples/sec: 459.16\n",
      "2020-05-17 14:45:40,720 epoch 7 - iter 126/429 - loss 1.05187143 - samples/sec: 454.45\n",
      "2020-05-17 14:45:43,887 epoch 7 - iter 168/429 - loss 1.06004689 - samples/sec: 425.53\n",
      "2020-05-17 14:45:46,899 epoch 7 - iter 210/429 - loss 1.06453061 - samples/sec: 447.37\n",
      "2020-05-17 14:45:50,020 epoch 7 - iter 252/429 - loss 1.06394743 - samples/sec: 432.11\n",
      "2020-05-17 14:45:53,019 epoch 7 - iter 294/429 - loss 1.06787450 - samples/sec: 449.72\n",
      "2020-05-17 14:45:55,941 epoch 7 - iter 336/429 - loss 1.06875259 - samples/sec: 462.14\n",
      "2020-05-17 14:45:58,882 epoch 7 - iter 378/429 - loss 1.06656336 - samples/sec: 458.73\n",
      "2020-05-17 14:46:01,898 epoch 7 - iter 420/429 - loss 1.06945806 - samples/sec: 447.41\n",
      "2020-05-17 14:46:02,464 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:46:02,465 EPOCH 7 done: loss 1.0693 - lr 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:46:03,298 DEV : loss 1.0661033391952515 - score 0.56\n",
      "2020-05-17 14:46:03,359 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 14:46:03,360 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:46:03,436 epoch 8 - iter 0/429 - loss 1.00424874 - samples/sec: 18220.31\n",
      "2020-05-17 14:46:06,502 epoch 8 - iter 42/429 - loss 1.06998360 - samples/sec: 439.40\n",
      "2020-05-17 14:46:09,579 epoch 8 - iter 84/429 - loss 1.06157779 - samples/sec: 438.26\n",
      "2020-05-17 14:46:12,661 epoch 8 - iter 126/429 - loss 1.06626726 - samples/sec: 437.46\n",
      "2020-05-17 14:46:15,911 epoch 8 - iter 168/429 - loss 1.06315096 - samples/sec: 414.86\n",
      "2020-05-17 14:46:19,241 epoch 8 - iter 210/429 - loss 1.05659832 - samples/sec: 405.03\n",
      "2020-05-17 14:46:22,569 epoch 8 - iter 252/429 - loss 1.05027437 - samples/sec: 405.18\n",
      "2020-05-17 14:46:25,835 epoch 8 - iter 294/429 - loss 1.04967482 - samples/sec: 412.74\n",
      "2020-05-17 14:46:29,054 epoch 8 - iter 336/429 - loss 1.04824803 - samples/sec: 419.17\n",
      "2020-05-17 14:46:32,320 epoch 8 - iter 378/429 - loss 1.05035627 - samples/sec: 412.60\n",
      "2020-05-17 14:46:35,646 epoch 8 - iter 420/429 - loss 1.04868147 - samples/sec: 405.61\n",
      "2020-05-17 14:46:36,295 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:46:36,296 EPOCH 8 done: loss 1.0473 - lr 0.1000\n",
      "2020-05-17 14:46:37,202 DEV : loss 1.0090757608413696 - score 0.61\n",
      "2020-05-17 14:46:37,264 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:46:47,973 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:46:48,063 epoch 9 - iter 0/429 - loss 1.16230595 - samples/sec: 15549.29\n",
      "2020-05-17 14:46:51,443 epoch 9 - iter 42/429 - loss 1.07562969 - samples/sec: 398.82\n",
      "2020-05-17 14:46:54,799 epoch 9 - iter 84/429 - loss 1.05871351 - samples/sec: 402.07\n",
      "2020-05-17 14:46:58,135 epoch 9 - iter 126/429 - loss 1.04993809 - samples/sec: 404.58\n",
      "2020-05-17 14:47:01,523 epoch 9 - iter 168/429 - loss 1.03845657 - samples/sec: 397.97\n",
      "2020-05-17 14:47:04,853 epoch 9 - iter 210/429 - loss 1.04899818 - samples/sec: 404.77\n",
      "2020-05-17 14:47:08,170 epoch 9 - iter 252/429 - loss 1.05453301 - samples/sec: 406.54\n",
      "2020-05-17 14:47:11,319 epoch 9 - iter 294/429 - loss 1.05699224 - samples/sec: 428.00\n",
      "2020-05-17 14:47:14,587 epoch 9 - iter 336/429 - loss 1.05676484 - samples/sec: 412.55\n",
      "2020-05-17 14:47:17,835 epoch 9 - iter 378/429 - loss 1.05635379 - samples/sec: 414.89\n",
      "2020-05-17 14:47:21,104 epoch 9 - iter 420/429 - loss 1.05001338 - samples/sec: 412.29\n",
      "2020-05-17 14:47:21,726 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:47:21,727 EPOCH 9 done: loss 1.0501 - lr 0.1000\n",
      "2020-05-17 14:47:22,606 DEV : loss 1.0543545484542847 - score 0.576\n",
      "2020-05-17 14:47:22,666 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:47:22,667 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:47:22,748 epoch 10 - iter 0/429 - loss 1.06067061 - samples/sec: 17015.18\n",
      "2020-05-17 14:47:26,055 epoch 10 - iter 42/429 - loss 1.05309559 - samples/sec: 407.43\n",
      "2020-05-17 14:47:29,291 epoch 10 - iter 84/429 - loss 1.06333647 - samples/sec: 416.57\n",
      "2020-05-17 14:47:32,587 epoch 10 - iter 126/429 - loss 1.04522269 - samples/sec: 408.95\n",
      "2020-05-17 14:47:35,803 epoch 10 - iter 168/429 - loss 1.04198788 - samples/sec: 419.15\n",
      "2020-05-17 14:47:39,012 epoch 10 - iter 210/429 - loss 1.04430629 - samples/sec: 420.01\n",
      "2020-05-17 14:47:42,228 epoch 10 - iter 252/429 - loss 1.04165359 - samples/sec: 420.07\n",
      "2020-05-17 14:47:45,534 epoch 10 - iter 294/429 - loss 1.04045483 - samples/sec: 407.68\n",
      "2020-05-17 14:47:48,812 epoch 10 - iter 336/429 - loss 1.03744545 - samples/sec: 411.22\n",
      "2020-05-17 14:47:52,059 epoch 10 - iter 378/429 - loss 1.03259431 - samples/sec: 415.21\n",
      "2020-05-17 14:47:55,255 epoch 10 - iter 420/429 - loss 1.02736808 - samples/sec: 421.64\n",
      "2020-05-17 14:47:55,877 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:47:55,878 EPOCH 10 done: loss 1.0281 - lr 0.1000\n",
      "2020-05-17 14:47:56,769 DEV : loss 0.9693165421485901 - score 0.632\n",
      "2020-05-17 14:47:56,830 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:48:07,501 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:48:07,598 epoch 11 - iter 0/429 - loss 0.97709525 - samples/sec: 14316.01\n",
      "2020-05-17 14:48:10,912 epoch 11 - iter 42/429 - loss 0.99813870 - samples/sec: 406.60\n",
      "2020-05-17 14:48:14,240 epoch 11 - iter 84/429 - loss 1.00415953 - samples/sec: 405.02\n",
      "2020-05-17 14:48:17,525 epoch 11 - iter 126/429 - loss 0.99525358 - samples/sec: 410.30\n",
      "2020-05-17 14:48:20,886 epoch 11 - iter 168/429 - loss 1.01951213 - samples/sec: 401.06\n",
      "2020-05-17 14:48:24,127 epoch 11 - iter 210/429 - loss 1.01408940 - samples/sec: 415.76\n",
      "2020-05-17 14:48:27,430 epoch 11 - iter 252/429 - loss 1.01255677 - samples/sec: 408.16\n",
      "2020-05-17 14:48:30,711 epoch 11 - iter 294/429 - loss 1.00806268 - samples/sec: 411.11\n",
      "2020-05-17 14:48:33,969 epoch 11 - iter 336/429 - loss 1.00941708 - samples/sec: 413.93\n",
      "2020-05-17 14:48:37,216 epoch 11 - iter 378/429 - loss 1.00920114 - samples/sec: 415.05\n",
      "2020-05-17 14:48:40,547 epoch 11 - iter 420/429 - loss 1.01016326 - samples/sec: 404.59\n",
      "2020-05-17 14:48:41,182 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:48:41,183 EPOCH 11 done: loss 1.0119 - lr 0.1000\n",
      "2020-05-17 14:48:42,081 DEV : loss 0.9855749011039734 - score 0.618\n",
      "2020-05-17 14:48:42,142 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:48:42,144 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:48:42,220 epoch 12 - iter 0/429 - loss 0.86201519 - samples/sec: 18262.16\n",
      "2020-05-17 14:48:45,477 epoch 12 - iter 42/429 - loss 0.95329507 - samples/sec: 413.75\n",
      "2020-05-17 14:48:48,717 epoch 12 - iter 84/429 - loss 0.97117708 - samples/sec: 416.04\n",
      "2020-05-17 14:48:51,975 epoch 12 - iter 126/429 - loss 0.98616765 - samples/sec: 413.74\n",
      "2020-05-17 14:48:55,342 epoch 12 - iter 168/429 - loss 0.99231421 - samples/sec: 400.18\n",
      "2020-05-17 14:48:58,748 epoch 12 - iter 210/429 - loss 0.98214115 - samples/sec: 395.76\n",
      "2020-05-17 14:49:02,130 epoch 12 - iter 252/429 - loss 0.98590273 - samples/sec: 398.59\n",
      "2020-05-17 14:49:05,400 epoch 12 - iter 294/429 - loss 0.99239649 - samples/sec: 412.79\n",
      "2020-05-17 14:49:08,673 epoch 12 - iter 336/429 - loss 0.99117268 - samples/sec: 411.73\n",
      "2020-05-17 14:49:11,953 epoch 12 - iter 378/429 - loss 0.98827355 - samples/sec: 410.98\n",
      "2020-05-17 14:49:15,161 epoch 12 - iter 420/429 - loss 0.98312690 - samples/sec: 420.52\n",
      "2020-05-17 14:49:15,734 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:49:15,735 EPOCH 12 done: loss 0.9835 - lr 0.1000\n",
      "2020-05-17 14:49:16,611 DEV : loss 0.9101993441581726 - score 0.646\n",
      "2020-05-17 14:49:16,672 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:49:27,329 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:49:27,410 epoch 13 - iter 0/429 - loss 0.97073609 - samples/sec: 17330.40\n",
      "2020-05-17 14:49:30,519 epoch 13 - iter 42/429 - loss 0.94782779 - samples/sec: 433.51\n",
      "2020-05-17 14:49:33,728 epoch 13 - iter 84/429 - loss 0.94737710 - samples/sec: 420.19\n",
      "2020-05-17 14:49:36,955 epoch 13 - iter 126/429 - loss 0.95128634 - samples/sec: 417.87\n",
      "2020-05-17 14:49:40,208 epoch 13 - iter 168/429 - loss 0.95414395 - samples/sec: 414.53\n",
      "2020-05-17 14:49:43,603 epoch 13 - iter 210/429 - loss 0.96433698 - samples/sec: 397.07\n",
      "2020-05-17 14:49:46,867 epoch 13 - iter 252/429 - loss 0.96066280 - samples/sec: 413.02\n",
      "2020-05-17 14:49:50,081 epoch 13 - iter 294/429 - loss 0.96544782 - samples/sec: 419.26\n",
      "2020-05-17 14:49:53,316 epoch 13 - iter 336/429 - loss 0.96666754 - samples/sec: 417.02\n",
      "2020-05-17 14:49:56,527 epoch 13 - iter 378/429 - loss 0.96459764 - samples/sec: 419.69\n",
      "2020-05-17 14:49:59,781 epoch 13 - iter 420/429 - loss 0.96137383 - samples/sec: 414.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:50:00,394 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:50:00,395 EPOCH 13 done: loss 0.9601 - lr 0.1000\n",
      "2020-05-17 14:50:01,274 DEV : loss 0.9751898050308228 - score 0.584\n",
      "2020-05-17 14:50:01,339 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:50:01,340 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:50:01,420 epoch 14 - iter 0/429 - loss 0.76243532 - samples/sec: 17305.55\n",
      "2020-05-17 14:50:04,616 epoch 14 - iter 42/429 - loss 0.92409004 - samples/sec: 421.85\n",
      "2020-05-17 14:50:07,860 epoch 14 - iter 84/429 - loss 0.92303703 - samples/sec: 415.50\n",
      "2020-05-17 14:50:11,106 epoch 14 - iter 126/429 - loss 0.93769974 - samples/sec: 415.44\n",
      "2020-05-17 14:50:14,445 epoch 14 - iter 168/429 - loss 0.95245250 - samples/sec: 403.66\n",
      "2020-05-17 14:50:17,805 epoch 14 - iter 210/429 - loss 0.96040384 - samples/sec: 401.07\n",
      "2020-05-17 14:50:21,069 epoch 14 - iter 252/429 - loss 0.95853120 - samples/sec: 412.97\n",
      "2020-05-17 14:50:24,324 epoch 14 - iter 294/429 - loss 0.96507431 - samples/sec: 414.25\n",
      "2020-05-17 14:50:27,664 epoch 14 - iter 336/429 - loss 0.96502073 - samples/sec: 404.57\n",
      "2020-05-17 14:50:30,977 epoch 14 - iter 378/429 - loss 0.96404483 - samples/sec: 406.79\n",
      "2020-05-17 14:50:34,290 epoch 14 - iter 420/429 - loss 0.96305018 - samples/sec: 407.06\n",
      "2020-05-17 14:50:34,914 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:50:34,915 EPOCH 14 done: loss 0.9628 - lr 0.1000\n",
      "2020-05-17 14:50:35,814 DEV : loss 1.0458202362060547 - score 0.592\n",
      "2020-05-17 14:50:35,876 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 14:50:35,877 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:50:35,948 epoch 15 - iter 0/429 - loss 0.96370196 - samples/sec: 19421.08\n",
      "2020-05-17 14:50:39,270 epoch 15 - iter 42/429 - loss 0.94369365 - samples/sec: 405.60\n",
      "2020-05-17 14:50:42,611 epoch 15 - iter 84/429 - loss 0.94983537 - samples/sec: 403.73\n",
      "2020-05-17 14:50:45,931 epoch 15 - iter 126/429 - loss 0.95014141 - samples/sec: 406.03\n",
      "2020-05-17 14:50:49,260 epoch 15 - iter 168/429 - loss 0.93851684 - samples/sec: 405.02\n",
      "2020-05-17 14:50:52,519 epoch 15 - iter 210/429 - loss 0.93451609 - samples/sec: 413.51\n",
      "2020-05-17 14:50:55,833 epoch 15 - iter 252/429 - loss 0.92739148 - samples/sec: 406.72\n",
      "2020-05-17 14:50:59,039 epoch 15 - iter 294/429 - loss 0.92608530 - samples/sec: 420.55\n",
      "2020-05-17 14:51:02,359 epoch 15 - iter 336/429 - loss 0.92393903 - samples/sec: 406.02\n",
      "2020-05-17 14:51:05,630 epoch 15 - iter 378/429 - loss 0.92512829 - samples/sec: 412.91\n",
      "2020-05-17 14:51:08,966 epoch 15 - iter 420/429 - loss 0.92720063 - samples/sec: 404.60\n",
      "2020-05-17 14:51:09,593 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:51:09,595 EPOCH 15 done: loss 0.9264 - lr 0.1000\n",
      "2020-05-17 14:51:10,506 DEV : loss 1.1635737419128418 - score 0.592\n",
      "2020-05-17 14:51:10,566 BAD EPOCHS (no improvement): 3\n",
      "2020-05-17 14:51:21,293 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:51:21,294 Testing using best model ...\n",
      "2020-05-17 14:51:21,294 loading file best-model.pt\n",
      "2020-05-17 14:51:25,645 0.704\t0.704\t0.704\n",
      "2020-05-17 14:51:25,646 \n",
      "MICRO_AVG: acc 0.5432 - f1-score 0.704\n",
      "MACRO_AVG: acc 0.4268 - f1-score 0.5504\n",
      "0          tp: 123 - fp: 29 - fn: 23 - tn: 325 - precision: 0.8092 - recall: 0.8425 - accuracy: 0.7029 - f1-score: 0.8255\n",
      "1          tp: 45 - fp: 26 - fn: 43 - tn: 386 - precision: 0.6338 - recall: 0.5114 - accuracy: 0.3947 - f1-score: 0.5661\n",
      "2          tp: 0 - fp: 0 - fn: 10 - tn: 490 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "3          tp: 116 - fp: 41 - fn: 42 - tn: 301 - precision: 0.7389 - recall: 0.7342 - accuracy: 0.5829 - f1-score: 0.7365\n",
      "4          tp: 68 - fp: 52 - fn: 30 - tn: 350 - precision: 0.5667 - recall: 0.6939 - accuracy: 0.4533 - f1-score: 0.6239\n",
      "2020-05-17 14:51:25,646 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "fasttext news/wiki\n",
      "2020-05-17 14:51:34,830 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 14:51:34,831 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 14:51:34,832 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 14:51:34,832 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:51:45,662 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 261832.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:51:45,718 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 14:51:45,719 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 261893.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:51:45,775 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 14:51:45,778 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:51:45,779 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('en')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=300, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 14:51:45,780 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:51:45,781 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 14:51:45,782 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:51:45,782 Parameters:\n",
      "2020-05-17 14:51:45,783  - learning_rate: \"0.1\"\n",
      "2020-05-17 14:51:45,783  - mini_batch_size: \"32\"\n",
      "2020-05-17 14:51:45,784  - patience: \"5\"\n",
      "2020-05-17 14:51:45,784  - anneal_factor: \"0.5\"\n",
      "2020-05-17 14:51:45,785  - max_epochs: \"15\"\n",
      "2020-05-17 14:51:45,785  - shuffle: \"True\"\n",
      "2020-05-17 14:51:45,787  - train_with_dev: \"False\"\n",
      "2020-05-17 14:51:45,787  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 14:51:45,788 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:51:45,789 Model training base path: \".\"\n",
      "2020-05-17 14:51:45,789 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:51:45,791 Device: cuda:0\n",
      "2020-05-17 14:51:45,792 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:51:45,792 Embeddings storage mode: cpu\n",
      "2020-05-17 14:51:45,793 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:51:45,921 epoch 1 - iter 0/429 - loss 1.60830641 - samples/sec: 10628.46\n",
      "2020-05-17 14:51:50,171 epoch 1 - iter 42/429 - loss 1.47772865 - samples/sec: 316.88\n",
      "2020-05-17 14:51:54,474 epoch 1 - iter 84/429 - loss 1.46796460 - samples/sec: 313.15\n",
      "2020-05-17 14:51:58,634 epoch 1 - iter 126/429 - loss 1.46031228 - samples/sec: 323.83\n",
      "2020-05-17 14:52:02,741 epoch 1 - iter 168/429 - loss 1.45698598 - samples/sec: 328.05\n",
      "2020-05-17 14:52:07,007 epoch 1 - iter 210/429 - loss 1.45197116 - samples/sec: 315.89\n",
      "2020-05-17 14:52:13,229 epoch 1 - iter 252/429 - loss 1.44605934 - samples/sec: 216.30\n",
      "2020-05-17 14:52:17,585 epoch 1 - iter 294/429 - loss 1.44421224 - samples/sec: 309.16\n",
      "2020-05-17 14:52:21,892 epoch 1 - iter 336/429 - loss 1.43983900 - samples/sec: 312.78\n",
      "2020-05-17 14:52:26,219 epoch 1 - iter 378/429 - loss 1.43629472 - samples/sec: 311.24\n",
      "2020-05-17 14:52:30,551 epoch 1 - iter 420/429 - loss 1.43210892 - samples/sec: 310.88\n",
      "2020-05-17 14:52:31,362 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:52:31,363 EPOCH 1 done: loss 1.4323 - lr 0.1000\n",
      "2020-05-17 14:52:32,669 DEV : loss 1.419691562652588 - score 0.336\n",
      "2020-05-17 14:52:32,732 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:52:43,507 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:52:43,593 epoch 2 - iter 0/429 - loss 1.41913736 - samples/sec: 16421.32\n",
      "2020-05-17 14:52:46,851 epoch 2 - iter 42/429 - loss 1.41625045 - samples/sec: 413.72\n",
      "2020-05-17 14:52:50,062 epoch 2 - iter 84/429 - loss 1.42565840 - samples/sec: 419.75\n",
      "2020-05-17 14:52:53,342 epoch 2 - iter 126/429 - loss 1.41891405 - samples/sec: 411.11\n",
      "2020-05-17 14:52:56,630 epoch 2 - iter 168/429 - loss 1.41955020 - samples/sec: 409.88\n",
      "2020-05-17 14:52:59,876 epoch 2 - iter 210/429 - loss 1.41767908 - samples/sec: 415.37\n",
      "2020-05-17 14:53:03,143 epoch 2 - iter 252/429 - loss 1.41266675 - samples/sec: 412.73\n",
      "2020-05-17 14:53:06,374 epoch 2 - iter 294/429 - loss 1.41396501 - samples/sec: 417.19\n",
      "2020-05-17 14:53:09,752 epoch 2 - iter 336/429 - loss 1.41872265 - samples/sec: 398.99\n",
      "2020-05-17 14:53:13,100 epoch 2 - iter 378/429 - loss 1.41854358 - samples/sec: 402.50\n",
      "2020-05-17 14:53:16,558 epoch 2 - iter 420/429 - loss 1.41665216 - samples/sec: 389.74\n",
      "2020-05-17 14:53:17,185 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:53:17,186 EPOCH 2 done: loss 1.4167 - lr 0.1000\n",
      "2020-05-17 14:53:18,154 DEV : loss 1.4022825956344604 - score 0.388\n",
      "2020-05-17 14:53:18,217 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:53:28,956 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:53:29,046 epoch 3 - iter 0/429 - loss 1.40348303 - samples/sec: 15669.92\n",
      "2020-05-17 14:53:32,372 epoch 3 - iter 42/429 - loss 1.41281174 - samples/sec: 405.18\n",
      "2020-05-17 14:53:35,734 epoch 3 - iter 84/429 - loss 1.40792334 - samples/sec: 400.86\n",
      "2020-05-17 14:53:39,150 epoch 3 - iter 126/429 - loss 1.40221061 - samples/sec: 394.61\n",
      "2020-05-17 14:53:42,482 epoch 3 - iter 168/429 - loss 1.39582459 - samples/sec: 404.53\n",
      "2020-05-17 14:53:45,686 epoch 3 - iter 210/429 - loss 1.39394838 - samples/sec: 420.65\n",
      "2020-05-17 14:53:48,979 epoch 3 - iter 252/429 - loss 1.38995173 - samples/sec: 409.30\n",
      "2020-05-17 14:53:52,278 epoch 3 - iter 294/429 - loss 1.38525576 - samples/sec: 408.61\n",
      "2020-05-17 14:53:55,644 epoch 3 - iter 336/429 - loss 1.38652903 - samples/sec: 400.38\n",
      "2020-05-17 14:53:58,981 epoch 3 - iter 378/429 - loss 1.38513748 - samples/sec: 403.97\n",
      "2020-05-17 14:54:02,311 epoch 3 - iter 420/429 - loss 1.37866003 - samples/sec: 404.76\n",
      "2020-05-17 14:54:02,960 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:54:02,961 EPOCH 3 done: loss 1.3775 - lr 0.1000\n",
      "2020-05-17 14:54:03,895 DEV : loss 1.2596911191940308 - score 0.464\n",
      "2020-05-17 14:54:03,957 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:54:14,892 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:54:14,984 epoch 4 - iter 0/429 - loss 1.15646863 - samples/sec: 15114.77\n",
      "2020-05-17 14:54:18,397 epoch 4 - iter 42/429 - loss 1.36974788 - samples/sec: 394.91\n",
      "2020-05-17 14:54:21,815 epoch 4 - iter 84/429 - loss 1.35444271 - samples/sec: 394.46\n",
      "2020-05-17 14:54:25,216 epoch 4 - iter 126/429 - loss 1.34484083 - samples/sec: 396.21\n",
      "2020-05-17 14:54:28,519 epoch 4 - iter 168/429 - loss 1.34426163 - samples/sec: 408.18\n",
      "2020-05-17 14:54:31,767 epoch 4 - iter 210/429 - loss 1.35305201 - samples/sec: 415.04\n",
      "2020-05-17 14:54:35,058 epoch 4 - iter 252/429 - loss 1.34954029 - samples/sec: 409.65\n",
      "2020-05-17 14:54:38,385 epoch 4 - iter 294/429 - loss 1.34807686 - samples/sec: 405.28\n",
      "2020-05-17 14:54:41,698 epoch 4 - iter 336/429 - loss 1.34946035 - samples/sec: 407.00\n",
      "2020-05-17 14:54:44,986 epoch 4 - iter 378/429 - loss 1.34639407 - samples/sec: 410.03\n",
      "2020-05-17 14:54:48,219 epoch 4 - iter 420/429 - loss 1.34147549 - samples/sec: 416.93\n",
      "2020-05-17 14:54:48,827 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:54:48,828 EPOCH 4 done: loss 1.3428 - lr 0.1000\n",
      "2020-05-17 14:54:49,755 DEV : loss 1.1891511678695679 - score 0.532\n",
      "2020-05-17 14:54:49,817 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 14:55:00,635 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:55:00,729 epoch 5 - iter 0/429 - loss 1.21602988 - samples/sec: 15059.17\n",
      "2020-05-17 14:55:04,126 epoch 5 - iter 42/429 - loss 1.31776638 - samples/sec: 396.88\n",
      "2020-05-17 14:55:07,573 epoch 5 - iter 84/429 - loss 1.29041837 - samples/sec: 390.97\n",
      "2020-05-17 14:55:10,943 epoch 5 - iter 126/429 - loss 1.28731731 - samples/sec: 399.87\n",
      "2020-05-17 14:55:14,239 epoch 5 - iter 168/429 - loss 1.29144479 - samples/sec: 408.93\n",
      "2020-05-17 14:55:17,550 epoch 5 - iter 210/429 - loss 1.28754491 - samples/sec: 407.70\n",
      "2020-05-17 14:55:20,820 epoch 5 - iter 252/429 - loss 1.28821405 - samples/sec: 412.12\n",
      "2020-05-17 14:55:24,092 epoch 5 - iter 294/429 - loss 1.28730289 - samples/sec: 412.18\n",
      "2020-05-17 14:55:27,437 epoch 5 - iter 336/429 - loss 1.29736507 - samples/sec: 403.44\n",
      "2020-05-17 14:55:30,736 epoch 5 - iter 378/429 - loss 1.30485591 - samples/sec: 409.31\n",
      "2020-05-17 14:55:34,143 epoch 5 - iter 420/429 - loss 1.30392071 - samples/sec: 395.74\n",
      "2020-05-17 14:55:34,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:55:34,768 EPOCH 5 done: loss 1.3020 - lr 0.1000\n",
      "2020-05-17 14:55:35,689 DEV : loss 1.2122985124588013 - score 0.494\n",
      "2020-05-17 14:55:35,752 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:55:35,754 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:55:35,830 epoch 6 - iter 0/429 - loss 1.18437219 - samples/sec: 18477.78\n",
      "2020-05-17 14:55:39,043 epoch 6 - iter 42/429 - loss 1.30462107 - samples/sec: 419.28\n",
      "2020-05-17 14:55:42,342 epoch 6 - iter 84/429 - loss 1.30308059 - samples/sec: 408.53\n",
      "2020-05-17 14:55:45,566 epoch 6 - iter 126/429 - loss 1.29626307 - samples/sec: 418.53\n",
      "2020-05-17 14:55:48,868 epoch 6 - iter 168/429 - loss 1.30482116 - samples/sec: 408.35\n",
      "2020-05-17 14:55:52,259 epoch 6 - iter 210/429 - loss 1.31100217 - samples/sec: 397.68\n",
      "2020-05-17 14:55:55,634 epoch 6 - iter 252/429 - loss 1.32073817 - samples/sec: 399.27\n",
      "2020-05-17 14:55:59,004 epoch 6 - iter 294/429 - loss 1.31288514 - samples/sec: 399.92\n",
      "2020-05-17 14:56:02,409 epoch 6 - iter 336/429 - loss 1.30349563 - samples/sec: 395.88\n",
      "2020-05-17 14:56:05,823 epoch 6 - iter 378/429 - loss 1.30802532 - samples/sec: 394.80\n",
      "2020-05-17 14:56:09,157 epoch 6 - iter 420/429 - loss 1.30338159 - samples/sec: 404.26\n",
      "2020-05-17 14:56:09,825 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:56:09,827 EPOCH 6 done: loss 1.3050 - lr 0.1000\n",
      "2020-05-17 14:56:10,760 DEV : loss 1.4621667861938477 - score 0.374\n",
      "2020-05-17 14:56:10,822 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 14:56:10,824 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:56:10,905 epoch 7 - iter 0/429 - loss 1.35085487 - samples/sec: 17072.12\n",
      "2020-05-17 14:56:14,211 epoch 7 - iter 42/429 - loss 1.25691751 - samples/sec: 407.60\n",
      "2020-05-17 14:56:17,564 epoch 7 - iter 84/429 - loss 1.26572556 - samples/sec: 402.12\n",
      "2020-05-17 14:56:20,840 epoch 7 - iter 126/429 - loss 1.23574292 - samples/sec: 411.41\n",
      "2020-05-17 14:56:24,170 epoch 7 - iter 168/429 - loss 1.24967874 - samples/sec: 405.77\n",
      "2020-05-17 14:56:27,534 epoch 7 - iter 210/429 - loss 1.28584314 - samples/sec: 400.67\n",
      "2020-05-17 14:56:30,946 epoch 7 - iter 252/429 - loss 1.28221660 - samples/sec: 394.96\n",
      "2020-05-17 14:56:34,343 epoch 7 - iter 294/429 - loss 1.28512369 - samples/sec: 396.66\n",
      "2020-05-17 14:56:37,711 epoch 7 - iter 336/429 - loss 1.28935635 - samples/sec: 400.21\n",
      "2020-05-17 14:56:40,919 epoch 7 - iter 378/429 - loss 1.28921743 - samples/sec: 420.13\n",
      "2020-05-17 14:56:44,350 epoch 7 - iter 420/429 - loss 1.29043426 - samples/sec: 392.78\n",
      "2020-05-17 14:56:45,004 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:56:45,005 EPOCH 7 done: loss 1.2907 - lr 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 14:56:45,969 DEV : loss 1.1596801280975342 - score 0.532\n",
      "2020-05-17 14:56:46,033 BAD EPOCHS (no improvement): 3\n",
      "2020-05-17 14:56:56,870 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:56:56,963 epoch 8 - iter 0/429 - loss 1.19991672 - samples/sec: 15123.90\n",
      "2020-05-17 14:57:00,226 epoch 8 - iter 42/429 - loss 1.33415430 - samples/sec: 413.15\n",
      "2020-05-17 14:57:03,596 epoch 8 - iter 84/429 - loss 1.31554907 - samples/sec: 399.94\n",
      "2020-05-17 14:57:06,851 epoch 8 - iter 126/429 - loss 1.31261658 - samples/sec: 414.07\n",
      "2020-05-17 14:57:10,206 epoch 8 - iter 168/429 - loss 1.29076184 - samples/sec: 401.80\n",
      "2020-05-17 14:57:13,599 epoch 8 - iter 210/429 - loss 1.27832038 - samples/sec: 397.15\n",
      "2020-05-17 14:57:16,927 epoch 8 - iter 252/429 - loss 1.27460625 - samples/sec: 405.24\n",
      "2020-05-17 14:57:20,333 epoch 8 - iter 294/429 - loss 1.27091674 - samples/sec: 395.76\n",
      "2020-05-17 14:57:23,679 epoch 8 - iter 336/429 - loss 1.26157382 - samples/sec: 402.84\n",
      "2020-05-17 14:57:26,807 epoch 8 - iter 378/429 - loss 1.26388374 - samples/sec: 431.76\n",
      "2020-05-17 14:57:30,130 epoch 8 - iter 420/429 - loss 1.25995448 - samples/sec: 405.67\n",
      "2020-05-17 14:57:30,747 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:57:30,749 EPOCH 8 done: loss 1.2587 - lr 0.1000\n",
      "2020-05-17 14:57:31,671 DEV : loss 1.1487090587615967 - score 0.522\n",
      "2020-05-17 14:57:31,735 BAD EPOCHS (no improvement): 4\n",
      "2020-05-17 14:57:31,737 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:57:31,820 epoch 9 - iter 0/429 - loss 1.43493783 - samples/sec: 16687.67\n",
      "2020-05-17 14:57:35,117 epoch 9 - iter 42/429 - loss 1.24203173 - samples/sec: 408.74\n",
      "2020-05-17 14:57:38,322 epoch 9 - iter 84/429 - loss 1.23585741 - samples/sec: 420.67\n",
      "2020-05-17 14:57:41,649 epoch 9 - iter 126/429 - loss 1.23809013 - samples/sec: 405.23\n",
      "2020-05-17 14:57:45,056 epoch 9 - iter 168/429 - loss 1.25003693 - samples/sec: 396.41\n",
      "2020-05-17 14:57:48,467 epoch 9 - iter 210/429 - loss 1.24498722 - samples/sec: 395.10\n",
      "2020-05-17 14:57:51,882 epoch 9 - iter 252/429 - loss 1.25057855 - samples/sec: 394.45\n",
      "2020-05-17 14:57:55,294 epoch 9 - iter 294/429 - loss 1.24348296 - samples/sec: 395.02\n",
      "2020-05-17 14:57:58,705 epoch 9 - iter 336/429 - loss 1.24322296 - samples/sec: 395.14\n",
      "2020-05-17 14:58:02,099 epoch 9 - iter 378/429 - loss 1.24299422 - samples/sec: 397.02\n",
      "2020-05-17 14:58:05,485 epoch 9 - iter 420/429 - loss 1.23319485 - samples/sec: 397.99\n",
      "2020-05-17 14:58:06,121 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:58:06,122 EPOCH 9 done: loss 1.2333 - lr 0.1000\n",
      "2020-05-17 14:58:07,043 DEV : loss 1.1751677989959717 - score 0.504\n",
      "2020-05-17 14:58:07,105 BAD EPOCHS (no improvement): 5\n",
      "2020-05-17 14:58:07,107 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:58:07,190 epoch 10 - iter 0/429 - loss 1.17165959 - samples/sec: 16430.08\n",
      "2020-05-17 14:58:10,558 epoch 10 - iter 42/429 - loss 1.19996446 - samples/sec: 400.24\n",
      "2020-05-17 14:58:13,934 epoch 10 - iter 84/429 - loss 1.18122214 - samples/sec: 399.11\n",
      "2020-05-17 14:58:17,303 epoch 10 - iter 126/429 - loss 1.19031591 - samples/sec: 400.17\n",
      "2020-05-17 14:58:20,661 epoch 10 - iter 168/429 - loss 1.18711858 - samples/sec: 401.43\n",
      "2020-05-17 14:58:24,007 epoch 10 - iter 210/429 - loss 1.19020832 - samples/sec: 402.86\n",
      "2020-05-17 14:58:27,426 epoch 10 - iter 252/429 - loss 1.18950487 - samples/sec: 394.28\n",
      "2020-05-17 14:58:30,839 epoch 10 - iter 294/429 - loss 1.19972711 - samples/sec: 395.74\n",
      "2020-05-17 14:58:34,127 epoch 10 - iter 336/429 - loss 1.20096536 - samples/sec: 409.85\n",
      "2020-05-17 14:58:37,487 epoch 10 - iter 378/429 - loss 1.20719733 - samples/sec: 401.13\n",
      "2020-05-17 14:58:40,868 epoch 10 - iter 420/429 - loss 1.20004103 - samples/sec: 399.35\n",
      "2020-05-17 14:58:41,507 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:58:41,508 EPOCH 10 done: loss 1.2040 - lr 0.1000\n",
      "2020-05-17 14:58:42,426 DEV : loss 1.4483928680419922 - score 0.372\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-05-17 14:58:42,492 BAD EPOCHS (no improvement): 6\n",
      "2020-05-17 14:58:42,494 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:58:42,578 epoch 11 - iter 0/429 - loss 1.47746491 - samples/sec: 16278.21\n",
      "2020-05-17 14:58:45,890 epoch 11 - iter 42/429 - loss 1.16556705 - samples/sec: 406.92\n",
      "2020-05-17 14:58:49,222 epoch 11 - iter 84/429 - loss 1.14624975 - samples/sec: 404.51\n",
      "2020-05-17 14:58:54,555 epoch 11 - iter 126/429 - loss 1.13230600 - samples/sec: 252.44\n",
      "2020-05-17 14:58:57,871 epoch 11 - iter 168/429 - loss 1.13925871 - samples/sec: 406.47\n",
      "2020-05-17 14:59:01,256 epoch 11 - iter 210/429 - loss 1.13434078 - samples/sec: 398.20\n",
      "2020-05-17 14:59:04,675 epoch 11 - iter 252/429 - loss 1.12910579 - samples/sec: 394.11\n",
      "2020-05-17 14:59:07,998 epoch 11 - iter 294/429 - loss 1.12319088 - samples/sec: 405.47\n",
      "2020-05-17 14:59:11,411 epoch 11 - iter 336/429 - loss 1.12140237 - samples/sec: 394.88\n",
      "2020-05-17 14:59:14,847 epoch 11 - iter 378/429 - loss 1.12110341 - samples/sec: 392.30\n",
      "2020-05-17 14:59:18,292 epoch 11 - iter 420/429 - loss 1.11774953 - samples/sec: 391.04\n",
      "2020-05-17 14:59:18,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:59:18,938 EPOCH 11 done: loss 1.1196 - lr 0.0500\n",
      "2020-05-17 14:59:19,886 DEV : loss 1.259323239326477 - score 0.516\n",
      "2020-05-17 14:59:19,954 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 14:59:19,955 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:59:20,044 epoch 12 - iter 0/429 - loss 1.23056817 - samples/sec: 15564.91\n",
      "2020-05-17 14:59:23,389 epoch 12 - iter 42/429 - loss 1.10383482 - samples/sec: 403.45\n",
      "2020-05-17 14:59:26,716 epoch 12 - iter 84/429 - loss 1.10010245 - samples/sec: 405.25\n",
      "2020-05-17 14:59:30,154 epoch 12 - iter 126/429 - loss 1.09363766 - samples/sec: 392.63\n",
      "2020-05-17 14:59:33,481 epoch 12 - iter 168/429 - loss 1.09650407 - samples/sec: 405.10\n",
      "2020-05-17 14:59:36,715 epoch 12 - iter 210/429 - loss 1.08711382 - samples/sec: 416.90\n",
      "2020-05-17 14:59:40,059 epoch 12 - iter 252/429 - loss 1.09167934 - samples/sec: 403.08\n",
      "2020-05-17 14:59:43,483 epoch 12 - iter 294/429 - loss 1.09417871 - samples/sec: 393.80\n",
      "2020-05-17 14:59:46,864 epoch 12 - iter 336/429 - loss 1.09140845 - samples/sec: 398.64\n",
      "2020-05-17 14:59:50,215 epoch 12 - iter 378/429 - loss 1.08847486 - samples/sec: 402.25\n",
      "2020-05-17 14:59:53,519 epoch 12 - iter 420/429 - loss 1.08507265 - samples/sec: 407.83\n",
      "2020-05-17 14:59:54,154 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 14:59:54,155 EPOCH 12 done: loss 1.0866 - lr 0.0500\n",
      "2020-05-17 14:59:55,071 DEV : loss 1.055328369140625 - score 0.572\n",
      "2020-05-17 14:59:55,135 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:00:06,028 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:00:06,111 epoch 13 - iter 0/429 - loss 1.16768634 - samples/sec: 17046.66\n",
      "2020-05-17 15:00:09,424 epoch 13 - iter 42/429 - loss 1.06373867 - samples/sec: 406.74\n",
      "2020-05-17 15:00:12,747 epoch 13 - iter 84/429 - loss 1.06413247 - samples/sec: 405.83\n",
      "2020-05-17 15:00:16,024 epoch 13 - iter 126/429 - loss 1.06749987 - samples/sec: 411.53\n",
      "2020-05-17 15:00:19,314 epoch 13 - iter 168/429 - loss 1.06244177 - samples/sec: 409.78\n",
      "2020-05-17 15:00:22,692 epoch 13 - iter 210/429 - loss 1.06837763 - samples/sec: 399.02\n",
      "2020-05-17 15:00:25,946 epoch 13 - iter 252/429 - loss 1.06769539 - samples/sec: 414.16\n",
      "2020-05-17 15:00:29,201 epoch 13 - iter 294/429 - loss 1.06856835 - samples/sec: 414.09\n",
      "2020-05-17 15:00:32,520 epoch 13 - iter 336/429 - loss 1.07097063 - samples/sec: 406.13\n",
      "2020-05-17 15:00:35,778 epoch 13 - iter 378/429 - loss 1.07087775 - samples/sec: 413.65\n",
      "2020-05-17 15:00:39,086 epoch 13 - iter 420/429 - loss 1.06890778 - samples/sec: 407.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:00:39,716 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:00:39,717 EPOCH 13 done: loss 1.0673 - lr 0.0500\n",
      "2020-05-17 15:00:40,643 DEV : loss 1.0098029375076294 - score 0.602\n",
      "2020-05-17 15:00:40,707 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:00:51,388 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:00:51,473 epoch 14 - iter 0/429 - loss 0.75870889 - samples/sec: 16624.43\n",
      "2020-05-17 15:00:54,749 epoch 14 - iter 42/429 - loss 1.03701408 - samples/sec: 411.45\n",
      "2020-05-17 15:00:58,054 epoch 14 - iter 84/429 - loss 1.04540966 - samples/sec: 407.76\n",
      "2020-05-17 15:01:01,378 epoch 14 - iter 126/429 - loss 1.04872718 - samples/sec: 405.65\n",
      "2020-05-17 15:01:04,655 epoch 14 - iter 168/429 - loss 1.05151839 - samples/sec: 411.22\n",
      "2020-05-17 15:01:08,083 epoch 14 - iter 210/429 - loss 1.05908856 - samples/sec: 393.36\n",
      "2020-05-17 15:01:11,446 epoch 14 - iter 252/429 - loss 1.05786303 - samples/sec: 400.86\n",
      "2020-05-17 15:01:14,882 epoch 14 - iter 294/429 - loss 1.05962783 - samples/sec: 392.50\n",
      "2020-05-17 15:01:18,288 epoch 14 - iter 336/429 - loss 1.06330733 - samples/sec: 395.75\n",
      "2020-05-17 15:01:21,697 epoch 14 - iter 378/429 - loss 1.06578706 - samples/sec: 395.39\n",
      "2020-05-17 15:01:25,075 epoch 14 - iter 420/429 - loss 1.06400529 - samples/sec: 399.10\n",
      "2020-05-17 15:01:25,709 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:01:25,710 EPOCH 14 done: loss 1.0644 - lr 0.0500\n",
      "2020-05-17 15:01:26,672 DEV : loss 1.0056179761886597 - score 0.602\n",
      "2020-05-17 15:01:26,736 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:01:37,752 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:01:37,838 epoch 15 - iter 0/429 - loss 0.99628323 - samples/sec: 16366.97\n",
      "2020-05-17 15:01:41,158 epoch 15 - iter 42/429 - loss 1.02371275 - samples/sec: 405.90\n",
      "2020-05-17 15:01:44,466 epoch 15 - iter 84/429 - loss 1.03842246 - samples/sec: 407.44\n",
      "2020-05-17 15:01:47,812 epoch 15 - iter 126/429 - loss 1.04696061 - samples/sec: 402.98\n",
      "2020-05-17 15:01:51,270 epoch 15 - iter 168/429 - loss 1.04221763 - samples/sec: 389.64\n",
      "2020-05-17 15:01:54,724 epoch 15 - iter 210/429 - loss 1.03918312 - samples/sec: 390.33\n",
      "2020-05-17 15:01:57,998 epoch 15 - iter 252/429 - loss 1.04166622 - samples/sec: 412.05\n",
      "2020-05-17 15:02:01,308 epoch 15 - iter 294/429 - loss 1.03918710 - samples/sec: 407.04\n",
      "2020-05-17 15:02:04,581 epoch 15 - iter 336/429 - loss 1.04357607 - samples/sec: 411.87\n",
      "2020-05-17 15:02:07,939 epoch 15 - iter 378/429 - loss 1.04702569 - samples/sec: 401.28\n",
      "2020-05-17 15:02:11,326 epoch 15 - iter 420/429 - loss 1.04950892 - samples/sec: 397.96\n",
      "2020-05-17 15:02:11,974 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:02:11,975 EPOCH 15 done: loss 1.0490 - lr 0.0500\n",
      "2020-05-17 15:02:12,953 DEV : loss 1.174307107925415 - score 0.528\n",
      "2020-05-17 15:02:13,016 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 15:02:23,863 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:02:23,865 Testing using best model ...\n",
      "2020-05-17 15:02:23,867 loading file best-model.pt\n",
      "2020-05-17 15:02:26,500 0.626\t0.626\t0.626\n",
      "2020-05-17 15:02:26,501 \n",
      "MICRO_AVG: acc 0.4556 - f1-score 0.626\n",
      "MACRO_AVG: acc 0.3316 - f1-score 0.45152000000000003\n",
      "0          tp: 114 - fp: 41 - fn: 32 - tn: 313 - precision: 0.7355 - recall: 0.7808 - accuracy: 0.6096 - f1-score: 0.7575\n",
      "1          tp: 19 - fp: 12 - fn: 69 - tn: 400 - precision: 0.6129 - recall: 0.2159 - accuracy: 0.1900 - f1-score: 0.3193\n",
      "2          tp: 0 - fp: 0 - fn: 10 - tn: 490 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "3          tp: 136 - fp: 89 - fn: 22 - tn: 253 - precision: 0.6044 - recall: 0.8608 - accuracy: 0.5506 - f1-score: 0.7102\n",
      "4          tp: 44 - fp: 45 - fn: 54 - tn: 357 - precision: 0.4944 - recall: 0.4490 - accuracy: 0.3077 - f1-score: 0.4706\n",
      "2020-05-17 15:02:26,502 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "en-twitter\n",
      "2020-05-17 15:02:32,733 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 15:02:32,734 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 15:02:32,735 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 15:02:32,736 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:02:48,374 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 256541.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:02:48,431 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 15:02:48,432 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 217690.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:02:48,498 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 15:02:48,501 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:02:48,503 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('en-twitter')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 15:02:48,504 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:02:48,505 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 15:02:48,506 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:02:48,507 Parameters:\n",
      "2020-05-17 15:02:48,507  - learning_rate: \"0.1\"\n",
      "2020-05-17 15:02:48,508  - mini_batch_size: \"32\"\n",
      "2020-05-17 15:02:48,509  - patience: \"5\"\n",
      "2020-05-17 15:02:48,509  - anneal_factor: \"0.5\"\n",
      "2020-05-17 15:02:48,510  - max_epochs: \"15\"\n",
      "2020-05-17 15:02:48,510  - shuffle: \"True\"\n",
      "2020-05-17 15:02:48,511  - train_with_dev: \"False\"\n",
      "2020-05-17 15:02:48,511  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 15:02:48,512 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:02:48,512 Model training base path: \".\"\n",
      "2020-05-17 15:02:48,513 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:02:48,513 Device: cuda:0\n",
      "2020-05-17 15:02:48,514 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:02:48,514 Embeddings storage mode: cpu\n",
      "2020-05-17 15:02:48,519 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:02:48,681 epoch 1 - iter 0/429 - loss 1.64963782 - samples/sec: 8407.05\n",
      "2020-05-17 15:02:53,371 epoch 1 - iter 42/429 - loss 1.47375114 - samples/sec: 287.37\n",
      "2020-05-17 15:02:57,779 epoch 1 - iter 84/429 - loss 1.47503687 - samples/sec: 305.95\n",
      "2020-05-17 15:03:03,635 epoch 1 - iter 126/429 - loss 1.46430009 - samples/sec: 229.88\n",
      "2020-05-17 15:03:07,727 epoch 1 - iter 168/429 - loss 1.46263328 - samples/sec: 329.10\n",
      "2020-05-17 15:03:11,783 epoch 1 - iter 210/429 - loss 1.45666312 - samples/sec: 332.05\n",
      "2020-05-17 15:03:15,829 epoch 1 - iter 252/429 - loss 1.44959366 - samples/sec: 332.87\n",
      "2020-05-17 15:03:19,778 epoch 1 - iter 294/429 - loss 1.44477963 - samples/sec: 341.06\n",
      "2020-05-17 15:03:23,794 epoch 1 - iter 336/429 - loss 1.43980878 - samples/sec: 335.45\n",
      "2020-05-17 15:03:27,800 epoch 1 - iter 378/429 - loss 1.43464454 - samples/sec: 336.30\n",
      "2020-05-17 15:03:31,773 epoch 1 - iter 420/429 - loss 1.42942987 - samples/sec: 339.04\n",
      "2020-05-17 15:03:32,512 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:03:32,514 EPOCH 1 done: loss 1.4298 - lr 0.1000\n",
      "2020-05-17 15:03:35,751 DEV : loss 1.380334496498108 - score 0.374\n",
      "2020-05-17 15:03:35,815 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:03:45,250 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:03:45,323 epoch 2 - iter 0/429 - loss 1.36812377 - samples/sec: 19290.89\n",
      "2020-05-17 15:03:48,145 epoch 2 - iter 42/429 - loss 1.37751475 - samples/sec: 477.67\n",
      "2020-05-17 15:03:51,058 epoch 2 - iter 84/429 - loss 1.39024114 - samples/sec: 462.98\n",
      "2020-05-17 15:03:53,996 epoch 2 - iter 126/429 - loss 1.38031038 - samples/sec: 458.96\n",
      "2020-05-17 15:03:56,947 epoch 2 - iter 168/429 - loss 1.37995564 - samples/sec: 457.27\n",
      "2020-05-17 15:03:59,878 epoch 2 - iter 210/429 - loss 1.37563201 - samples/sec: 460.02\n",
      "2020-05-17 15:04:02,836 epoch 2 - iter 252/429 - loss 1.37002675 - samples/sec: 455.76\n",
      "2020-05-17 15:04:05,777 epoch 2 - iter 294/429 - loss 1.36687120 - samples/sec: 458.48\n",
      "2020-05-17 15:04:08,712 epoch 2 - iter 336/429 - loss 1.37000204 - samples/sec: 459.49\n",
      "2020-05-17 15:04:11,638 epoch 2 - iter 378/429 - loss 1.37014989 - samples/sec: 460.67\n",
      "2020-05-17 15:04:14,618 epoch 2 - iter 420/429 - loss 1.36685264 - samples/sec: 452.39\n",
      "2020-05-17 15:04:15,189 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:04:15,190 EPOCH 2 done: loss 1.3668 - lr 0.1000\n",
      "2020-05-17 15:04:16,060 DEV : loss 1.254705548286438 - score 0.472\n",
      "2020-05-17 15:04:16,127 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:04:25,483 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:04:25,562 epoch 3 - iter 0/429 - loss 1.16742408 - samples/sec: 17695.93\n",
      "2020-05-17 15:04:28,543 epoch 3 - iter 42/429 - loss 1.32048711 - samples/sec: 452.21\n",
      "2020-05-17 15:04:31,554 epoch 3 - iter 84/429 - loss 1.32735584 - samples/sec: 447.53\n",
      "2020-05-17 15:04:34,673 epoch 3 - iter 126/429 - loss 1.32168505 - samples/sec: 432.26\n",
      "2020-05-17 15:04:37,691 epoch 3 - iter 168/429 - loss 1.31728617 - samples/sec: 447.39\n",
      "2020-05-17 15:04:40,663 epoch 3 - iter 210/429 - loss 1.32755368 - samples/sec: 453.57\n",
      "2020-05-17 15:04:43,650 epoch 3 - iter 252/429 - loss 1.32362311 - samples/sec: 451.41\n",
      "2020-05-17 15:04:46,626 epoch 3 - iter 294/429 - loss 1.31659115 - samples/sec: 453.00\n",
      "2020-05-17 15:04:49,622 epoch 3 - iter 336/429 - loss 1.31761382 - samples/sec: 450.03\n",
      "2020-05-17 15:04:52,591 epoch 3 - iter 378/429 - loss 1.31266531 - samples/sec: 454.25\n",
      "2020-05-17 15:04:55,565 epoch 3 - iter 420/429 - loss 1.30740222 - samples/sec: 453.23\n",
      "2020-05-17 15:04:56,143 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:04:56,144 EPOCH 3 done: loss 1.3071 - lr 0.1000\n",
      "2020-05-17 15:04:56,949 DEV : loss 1.1779992580413818 - score 0.542\n",
      "2020-05-17 15:04:57,015 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:05:06,283 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:05:06,367 epoch 4 - iter 0/429 - loss 1.09460914 - samples/sec: 16674.64\n",
      "2020-05-17 15:05:09,519 epoch 4 - iter 42/429 - loss 1.27156980 - samples/sec: 427.83\n",
      "2020-05-17 15:05:12,787 epoch 4 - iter 84/429 - loss 1.25248329 - samples/sec: 412.25\n",
      "2020-05-17 15:05:15,835 epoch 4 - iter 126/429 - loss 1.24406763 - samples/sec: 442.69\n",
      "2020-05-17 15:05:18,855 epoch 4 - iter 168/429 - loss 1.25058204 - samples/sec: 446.71\n",
      "2020-05-17 15:05:22,046 epoch 4 - iter 210/429 - loss 1.25389085 - samples/sec: 422.38\n",
      "2020-05-17 15:05:25,210 epoch 4 - iter 252/429 - loss 1.25209855 - samples/sec: 426.30\n",
      "2020-05-17 15:05:28,319 epoch 4 - iter 294/429 - loss 1.25025086 - samples/sec: 434.27\n",
      "2020-05-17 15:05:31,403 epoch 4 - iter 336/429 - loss 1.25007687 - samples/sec: 437.04\n",
      "2020-05-17 15:05:34,488 epoch 4 - iter 378/429 - loss 1.24866978 - samples/sec: 437.02\n",
      "2020-05-17 15:05:37,680 epoch 4 - iter 420/429 - loss 1.24749801 - samples/sec: 422.19\n",
      "2020-05-17 15:05:38,299 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:05:38,300 EPOCH 4 done: loss 1.2489 - lr 0.1000\n",
      "2020-05-17 15:05:39,217 DEV : loss 1.1778156757354736 - score 0.504\n",
      "2020-05-17 15:05:39,288 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:05:39,290 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:05:39,392 epoch 5 - iter 0/429 - loss 1.31005871 - samples/sec: 13876.94\n",
      "2020-05-17 15:05:42,624 epoch 5 - iter 42/429 - loss 1.22435587 - samples/sec: 417.04\n",
      "2020-05-17 15:05:45,750 epoch 5 - iter 84/429 - loss 1.23246663 - samples/sec: 432.09\n",
      "2020-05-17 15:05:48,898 epoch 5 - iter 126/429 - loss 1.22228491 - samples/sec: 428.23\n",
      "2020-05-17 15:05:51,991 epoch 5 - iter 168/429 - loss 1.22552017 - samples/sec: 436.28\n",
      "2020-05-17 15:05:55,147 epoch 5 - iter 210/429 - loss 1.22230238 - samples/sec: 427.07\n",
      "2020-05-17 15:05:58,322 epoch 5 - iter 252/429 - loss 1.21946755 - samples/sec: 424.53\n",
      "2020-05-17 15:06:01,251 epoch 5 - iter 294/429 - loss 1.21567162 - samples/sec: 460.19\n",
      "2020-05-17 15:06:04,404 epoch 5 - iter 336/429 - loss 1.21791394 - samples/sec: 428.19\n",
      "2020-05-17 15:06:07,531 epoch 5 - iter 378/429 - loss 1.21453316 - samples/sec: 431.20\n",
      "2020-05-17 15:06:10,675 epoch 5 - iter 420/429 - loss 1.21388010 - samples/sec: 428.68\n",
      "2020-05-17 15:06:11,282 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:06:11,283 EPOCH 5 done: loss 1.2136 - lr 0.1000\n",
      "2020-05-17 15:06:12,134 DEV : loss 1.2032792568206787 - score 0.51\n",
      "2020-05-17 15:06:12,203 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 15:06:12,205 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:06:12,283 epoch 6 - iter 0/429 - loss 0.99712533 - samples/sec: 17844.77\n",
      "2020-05-17 15:06:15,424 epoch 6 - iter 42/429 - loss 1.17948628 - samples/sec: 430.59\n",
      "2020-05-17 15:06:18,579 epoch 6 - iter 84/429 - loss 1.18652441 - samples/sec: 427.28\n",
      "2020-05-17 15:06:21,707 epoch 6 - iter 126/429 - loss 1.19243742 - samples/sec: 431.02\n",
      "2020-05-17 15:06:24,834 epoch 6 - iter 168/429 - loss 1.19332643 - samples/sec: 430.97\n",
      "2020-05-17 15:06:27,968 epoch 6 - iter 210/429 - loss 1.19137357 - samples/sec: 430.08\n",
      "2020-05-17 15:06:31,144 epoch 6 - iter 252/429 - loss 1.19339662 - samples/sec: 424.48\n",
      "2020-05-17 15:06:34,370 epoch 6 - iter 294/429 - loss 1.19299224 - samples/sec: 417.83\n",
      "2020-05-17 15:06:37,622 epoch 6 - iter 336/429 - loss 1.19004692 - samples/sec: 414.45\n",
      "2020-05-17 15:06:40,811 epoch 6 - iter 378/429 - loss 1.18864757 - samples/sec: 422.58\n",
      "2020-05-17 15:06:44,087 epoch 6 - iter 420/429 - loss 1.18917443 - samples/sec: 411.70\n",
      "2020-05-17 15:06:44,676 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:06:44,678 EPOCH 6 done: loss 1.1902 - lr 0.1000\n",
      "2020-05-17 15:06:45,589 DEV : loss 1.2512544393539429 - score 0.516\n",
      "2020-05-17 15:06:45,652 BAD EPOCHS (no improvement): 3\n",
      "2020-05-17 15:06:45,654 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:06:45,720 epoch 7 - iter 0/429 - loss 1.18213904 - samples/sec: 20793.60\n",
      "2020-05-17 15:06:48,922 epoch 7 - iter 42/429 - loss 1.17583579 - samples/sec: 420.90\n",
      "2020-05-17 15:06:52,114 epoch 7 - iter 84/429 - loss 1.16620721 - samples/sec: 422.16\n",
      "2020-05-17 15:06:55,342 epoch 7 - iter 126/429 - loss 1.15230437 - samples/sec: 417.66\n",
      "2020-05-17 15:06:58,567 epoch 7 - iter 168/429 - loss 1.15668441 - samples/sec: 418.00\n",
      "2020-05-17 15:07:01,729 epoch 7 - iter 210/429 - loss 1.15994338 - samples/sec: 426.39\n",
      "2020-05-17 15:07:04,938 epoch 7 - iter 252/429 - loss 1.15989511 - samples/sec: 420.05\n",
      "2020-05-17 15:07:08,130 epoch 7 - iter 294/429 - loss 1.15922501 - samples/sec: 422.21\n",
      "2020-05-17 15:07:11,315 epoch 7 - iter 336/429 - loss 1.16254330 - samples/sec: 423.10\n",
      "2020-05-17 15:07:14,451 epoch 7 - iter 378/429 - loss 1.16383530 - samples/sec: 429.93\n",
      "2020-05-17 15:07:17,646 epoch 7 - iter 420/429 - loss 1.16194143 - samples/sec: 423.01\n",
      "2020-05-17 15:07:18,216 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:07:18,218 EPOCH 7 done: loss 1.1626 - lr 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:07:19,012 DEV : loss 1.104432225227356 - score 0.542\n",
      "2020-05-17 15:07:19,075 BAD EPOCHS (no improvement): 4\n",
      "2020-05-17 15:07:28,381 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:07:28,458 epoch 8 - iter 0/429 - loss 1.05615699 - samples/sec: 17982.53\n",
      "2020-05-17 15:07:31,409 epoch 8 - iter 42/429 - loss 1.14649880 - samples/sec: 456.79\n",
      "2020-05-17 15:07:34,590 epoch 8 - iter 84/429 - loss 1.15708696 - samples/sec: 423.86\n",
      "2020-05-17 15:07:37,736 epoch 8 - iter 126/429 - loss 1.15409450 - samples/sec: 428.54\n",
      "2020-05-17 15:07:40,985 epoch 8 - iter 168/429 - loss 1.15004397 - samples/sec: 414.98\n",
      "2020-05-17 15:07:44,141 epoch 8 - iter 210/429 - loss 1.14667066 - samples/sec: 427.11\n",
      "2020-05-17 15:07:47,184 epoch 8 - iter 252/429 - loss 1.14609123 - samples/sec: 442.90\n",
      "2020-05-17 15:07:50,344 epoch 8 - iter 294/429 - loss 1.14332324 - samples/sec: 426.81\n",
      "2020-05-17 15:07:53,493 epoch 8 - iter 336/429 - loss 1.14472948 - samples/sec: 428.43\n",
      "2020-05-17 15:07:56,555 epoch 8 - iter 378/429 - loss 1.14653544 - samples/sec: 440.21\n",
      "2020-05-17 15:07:59,503 epoch 8 - iter 420/429 - loss 1.14451056 - samples/sec: 458.31\n",
      "2020-05-17 15:08:00,073 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:08:00,074 EPOCH 8 done: loss 1.1429 - lr 0.1000\n",
      "2020-05-17 15:08:00,864 DEV : loss 1.1999380588531494 - score 0.496\n",
      "2020-05-17 15:08:00,928 BAD EPOCHS (no improvement): 5\n",
      "2020-05-17 15:08:00,929 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:08:01,002 epoch 9 - iter 0/429 - loss 1.33241284 - samples/sec: 19256.75\n",
      "2020-05-17 15:08:03,854 epoch 9 - iter 42/429 - loss 1.15450066 - samples/sec: 472.60\n",
      "2020-05-17 15:08:06,815 epoch 9 - iter 84/429 - loss 1.14633299 - samples/sec: 455.19\n",
      "2020-05-17 15:08:09,954 epoch 9 - iter 126/429 - loss 1.13154134 - samples/sec: 429.80\n",
      "2020-05-17 15:08:13,163 epoch 9 - iter 168/429 - loss 1.12945700 - samples/sec: 420.05\n",
      "2020-05-17 15:08:16,506 epoch 9 - iter 210/429 - loss 1.12877356 - samples/sec: 403.05\n",
      "2020-05-17 15:08:19,487 epoch 9 - iter 252/429 - loss 1.13007292 - samples/sec: 452.48\n",
      "2020-05-17 15:08:22,444 epoch 9 - iter 294/429 - loss 1.13177765 - samples/sec: 455.85\n",
      "2020-05-17 15:08:25,356 epoch 9 - iter 336/429 - loss 1.13173473 - samples/sec: 462.90\n",
      "2020-05-17 15:08:28,359 epoch 9 - iter 378/429 - loss 1.13009639 - samples/sec: 448.82\n",
      "2020-05-17 15:08:31,367 epoch 9 - iter 420/429 - loss 1.12698940 - samples/sec: 448.41\n",
      "2020-05-17 15:08:31,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:08:31,938 EPOCH 9 done: loss 1.1271 - lr 0.1000\n",
      "2020-05-17 15:08:32,730 DEV : loss 1.068070411682129 - score 0.552\n",
      "2020-05-17 15:08:32,800 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:08:42,124 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:08:42,205 epoch 10 - iter 0/429 - loss 1.16809833 - samples/sec: 17195.33\n",
      "2020-05-17 15:08:45,197 epoch 10 - iter 42/429 - loss 1.10651009 - samples/sec: 450.48\n",
      "2020-05-17 15:08:48,205 epoch 10 - iter 84/429 - loss 1.10501900 - samples/sec: 448.30\n",
      "2020-05-17 15:08:51,316 epoch 10 - iter 126/429 - loss 1.11337723 - samples/sec: 433.36\n",
      "2020-05-17 15:08:54,507 epoch 10 - iter 168/429 - loss 1.11812989 - samples/sec: 422.34\n",
      "2020-05-17 15:08:57,825 epoch 10 - iter 210/429 - loss 1.13065390 - samples/sec: 406.20\n",
      "2020-05-17 15:09:01,019 epoch 10 - iter 252/429 - loss 1.12572297 - samples/sec: 421.97\n",
      "2020-05-17 15:09:04,158 epoch 10 - iter 294/429 - loss 1.12802731 - samples/sec: 429.30\n",
      "2020-05-17 15:09:07,722 epoch 10 - iter 336/429 - loss 1.12074997 - samples/sec: 378.11\n",
      "2020-05-17 15:09:10,774 epoch 10 - iter 378/429 - loss 1.12017392 - samples/sec: 441.57\n",
      "2020-05-17 15:09:13,955 epoch 10 - iter 420/429 - loss 1.11635142 - samples/sec: 423.51\n",
      "2020-05-17 15:09:14,570 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:09:14,572 EPOCH 10 done: loss 1.1184 - lr 0.1000\n",
      "2020-05-17 15:09:15,513 DEV : loss 1.079099416732788 - score 0.564\n",
      "2020-05-17 15:09:15,580 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:09:25,644 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:09:25,732 epoch 11 - iter 0/429 - loss 1.21964896 - samples/sec: 15749.65\n",
      "2020-05-17 15:09:29,059 epoch 11 - iter 42/429 - loss 1.10067546 - samples/sec: 405.09\n",
      "2020-05-17 15:09:32,410 epoch 11 - iter 84/429 - loss 1.09924067 - samples/sec: 402.78\n",
      "2020-05-17 15:09:35,650 epoch 11 - iter 126/429 - loss 1.09412759 - samples/sec: 416.05\n",
      "2020-05-17 15:09:38,888 epoch 11 - iter 168/429 - loss 1.10557196 - samples/sec: 416.47\n",
      "2020-05-17 15:09:42,161 epoch 11 - iter 210/429 - loss 1.09900247 - samples/sec: 411.76\n",
      "2020-05-17 15:09:45,386 epoch 11 - iter 252/429 - loss 1.09599540 - samples/sec: 417.92\n",
      "2020-05-17 15:09:48,755 epoch 11 - iter 294/429 - loss 1.09530045 - samples/sec: 400.40\n",
      "2020-05-17 15:09:52,147 epoch 11 - iter 336/429 - loss 1.09261341 - samples/sec: 397.25\n",
      "2020-05-17 15:09:55,540 epoch 11 - iter 378/429 - loss 1.08903887 - samples/sec: 397.12\n",
      "2020-05-17 15:09:58,955 epoch 11 - iter 420/429 - loss 1.08979837 - samples/sec: 394.61\n",
      "2020-05-17 15:09:59,599 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:09:59,601 EPOCH 11 done: loss 1.0919 - lr 0.1000\n",
      "2020-05-17 15:10:00,534 DEV : loss 1.0269696712493896 - score 0.58\n",
      "2020-05-17 15:10:00,601 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:10:10,520 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:10:10,615 epoch 12 - iter 0/429 - loss 1.10612631 - samples/sec: 14511.97\n",
      "2020-05-17 15:10:13,925 epoch 12 - iter 42/429 - loss 1.08676209 - samples/sec: 407.09\n",
      "2020-05-17 15:10:17,215 epoch 12 - iter 84/429 - loss 1.08822545 - samples/sec: 409.81\n",
      "2020-05-17 15:10:20,483 epoch 12 - iter 126/429 - loss 1.08891097 - samples/sec: 413.41\n",
      "2020-05-17 15:10:23,730 epoch 12 - iter 168/429 - loss 1.08941849 - samples/sec: 415.09\n",
      "2020-05-17 15:10:26,883 epoch 12 - iter 210/429 - loss 1.08247819 - samples/sec: 427.53\n",
      "2020-05-17 15:10:30,211 epoch 12 - iter 252/429 - loss 1.08648365 - samples/sec: 405.12\n",
      "2020-05-17 15:10:33,481 epoch 12 - iter 294/429 - loss 1.08739501 - samples/sec: 412.18\n",
      "2020-05-17 15:10:36,744 epoch 12 - iter 336/429 - loss 1.08534146 - samples/sec: 413.28\n",
      "2020-05-17 15:10:39,927 epoch 12 - iter 378/429 - loss 1.08414682 - samples/sec: 424.63\n",
      "2020-05-17 15:10:43,200 epoch 12 - iter 420/429 - loss 1.08128139 - samples/sec: 411.78\n",
      "2020-05-17 15:10:43,842 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:10:43,842 EPOCH 12 done: loss 1.0817 - lr 0.1000\n",
      "2020-05-17 15:10:44,749 DEV : loss 1.0953871011734009 - score 0.55\n",
      "2020-05-17 15:10:44,816 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:10:44,817 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:10:44,899 epoch 13 - iter 0/429 - loss 1.15305793 - samples/sec: 16527.48\n",
      "2020-05-17 15:10:47,907 epoch 13 - iter 42/429 - loss 1.05302914 - samples/sec: 448.04\n",
      "2020-05-17 15:10:51,087 epoch 13 - iter 84/429 - loss 1.05742397 - samples/sec: 424.06\n",
      "2020-05-17 15:10:54,478 epoch 13 - iter 126/429 - loss 1.06363571 - samples/sec: 397.46\n",
      "2020-05-17 15:10:57,731 epoch 13 - iter 168/429 - loss 1.05960514 - samples/sec: 414.28\n",
      "2020-05-17 15:11:00,959 epoch 13 - iter 210/429 - loss 1.06195124 - samples/sec: 417.64\n",
      "2020-05-17 15:11:04,246 epoch 13 - iter 252/429 - loss 1.06421920 - samples/sec: 410.10\n",
      "2020-05-17 15:11:07,447 epoch 13 - iter 294/429 - loss 1.06723372 - samples/sec: 421.14\n",
      "2020-05-17 15:11:10,731 epoch 13 - iter 336/429 - loss 1.06358934 - samples/sec: 410.75\n",
      "2020-05-17 15:11:13,887 epoch 13 - iter 378/429 - loss 1.06158719 - samples/sec: 427.47\n",
      "2020-05-17 15:11:17,151 epoch 13 - iter 420/429 - loss 1.06247010 - samples/sec: 413.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:11:17,767 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:11:17,768 EPOCH 13 done: loss 1.0609 - lr 0.1000\n",
      "2020-05-17 15:11:18,704 DEV : loss 1.0136406421661377 - score 0.586\n",
      "2020-05-17 15:11:18,772 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:11:28,552 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:11:28,634 epoch 14 - iter 0/429 - loss 0.71913862 - samples/sec: 17252.16\n",
      "2020-05-17 15:11:31,900 epoch 14 - iter 42/429 - loss 1.03049056 - samples/sec: 412.74\n",
      "2020-05-17 15:11:35,107 epoch 14 - iter 84/429 - loss 1.03517302 - samples/sec: 420.14\n",
      "2020-05-17 15:11:38,498 epoch 14 - iter 126/429 - loss 1.03354533 - samples/sec: 397.54\n",
      "2020-05-17 15:11:41,736 epoch 14 - iter 168/429 - loss 1.05120019 - samples/sec: 416.07\n",
      "2020-05-17 15:11:45,170 epoch 14 - iter 210/429 - loss 1.04613699 - samples/sec: 392.48\n",
      "2020-05-17 15:11:48,527 epoch 14 - iter 252/429 - loss 1.04034895 - samples/sec: 401.54\n",
      "2020-05-17 15:11:51,838 epoch 14 - iter 294/429 - loss 1.04372298 - samples/sec: 407.17\n",
      "2020-05-17 15:11:55,130 epoch 14 - iter 336/429 - loss 1.04345026 - samples/sec: 409.31\n",
      "2020-05-17 15:11:58,442 epoch 14 - iter 378/429 - loss 1.04444838 - samples/sec: 406.98\n",
      "2020-05-17 15:12:01,745 epoch 14 - iter 420/429 - loss 1.04513183 - samples/sec: 408.91\n",
      "2020-05-17 15:12:02,357 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:12:02,358 EPOCH 14 done: loss 1.0457 - lr 0.1000\n",
      "2020-05-17 15:12:03,296 DEV : loss 1.159037709236145 - score 0.568\n",
      "2020-05-17 15:12:03,362 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:12:03,363 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:12:03,442 epoch 15 - iter 0/429 - loss 1.16263974 - samples/sec: 17497.15\n",
      "2020-05-17 15:12:06,836 epoch 15 - iter 42/429 - loss 1.01049127 - samples/sec: 397.49\n",
      "2020-05-17 15:12:10,235 epoch 15 - iter 84/429 - loss 1.02696826 - samples/sec: 396.49\n",
      "2020-05-17 15:12:13,586 epoch 15 - iter 126/429 - loss 1.02043647 - samples/sec: 402.20\n",
      "2020-05-17 15:12:16,965 epoch 15 - iter 168/429 - loss 1.01293545 - samples/sec: 398.87\n",
      "2020-05-17 15:12:20,325 epoch 15 - iter 210/429 - loss 1.01444210 - samples/sec: 401.08\n",
      "2020-05-17 15:12:23,605 epoch 15 - iter 252/429 - loss 1.01408564 - samples/sec: 410.88\n",
      "2020-05-17 15:12:26,941 epoch 15 - iter 294/429 - loss 1.01650366 - samples/sec: 404.23\n",
      "2020-05-17 15:12:30,279 epoch 15 - iter 336/429 - loss 1.01537065 - samples/sec: 403.68\n",
      "2020-05-17 15:12:33,659 epoch 15 - iter 378/429 - loss 1.01730165 - samples/sec: 399.16\n",
      "2020-05-17 15:12:39,015 epoch 15 - iter 420/429 - loss 1.01915400 - samples/sec: 251.37\n",
      "2020-05-17 15:12:39,652 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:12:39,653 EPOCH 15 done: loss 1.0195 - lr 0.1000\n",
      "2020-05-17 15:12:40,563 DEV : loss 1.3353164196014404 - score 0.562\n",
      "2020-05-17 15:12:40,629 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 15:12:50,576 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:12:50,577 Testing using best model ...\n",
      "2020-05-17 15:12:50,579 loading file best-model.pt\n",
      "2020-05-17 15:12:52,975 0.634\t0.634\t0.634\n",
      "2020-05-17 15:12:52,976 \n",
      "MICRO_AVG: acc 0.4641 - f1-score 0.634\n",
      "MACRO_AVG: acc 0.3568 - f1-score 0.48336000000000007\n",
      "0          tp: 116 - fp: 39 - fn: 30 - tn: 315 - precision: 0.7484 - recall: 0.7945 - accuracy: 0.6270 - f1-score: 0.7708\n",
      "1          tp: 27 - fp: 13 - fn: 61 - tn: 399 - precision: 0.6750 - recall: 0.3068 - accuracy: 0.2673 - f1-score: 0.4219\n",
      "2          tp: 0 - fp: 0 - fn: 10 - tn: 490 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "3          tp: 107 - fp: 48 - fn: 51 - tn: 294 - precision: 0.6903 - recall: 0.6772 - accuracy: 0.5194 - f1-score: 0.6837\n",
      "4          tp: 67 - fp: 83 - fn: 31 - tn: 319 - precision: 0.4467 - recall: 0.6837 - accuracy: 0.3702 - f1-score: 0.5404\n",
      "2020-05-17 15:12:52,976 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "elmo\n",
      "2020-05-17 15:13:25,529 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 15:13:25,530 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 15:13:25,531 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 15:13:25,532 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:13:42,807 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 243334.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:13:42,867 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 15:13:42,868 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 264362.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:13:42,924 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 15:13:42,930 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:13:42,931 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): ELMoEmbeddings(model=0-elmo-original)\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=3072, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 15:13:42,932 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:13:42,933 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 15:13:42,933 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:13:42,934 Parameters:\n",
      "2020-05-17 15:13:42,934  - learning_rate: \"0.1\"\n",
      "2020-05-17 15:13:42,935  - mini_batch_size: \"32\"\n",
      "2020-05-17 15:13:42,935  - patience: \"5\"\n",
      "2020-05-17 15:13:42,936  - anneal_factor: \"0.5\"\n",
      "2020-05-17 15:13:42,937  - max_epochs: \"15\"\n",
      "2020-05-17 15:13:42,938  - shuffle: \"True\"\n",
      "2020-05-17 15:13:42,939  - train_with_dev: \"False\"\n",
      "2020-05-17 15:13:42,939  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 15:13:42,940 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:13:42,940 Model training base path: \".\"\n",
      "2020-05-17 15:13:42,941 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:13:42,942 Device: cuda:0\n",
      "2020-05-17 15:13:42,943 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:13:42,944 Embeddings storage mode: cpu\n",
      "2020-05-17 15:13:42,947 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:13:43,451 epoch 1 - iter 0/429 - loss 1.59219003 - samples/sec: 2677.00\n",
      "2020-05-17 15:14:04,222 epoch 1 - iter 42/429 - loss 1.32942523 - samples/sec: 64.73\n",
      "2020-05-17 15:14:25,115 epoch 1 - iter 84/429 - loss 1.26155745 - samples/sec: 64.36\n",
      "2020-05-17 15:14:46,123 epoch 1 - iter 126/429 - loss 1.23122434 - samples/sec: 64.00\n",
      "2020-05-17 15:15:06,699 epoch 1 - iter 168/429 - loss 1.20584597 - samples/sec: 65.35\n",
      "2020-05-17 15:15:26,632 epoch 1 - iter 210/429 - loss 1.17989902 - samples/sec: 67.46\n",
      "2020-05-17 15:15:46,573 epoch 1 - iter 252/429 - loss 1.15719575 - samples/sec: 67.43\n",
      "2020-05-17 15:16:09,042 epoch 1 - iter 294/429 - loss 1.14250289 - samples/sec: 59.84\n",
      "2020-05-17 15:16:29,137 epoch 1 - iter 336/429 - loss 1.12845745 - samples/sec: 66.93\n",
      "2020-05-17 15:16:49,135 epoch 1 - iter 378/429 - loss 1.11862881 - samples/sec: 67.24\n",
      "2020-05-17 15:17:09,160 epoch 1 - iter 420/429 - loss 1.10552740 - samples/sec: 67.15\n",
      "2020-05-17 15:17:12,839 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:17:12,840 EPOCH 1 done: loss 1.1038 - lr 0.1000\n",
      "2020-05-17 15:17:19,952 DEV : loss 1.068102240562439 - score 0.574\n",
      "2020-05-17 15:17:20,018 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ELMoEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _ElmoBiLm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _ElmoCharacterEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Highway. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ElmoLstm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LstmCellWithProjection. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:17:21,198 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:17:21,272 epoch 2 - iter 0/429 - loss 0.81793642 - samples/sec: 19013.32\n",
      "2020-05-17 15:17:24,568 epoch 2 - iter 42/429 - loss 0.94525675 - samples/sec: 409.57\n",
      "2020-05-17 15:17:28,010 epoch 2 - iter 84/429 - loss 0.94374180 - samples/sec: 391.75\n",
      "2020-05-17 15:17:31,497 epoch 2 - iter 126/429 - loss 0.93746258 - samples/sec: 386.38\n",
      "2020-05-17 15:17:35,028 epoch 2 - iter 168/429 - loss 0.94032681 - samples/sec: 381.63\n",
      "2020-05-17 15:17:38,524 epoch 2 - iter 210/429 - loss 0.93683939 - samples/sec: 385.41\n",
      "2020-05-17 15:17:42,070 epoch 2 - iter 252/429 - loss 0.93591073 - samples/sec: 380.03\n",
      "2020-05-17 15:17:45,561 epoch 2 - iter 294/429 - loss 0.94224333 - samples/sec: 386.03\n",
      "2020-05-17 15:17:48,816 epoch 2 - iter 336/429 - loss 0.94593177 - samples/sec: 414.03\n",
      "2020-05-17 15:17:52,387 epoch 2 - iter 378/429 - loss 0.94446101 - samples/sec: 377.22\n",
      "2020-05-17 15:17:55,933 epoch 2 - iter 420/429 - loss 0.94165411 - samples/sec: 380.64\n",
      "2020-05-17 15:17:56,610 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:17:56,611 EPOCH 2 done: loss 0.9407 - lr 0.1000\n",
      "2020-05-17 15:17:57,579 DEV : loss 0.9486087560653687 - score 0.622\n",
      "2020-05-17 15:17:57,642 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:17:58,743 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:17:58,836 epoch 3 - iter 0/429 - loss 0.79264182 - samples/sec: 14936.67\n",
      "2020-05-17 15:18:02,339 epoch 3 - iter 42/429 - loss 0.86548988 - samples/sec: 384.54\n",
      "2020-05-17 15:18:05,888 epoch 3 - iter 84/429 - loss 0.86984294 - samples/sec: 380.19\n",
      "2020-05-17 15:18:09,414 epoch 3 - iter 126/429 - loss 0.86720083 - samples/sec: 382.24\n",
      "2020-05-17 15:18:12,951 epoch 3 - iter 168/429 - loss 0.86279127 - samples/sec: 381.06\n",
      "2020-05-17 15:18:16,609 epoch 3 - iter 210/429 - loss 0.86577044 - samples/sec: 368.83\n",
      "2020-05-17 15:18:20,230 epoch 3 - iter 252/429 - loss 0.85718587 - samples/sec: 372.18\n",
      "2020-05-17 15:18:23,796 epoch 3 - iter 294/429 - loss 0.86032131 - samples/sec: 377.79\n",
      "2020-05-17 15:18:27,407 epoch 3 - iter 336/429 - loss 0.86346616 - samples/sec: 373.18\n",
      "2020-05-17 15:18:30,973 epoch 3 - iter 378/429 - loss 0.86245575 - samples/sec: 377.78\n",
      "2020-05-17 15:18:34,552 epoch 3 - iter 420/429 - loss 0.85717216 - samples/sec: 377.05\n",
      "2020-05-17 15:18:35,236 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:18:35,237 EPOCH 3 done: loss 0.8564 - lr 0.1000\n",
      "2020-05-17 15:18:36,233 DEV : loss 1.0056898593902588 - score 0.61\n",
      "2020-05-17 15:18:36,296 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:18:36,298 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:18:36,393 epoch 4 - iter 0/429 - loss 0.55725914 - samples/sec: 14637.83\n",
      "2020-05-17 15:18:39,860 epoch 4 - iter 42/429 - loss 0.78796078 - samples/sec: 388.50\n",
      "2020-05-17 15:18:43,495 epoch 4 - iter 84/429 - loss 0.77573036 - samples/sec: 370.76\n",
      "2020-05-17 15:18:47,067 epoch 4 - iter 126/429 - loss 0.77213367 - samples/sec: 377.31\n",
      "2020-05-17 15:18:50,571 epoch 4 - iter 168/429 - loss 0.77484082 - samples/sec: 384.94\n",
      "2020-05-17 15:18:54,244 epoch 4 - iter 210/429 - loss 0.79111512 - samples/sec: 366.92\n",
      "2020-05-17 15:18:57,881 epoch 4 - iter 252/429 - loss 0.79344118 - samples/sec: 370.49\n",
      "2020-05-17 15:19:01,575 epoch 4 - iter 294/429 - loss 0.78902807 - samples/sec: 364.99\n",
      "2020-05-17 15:19:05,315 epoch 4 - iter 336/429 - loss 0.79459474 - samples/sec: 360.09\n",
      "2020-05-17 15:19:08,876 epoch 4 - iter 378/429 - loss 0.79038269 - samples/sec: 378.52\n",
      "2020-05-17 15:19:12,521 epoch 4 - iter 420/429 - loss 0.78735309 - samples/sec: 369.65\n",
      "2020-05-17 15:19:13,148 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:19:13,149 EPOCH 4 done: loss 0.7889 - lr 0.1000\n",
      "2020-05-17 15:19:14,146 DEV : loss 0.8281689882278442 - score 0.678\n",
      "2020-05-17 15:19:14,212 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:19:15,368 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:19:15,460 epoch 5 - iter 0/429 - loss 0.60067552 - samples/sec: 15273.34\n",
      "2020-05-17 15:19:19,110 epoch 5 - iter 42/429 - loss 0.69752747 - samples/sec: 369.08\n",
      "2020-05-17 15:19:22,806 epoch 5 - iter 84/429 - loss 0.70758568 - samples/sec: 364.66\n",
      "2020-05-17 15:19:26,444 epoch 5 - iter 126/429 - loss 0.70227646 - samples/sec: 370.30\n",
      "2020-05-17 15:19:29,872 epoch 5 - iter 168/429 - loss 0.71271801 - samples/sec: 393.20\n",
      "2020-05-17 15:19:33,411 epoch 5 - iter 210/429 - loss 0.71553938 - samples/sec: 380.76\n",
      "2020-05-17 15:19:36,996 epoch 5 - iter 252/429 - loss 0.71142951 - samples/sec: 375.84\n",
      "2020-05-17 15:19:40,562 epoch 5 - iter 294/429 - loss 0.71626558 - samples/sec: 377.78\n",
      "2020-05-17 15:19:44,137 epoch 5 - iter 336/429 - loss 0.72308142 - samples/sec: 376.91\n",
      "2020-05-17 15:19:47,658 epoch 5 - iter 378/429 - loss 0.71915247 - samples/sec: 382.66\n",
      "2020-05-17 15:19:51,284 epoch 5 - iter 420/429 - loss 0.72017785 - samples/sec: 371.63\n",
      "2020-05-17 15:19:51,948 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:19:51,949 EPOCH 5 done: loss 0.7205 - lr 0.1000\n",
      "2020-05-17 15:19:52,932 DEV : loss 0.7688546180725098 - score 0.698\n",
      "2020-05-17 15:19:52,997 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:19:54,099 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:19:54,189 epoch 6 - iter 0/429 - loss 0.81518114 - samples/sec: 15284.10\n",
      "2020-05-17 15:19:57,763 epoch 6 - iter 42/429 - loss 0.65981028 - samples/sec: 377.01\n",
      "2020-05-17 15:20:01,395 epoch 6 - iter 84/429 - loss 0.65811589 - samples/sec: 371.05\n",
      "2020-05-17 15:20:04,962 epoch 6 - iter 126/429 - loss 0.65624632 - samples/sec: 377.83\n",
      "2020-05-17 15:20:08,461 epoch 6 - iter 168/429 - loss 0.66533451 - samples/sec: 385.13\n",
      "2020-05-17 15:20:12,076 epoch 6 - iter 210/429 - loss 0.66704604 - samples/sec: 372.80\n",
      "2020-05-17 15:20:15,663 epoch 6 - iter 252/429 - loss 0.66828910 - samples/sec: 375.55\n",
      "2020-05-17 15:20:19,246 epoch 6 - iter 294/429 - loss 0.66924252 - samples/sec: 376.84\n",
      "2020-05-17 15:20:22,799 epoch 6 - iter 336/429 - loss 0.67142652 - samples/sec: 379.21\n",
      "2020-05-17 15:20:26,429 epoch 6 - iter 378/429 - loss 0.67099101 - samples/sec: 371.11\n",
      "2020-05-17 15:20:30,007 epoch 6 - iter 420/429 - loss 0.66966986 - samples/sec: 376.61\n",
      "2020-05-17 15:20:30,676 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:20:30,677 EPOCH 6 done: loss 0.6696 - lr 0.1000\n",
      "2020-05-17 15:20:31,669 DEV : loss 0.8351131081581116 - score 0.692\n",
      "2020-05-17 15:20:31,733 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:20:31,734 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:20:31,819 epoch 7 - iter 0/429 - loss 0.55958158 - samples/sec: 16183.48\n",
      "2020-05-17 15:20:35,410 epoch 7 - iter 42/429 - loss 0.63112873 - samples/sec: 375.22\n",
      "2020-05-17 15:20:38,689 epoch 7 - iter 84/429 - loss 0.63509513 - samples/sec: 411.00\n",
      "2020-05-17 15:20:42,248 epoch 7 - iter 126/429 - loss 0.61589083 - samples/sec: 378.85\n",
      "2020-05-17 15:20:45,867 epoch 7 - iter 168/429 - loss 0.62173892 - samples/sec: 372.36\n",
      "2020-05-17 15:20:49,526 epoch 7 - iter 210/429 - loss 0.62020252 - samples/sec: 368.67\n",
      "2020-05-17 15:20:53,159 epoch 7 - iter 252/429 - loss 0.62056712 - samples/sec: 370.83\n",
      "2020-05-17 15:20:56,653 epoch 7 - iter 294/429 - loss 0.62172268 - samples/sec: 385.59\n",
      "2020-05-17 15:21:00,266 epoch 7 - iter 336/429 - loss 0.62425992 - samples/sec: 373.15\n",
      "2020-05-17 15:21:03,887 epoch 7 - iter 378/429 - loss 0.62653561 - samples/sec: 372.29\n",
      "2020-05-17 15:21:07,496 epoch 7 - iter 420/429 - loss 0.62448859 - samples/sec: 373.41\n",
      "2020-05-17 15:21:08,123 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:21:08,124 EPOCH 7 done: loss 0.6249 - lr 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:21:09,107 DEV : loss 0.7821012735366821 - score 0.69\n",
      "2020-05-17 15:21:09,170 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 15:21:09,171 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:21:09,263 epoch 8 - iter 0/429 - loss 0.62723714 - samples/sec: 15014.21\n",
      "2020-05-17 15:21:12,810 epoch 8 - iter 42/429 - loss 0.55534861 - samples/sec: 379.86\n",
      "2020-05-17 15:21:16,368 epoch 8 - iter 84/429 - loss 0.55918250 - samples/sec: 378.86\n",
      "2020-05-17 15:21:19,847 epoch 8 - iter 126/429 - loss 0.56417803 - samples/sec: 387.94\n",
      "2020-05-17 15:21:23,435 epoch 8 - iter 168/429 - loss 0.56822268 - samples/sec: 375.63\n",
      "2020-05-17 15:21:27,098 epoch 8 - iter 210/429 - loss 0.56650969 - samples/sec: 367.89\n",
      "2020-05-17 15:21:30,723 epoch 8 - iter 252/429 - loss 0.56710586 - samples/sec: 371.67\n",
      "2020-05-17 15:21:34,293 epoch 8 - iter 294/429 - loss 0.57293475 - samples/sec: 378.12\n",
      "2020-05-17 15:21:37,908 epoch 8 - iter 336/429 - loss 0.57467836 - samples/sec: 372.83\n",
      "2020-05-17 15:21:41,512 epoch 8 - iter 378/429 - loss 0.57716455 - samples/sec: 373.86\n",
      "2020-05-17 15:21:45,242 epoch 8 - iter 420/429 - loss 0.57614194 - samples/sec: 361.23\n",
      "2020-05-17 15:21:45,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:21:45,939 EPOCH 8 done: loss 0.5766 - lr 0.1000\n",
      "2020-05-17 15:21:46,962 DEV : loss 0.7765580415725708 - score 0.704\n",
      "2020-05-17 15:21:47,034 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:21:48,198 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:21:48,296 epoch 9 - iter 0/429 - loss 0.44864720 - samples/sec: 14250.87\n",
      "2020-05-17 15:21:51,893 epoch 9 - iter 42/429 - loss 0.51285322 - samples/sec: 374.60\n",
      "2020-05-17 15:21:55,461 epoch 9 - iter 84/429 - loss 0.51345709 - samples/sec: 377.68\n",
      "2020-05-17 15:21:58,980 epoch 9 - iter 126/429 - loss 0.51145766 - samples/sec: 383.06\n",
      "2020-05-17 15:22:02,519 epoch 9 - iter 168/429 - loss 0.51669834 - samples/sec: 380.73\n",
      "2020-05-17 15:22:06,210 epoch 9 - iter 210/429 - loss 0.51412176 - samples/sec: 365.16\n",
      "2020-05-17 15:22:09,897 epoch 9 - iter 252/429 - loss 0.52399976 - samples/sec: 365.32\n",
      "2020-05-17 15:22:13,594 epoch 9 - iter 294/429 - loss 0.52873299 - samples/sec: 364.46\n",
      "2020-05-17 15:22:17,185 epoch 9 - iter 336/429 - loss 0.52937640 - samples/sec: 375.23\n",
      "2020-05-17 15:22:20,685 epoch 9 - iter 378/429 - loss 0.52753432 - samples/sec: 384.98\n",
      "2020-05-17 15:22:24,215 epoch 9 - iter 420/429 - loss 0.53419991 - samples/sec: 381.70\n",
      "2020-05-17 15:22:24,911 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:22:24,912 EPOCH 9 done: loss 0.5345 - lr 0.1000\n",
      "2020-05-17 15:22:25,820 DEV : loss 0.7968560457229614 - score 0.722\n",
      "2020-05-17 15:22:25,884 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:22:27,006 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:22:27,093 epoch 10 - iter 0/429 - loss 0.54429561 - samples/sec: 16044.20\n",
      "2020-05-17 15:22:30,489 epoch 10 - iter 42/429 - loss 0.47994896 - samples/sec: 396.84\n",
      "2020-05-17 15:22:33,706 epoch 10 - iter 84/429 - loss 0.47656864 - samples/sec: 418.94\n",
      "2020-05-17 15:22:36,991 epoch 10 - iter 126/429 - loss 0.48233981 - samples/sec: 410.17\n",
      "2020-05-17 15:22:40,283 epoch 10 - iter 168/429 - loss 0.48539291 - samples/sec: 410.03\n",
      "2020-05-17 15:22:43,532 epoch 10 - iter 210/429 - loss 0.49314271 - samples/sec: 414.90\n",
      "2020-05-17 15:22:46,804 epoch 10 - iter 252/429 - loss 0.49489260 - samples/sec: 411.90\n",
      "2020-05-17 15:22:50,114 epoch 10 - iter 294/429 - loss 0.49992488 - samples/sec: 407.15\n",
      "2020-05-17 15:22:53,389 epoch 10 - iter 336/429 - loss 0.49752381 - samples/sec: 411.55\n",
      "2020-05-17 15:22:56,688 epoch 10 - iter 378/429 - loss 0.49880742 - samples/sec: 408.77\n",
      "2020-05-17 15:23:00,111 epoch 10 - iter 420/429 - loss 0.49628928 - samples/sec: 393.71\n",
      "2020-05-17 15:23:00,733 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:23:00,734 EPOCH 10 done: loss 0.4981 - lr 0.1000\n",
      "2020-05-17 15:23:01,724 DEV : loss 0.7300011515617371 - score 0.746\n",
      "2020-05-17 15:23:01,789 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:23:02,942 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:23:03,028 epoch 11 - iter 0/429 - loss 0.30380699 - samples/sec: 16341.68\n",
      "2020-05-17 15:23:06,604 epoch 11 - iter 42/429 - loss 0.44498609 - samples/sec: 376.68\n",
      "2020-05-17 15:23:10,270 epoch 11 - iter 84/429 - loss 0.44912050 - samples/sec: 367.58\n",
      "2020-05-17 15:23:13,815 epoch 11 - iter 126/429 - loss 0.45189059 - samples/sec: 380.70\n",
      "2020-05-17 15:23:17,161 epoch 11 - iter 168/429 - loss 0.45645912 - samples/sec: 402.91\n",
      "2020-05-17 15:23:20,661 epoch 11 - iter 210/429 - loss 0.45590807 - samples/sec: 385.04\n",
      "2020-05-17 15:23:24,082 epoch 11 - iter 252/429 - loss 0.45510710 - samples/sec: 394.82\n",
      "2020-05-17 15:23:27,455 epoch 11 - iter 294/429 - loss 0.45487739 - samples/sec: 399.61\n",
      "2020-05-17 15:23:30,877 epoch 11 - iter 336/429 - loss 0.45482877 - samples/sec: 394.02\n",
      "2020-05-17 15:23:34,285 epoch 11 - iter 378/429 - loss 0.45631918 - samples/sec: 395.36\n",
      "2020-05-17 15:23:37,750 epoch 11 - iter 420/429 - loss 0.45314835 - samples/sec: 388.86\n",
      "2020-05-17 15:23:38,438 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:23:38,440 EPOCH 11 done: loss 0.4534 - lr 0.1000\n",
      "2020-05-17 15:23:39,418 DEV : loss 0.8463026285171509 - score 0.746\n",
      "2020-05-17 15:23:39,492 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:23:40,633 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:23:40,726 epoch 12 - iter 0/429 - loss 0.35786927 - samples/sec: 15031.54\n",
      "2020-05-17 15:23:44,452 epoch 12 - iter 42/429 - loss 0.38333061 - samples/sec: 361.51\n",
      "2020-05-17 15:23:48,031 epoch 12 - iter 84/429 - loss 0.41268213 - samples/sec: 376.49\n",
      "2020-05-17 15:23:51,688 epoch 12 - iter 126/429 - loss 0.41532274 - samples/sec: 368.40\n",
      "2020-05-17 15:23:55,308 epoch 12 - iter 168/429 - loss 0.41520950 - samples/sec: 372.94\n",
      "2020-05-17 15:23:58,893 epoch 12 - iter 210/429 - loss 0.41553115 - samples/sec: 375.95\n",
      "2020-05-17 15:24:02,471 epoch 12 - iter 252/429 - loss 0.42242892 - samples/sec: 376.66\n",
      "2020-05-17 15:24:05,986 epoch 12 - iter 294/429 - loss 0.42572507 - samples/sec: 383.32\n",
      "2020-05-17 15:24:09,669 epoch 12 - iter 336/429 - loss 0.42640916 - samples/sec: 366.36\n",
      "2020-05-17 15:24:13,299 epoch 12 - iter 378/429 - loss 0.43111154 - samples/sec: 371.89\n",
      "2020-05-17 15:24:16,919 epoch 12 - iter 420/429 - loss 0.43190039 - samples/sec: 372.13\n",
      "2020-05-17 15:24:17,614 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:24:17,615 EPOCH 12 done: loss 0.4321 - lr 0.1000\n",
      "2020-05-17 15:24:18,623 DEV : loss 0.8191906809806824 - score 0.74\n",
      "2020-05-17 15:24:18,691 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 15:24:18,692 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:24:18,788 epoch 13 - iter 0/429 - loss 0.36141825 - samples/sec: 14322.34\n",
      "2020-05-17 15:24:22,402 epoch 13 - iter 42/429 - loss 0.37128338 - samples/sec: 372.84\n",
      "2020-05-17 15:24:25,974 epoch 13 - iter 84/429 - loss 0.38576181 - samples/sec: 377.23\n",
      "2020-05-17 15:24:29,459 epoch 13 - iter 126/429 - loss 0.39166904 - samples/sec: 386.87\n",
      "2020-05-17 15:24:32,871 epoch 13 - iter 168/429 - loss 0.40058693 - samples/sec: 395.06\n",
      "2020-05-17 15:24:36,474 epoch 13 - iter 210/429 - loss 0.39437653 - samples/sec: 373.96\n",
      "2020-05-17 15:24:40,103 epoch 13 - iter 252/429 - loss 0.39987867 - samples/sec: 371.35\n",
      "2020-05-17 15:24:43,702 epoch 13 - iter 294/429 - loss 0.40307115 - samples/sec: 374.47\n",
      "2020-05-17 15:24:47,290 epoch 13 - iter 336/429 - loss 0.39969136 - samples/sec: 375.68\n",
      "2020-05-17 15:24:50,918 epoch 13 - iter 378/429 - loss 0.40104168 - samples/sec: 371.41\n",
      "2020-05-17 15:24:54,510 epoch 13 - iter 420/429 - loss 0.39921407 - samples/sec: 375.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:24:55,187 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:24:55,188 EPOCH 13 done: loss 0.3998 - lr 0.1000\n",
      "2020-05-17 15:24:56,202 DEV : loss 0.7134566307067871 - score 0.79\n",
      "2020-05-17 15:24:56,267 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:24:57,432 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:24:57,523 epoch 14 - iter 0/429 - loss 0.23951581 - samples/sec: 15453.97\n",
      "2020-05-17 15:25:01,111 epoch 14 - iter 42/429 - loss 0.33651725 - samples/sec: 375.40\n",
      "2020-05-17 15:25:04,679 epoch 14 - iter 84/429 - loss 0.34918969 - samples/sec: 377.62\n",
      "2020-05-17 15:25:08,282 epoch 14 - iter 126/429 - loss 0.35269781 - samples/sec: 374.07\n",
      "2020-05-17 15:25:11,903 epoch 14 - iter 168/429 - loss 0.35979062 - samples/sec: 372.07\n",
      "2020-05-17 15:25:15,542 epoch 14 - iter 210/429 - loss 0.36416262 - samples/sec: 370.30\n",
      "2020-05-17 15:25:19,142 epoch 14 - iter 252/429 - loss 0.36420471 - samples/sec: 375.10\n",
      "2020-05-17 15:25:22,704 epoch 14 - iter 294/429 - loss 0.36909071 - samples/sec: 378.27\n",
      "2020-05-17 15:25:26,251 epoch 14 - iter 336/429 - loss 0.37124397 - samples/sec: 380.22\n",
      "2020-05-17 15:25:32,154 epoch 14 - iter 378/429 - loss 0.37434966 - samples/sec: 228.31\n",
      "2020-05-17 15:25:35,726 epoch 14 - iter 420/429 - loss 0.37535420 - samples/sec: 377.08\n",
      "2020-05-17 15:25:36,418 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:25:36,419 EPOCH 14 done: loss 0.3758 - lr 0.1000\n",
      "2020-05-17 15:25:37,467 DEV : loss 0.7213953137397766 - score 0.766\n",
      "2020-05-17 15:25:37,533 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:25:37,534 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:25:37,624 epoch 15 - iter 0/429 - loss 0.38923359 - samples/sec: 15241.46\n",
      "2020-05-17 15:25:41,321 epoch 15 - iter 42/429 - loss 0.31811849 - samples/sec: 364.37\n",
      "2020-05-17 15:25:45,025 epoch 15 - iter 84/429 - loss 0.33516080 - samples/sec: 363.79\n",
      "2020-05-17 15:25:48,676 epoch 15 - iter 126/429 - loss 0.34381460 - samples/sec: 369.22\n",
      "2020-05-17 15:25:52,274 epoch 15 - iter 168/429 - loss 0.33402313 - samples/sec: 374.64\n",
      "2020-05-17 15:25:55,815 epoch 15 - iter 210/429 - loss 0.33989111 - samples/sec: 380.49\n",
      "2020-05-17 15:25:59,346 epoch 15 - iter 252/429 - loss 0.33546602 - samples/sec: 381.90\n",
      "2020-05-17 15:26:02,934 epoch 15 - iter 294/429 - loss 0.33908101 - samples/sec: 376.47\n",
      "2020-05-17 15:26:06,554 epoch 15 - iter 336/429 - loss 0.34024146 - samples/sec: 372.88\n",
      "2020-05-17 15:26:10,140 epoch 15 - iter 378/429 - loss 0.34105725 - samples/sec: 375.82\n",
      "2020-05-17 15:26:13,746 epoch 15 - iter 420/429 - loss 0.34674909 - samples/sec: 373.64\n",
      "2020-05-17 15:26:14,436 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:26:14,438 EPOCH 15 done: loss 0.3474 - lr 0.1000\n",
      "2020-05-17 15:26:15,428 DEV : loss 0.6922149062156677 - score 0.78\n",
      "2020-05-17 15:26:15,493 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 15:26:16,631 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:26:16,632 Testing using best model ...\n",
      "2020-05-17 15:26:16,634 loading file best-model.pt\n",
      "2020-05-17 15:26:22,592 0.782\t0.782\t0.782\n",
      "2020-05-17 15:26:22,593 \n",
      "MICRO_AVG: acc 0.642 - f1-score 0.782\n",
      "MACRO_AVG: acc 0.5488 - f1-score 0.6875\n",
      "0          tp: 132 - fp: 20 - fn: 14 - tn: 334 - precision: 0.8684 - recall: 0.9041 - accuracy: 0.7952 - f1-score: 0.8859\n",
      "1          tp: 58 - fp: 13 - fn: 30 - tn: 399 - precision: 0.8169 - recall: 0.6591 - accuracy: 0.5743 - f1-score: 0.7296\n",
      "2          tp: 3 - fp: 3 - fn: 7 - tn: 487 - precision: 0.5000 - recall: 0.3000 - accuracy: 0.2308 - f1-score: 0.3750\n",
      "3          tp: 145 - fp: 61 - fn: 13 - tn: 281 - precision: 0.7039 - recall: 0.9177 - accuracy: 0.6621 - f1-score: 0.7967\n",
      "4          tp: 53 - fp: 12 - fn: 45 - tn: 390 - precision: 0.8154 - recall: 0.5408 - accuracy: 0.4818 - f1-score: 0.6503\n",
      "2020-05-17 15:26:22,594 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "3267.184552669525\n"
     ]
    }
   ],
   "source": [
    "total_time = time.time()\n",
    "\n",
    "word_embeddings = [ WordEmbeddings('glove'),              ]\n",
    "modelname = 'glove'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "word_embeddings = [ WordEmbeddings('en-crawl'),                 ]\n",
    "modelname = 'fasttext web-crawl'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "word_embeddings = [ WordEmbeddings('en'),                 ]\n",
    "modelname = 'fasttext news/wiki'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "word_embeddings = [ WordEmbeddings('en-twitter'),                 ]\n",
    "modelname = 'en-twitter'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "word_embeddings = [ ELMoEmbeddings('original')              ]\n",
    "modelname = 'elmo'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "print(time.time() - total_time)\n",
    "\n",
    "# training times\n",
    "#       3K char long datafields:  2687 sec\n",
    "#       2K char long datafields:  2220 sec, 20% of time away with 1/3 away from text length.\n",
    "\n",
    "#       1.5k char , only 100 test-set  373 sec\n",
    "#       518 sec with batch=32 prediction  -> to small fraction\n",
    "\n",
    "\n",
    "# older, 8k long, or hatespeech=?\n",
    "# 1289 sec on 100 train (was 2x elmo)\n",
    "\n",
    "# 2403 sec on 18k\n",
    "# 2684 s   18 k\n",
    "\n",
    "# tiny - 500char, 500 test-set: 295 sec,  with 60epochs 331 sec  (was 100,100 train-dev)\n",
    "\n",
    "\n",
    "# 500char, 100,200 train-dev (test-500)  60 epo already 1022 secs\n",
    "\n",
    "# 300char, 13k train 3267 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair\n",
      "2020-05-17 15:41:33,898 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 15:41:33,899 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 15:41:33,899 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 15:41:33,900 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:41:43,553 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 265965.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:41:43,608 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 15:41:43,609 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 259904.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:41:43,665 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 15:41:43,669 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:41:43,670 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.05, inplace=False)\n",
      "          (encoder): Embedding(300, 100)\n",
      "          (rnn): LSTM(100, 2048)\n",
      "          (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 15:41:43,671 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:41:43,671 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 15:41:43,672 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:41:43,672 Parameters:\n",
      "2020-05-17 15:41:43,673  - learning_rate: \"0.1\"\n",
      "2020-05-17 15:41:43,673  - mini_batch_size: \"32\"\n",
      "2020-05-17 15:41:43,675  - patience: \"5\"\n",
      "2020-05-17 15:41:43,675  - anneal_factor: \"0.5\"\n",
      "2020-05-17 15:41:43,676  - max_epochs: \"15\"\n",
      "2020-05-17 15:41:43,677  - shuffle: \"True\"\n",
      "2020-05-17 15:41:43,678  - train_with_dev: \"False\"\n",
      "2020-05-17 15:41:43,680  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 15:41:43,681 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:41:43,681 Model training base path: \".\"\n",
      "2020-05-17 15:41:43,682 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:41:43,682 Device: cuda:0\n",
      "2020-05-17 15:41:43,682 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:41:43,683 Embeddings storage mode: cpu\n",
      "2020-05-17 15:41:43,685 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:41:43,950 epoch 1 - iter 0/429 - loss 1.62657619 - samples/sec: 5123.95\n",
      "2020-05-17 15:41:59,583 epoch 1 - iter 42/429 - loss 1.48372576 - samples/sec: 86.06\n",
      "2020-05-17 15:42:08,839 epoch 1 - iter 84/429 - loss 1.46120525 - samples/sec: 145.42\n",
      "2020-05-17 15:42:17,865 epoch 1 - iter 126/429 - loss 1.44395296 - samples/sec: 149.12\n",
      "2020-05-17 15:42:26,673 epoch 1 - iter 168/429 - loss 1.42902194 - samples/sec: 152.86\n",
      "2020-05-17 15:42:35,777 epoch 1 - iter 210/429 - loss 1.40975951 - samples/sec: 147.89\n",
      "2020-05-17 15:42:45,054 epoch 1 - iter 252/429 - loss 1.38686975 - samples/sec: 145.10\n",
      "2020-05-17 15:42:54,383 epoch 1 - iter 294/429 - loss 1.37051187 - samples/sec: 144.33\n",
      "2020-05-17 15:43:03,599 epoch 1 - iter 336/429 - loss 1.35483527 - samples/sec: 146.06\n",
      "2020-05-17 15:43:12,774 epoch 1 - iter 378/429 - loss 1.34072678 - samples/sec: 146.72\n",
      "2020-05-17 15:43:23,350 epoch 1 - iter 420/429 - loss 1.32819519 - samples/sec: 127.24\n",
      "2020-05-17 15:43:24,962 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:43:24,964 EPOCH 1 done: loss 1.3262 - lr 0.1000\n",
      "2020-05-17 15:43:28,065 DEV : loss 1.2431347370147705 - score 0.472\n",
      "2020-05-17 15:43:28,139 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:43:28,467 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:43:28,550 epoch 2 - iter 0/429 - loss 1.13285327 - samples/sec: 16782.46\n",
      "2020-05-17 15:43:31,911 epoch 2 - iter 42/429 - loss 1.21631105 - samples/sec: 401.51\n",
      "2020-05-17 15:43:35,159 epoch 2 - iter 84/429 - loss 1.22235621 - samples/sec: 415.85\n",
      "2020-05-17 15:43:38,268 epoch 2 - iter 126/429 - loss 1.20900943 - samples/sec: 434.14\n",
      "2020-05-17 15:43:41,412 epoch 2 - iter 168/429 - loss 1.21145808 - samples/sec: 429.35\n",
      "2020-05-17 15:43:44,535 epoch 2 - iter 210/429 - loss 1.21060712 - samples/sec: 432.44\n",
      "2020-05-17 15:43:47,659 epoch 2 - iter 252/429 - loss 1.20469070 - samples/sec: 432.41\n",
      "2020-05-17 15:43:50,764 epoch 2 - iter 294/429 - loss 1.20665145 - samples/sec: 435.92\n",
      "2020-05-17 15:43:53,955 epoch 2 - iter 336/429 - loss 1.21015676 - samples/sec: 423.00\n",
      "2020-05-17 15:43:57,214 epoch 2 - iter 378/429 - loss 1.20946703 - samples/sec: 414.20\n",
      "2020-05-17 15:44:00,442 epoch 2 - iter 420/429 - loss 1.20734822 - samples/sec: 419.46\n",
      "2020-05-17 15:44:01,062 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:44:01,063 EPOCH 2 done: loss 1.2071 - lr 0.1000\n",
      "2020-05-17 15:44:01,917 DEV : loss 1.149588704109192 - score 0.518\n",
      "2020-05-17 15:44:01,977 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:44:02,225 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:44:02,309 epoch 3 - iter 0/429 - loss 1.03750920 - samples/sec: 16494.21\n",
      "2020-05-17 15:44:05,532 epoch 3 - iter 42/429 - loss 1.17778064 - samples/sec: 418.85\n",
      "2020-05-17 15:44:08,747 epoch 3 - iter 84/429 - loss 1.18394969 - samples/sec: 419.94\n",
      "2020-05-17 15:44:12,045 epoch 3 - iter 126/429 - loss 1.17547260 - samples/sec: 409.79\n",
      "2020-05-17 15:44:15,471 epoch 3 - iter 168/429 - loss 1.17924677 - samples/sec: 394.05\n",
      "2020-05-17 15:44:18,766 epoch 3 - iter 210/429 - loss 1.18175081 - samples/sec: 409.76\n",
      "2020-05-17 15:44:22,059 epoch 3 - iter 252/429 - loss 1.17394630 - samples/sec: 410.62\n",
      "2020-05-17 15:44:25,217 epoch 3 - iter 294/429 - loss 1.17230319 - samples/sec: 428.81\n",
      "2020-05-17 15:44:28,435 epoch 3 - iter 336/429 - loss 1.17291501 - samples/sec: 420.14\n",
      "2020-05-17 15:44:31,618 epoch 3 - iter 378/429 - loss 1.17316873 - samples/sec: 424.24\n",
      "2020-05-17 15:44:34,994 epoch 3 - iter 420/429 - loss 1.16998320 - samples/sec: 399.85\n",
      "2020-05-17 15:44:35,632 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:44:35,633 EPOCH 3 done: loss 1.1696 - lr 0.1000\n",
      "2020-05-17 15:44:36,515 DEV : loss 1.1487574577331543 - score 0.518\n",
      "2020-05-17 15:44:36,577 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:44:36,846 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:44:36,934 epoch 4 - iter 0/429 - loss 0.88482487 - samples/sec: 15918.52\n",
      "2020-05-17 15:44:40,230 epoch 4 - iter 42/429 - loss 1.15754349 - samples/sec: 409.40\n",
      "2020-05-17 15:44:43,484 epoch 4 - iter 84/429 - loss 1.13363964 - samples/sec: 415.14\n",
      "2020-05-17 15:44:46,699 epoch 4 - iter 126/429 - loss 1.12791406 - samples/sec: 420.45\n",
      "2020-05-17 15:44:50,114 epoch 4 - iter 168/429 - loss 1.13116924 - samples/sec: 395.71\n",
      "2020-05-17 15:44:53,512 epoch 4 - iter 210/429 - loss 1.14545766 - samples/sec: 398.18\n",
      "2020-05-17 15:44:56,897 epoch 4 - iter 252/429 - loss 1.14774851 - samples/sec: 398.73\n",
      "2020-05-17 15:45:00,205 epoch 4 - iter 294/429 - loss 1.14463513 - samples/sec: 408.13\n",
      "2020-05-17 15:45:03,616 epoch 4 - iter 336/429 - loss 1.14430967 - samples/sec: 396.00\n",
      "2020-05-17 15:45:06,894 epoch 4 - iter 378/429 - loss 1.14420756 - samples/sec: 412.34\n",
      "2020-05-17 15:45:10,363 epoch 4 - iter 420/429 - loss 1.14586665 - samples/sec: 389.35\n",
      "2020-05-17 15:45:11,080 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:45:11,082 EPOCH 4 done: loss 1.1483 - lr 0.1000\n",
      "2020-05-17 15:45:12,154 DEV : loss 1.1725430488586426 - score 0.512\n",
      "2020-05-17 15:45:12,217 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 15:45:12,219 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:45:12,309 epoch 5 - iter 0/429 - loss 1.13805974 - samples/sec: 15415.39\n",
      "2020-05-17 15:45:15,795 epoch 5 - iter 42/429 - loss 1.11503805 - samples/sec: 387.65\n",
      "2020-05-17 15:45:19,186 epoch 5 - iter 84/429 - loss 1.13387837 - samples/sec: 398.29\n",
      "2020-05-17 15:45:22,774 epoch 5 - iter 126/429 - loss 1.13154081 - samples/sec: 376.31\n",
      "2020-05-17 15:45:26,245 epoch 5 - iter 168/429 - loss 1.13717541 - samples/sec: 389.14\n",
      "2020-05-17 15:45:29,492 epoch 5 - iter 210/429 - loss 1.13422074 - samples/sec: 415.96\n",
      "2020-05-17 15:45:32,935 epoch 5 - iter 252/429 - loss 1.12718819 - samples/sec: 392.22\n",
      "2020-05-17 15:45:36,239 epoch 5 - iter 294/429 - loss 1.12440645 - samples/sec: 408.84\n",
      "2020-05-17 15:45:39,458 epoch 5 - iter 336/429 - loss 1.12858108 - samples/sec: 419.72\n",
      "2020-05-17 15:45:42,748 epoch 5 - iter 378/429 - loss 1.12561422 - samples/sec: 410.94\n",
      "2020-05-17 15:45:46,107 epoch 5 - iter 420/429 - loss 1.12783264 - samples/sec: 401.92\n",
      "2020-05-17 15:45:46,721 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:45:46,722 EPOCH 5 done: loss 1.1273 - lr 0.1000\n",
      "2020-05-17 15:45:47,584 DEV : loss 1.0985426902770996 - score 0.55\n",
      "2020-05-17 15:45:47,645 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:45:47,887 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:45:47,967 epoch 6 - iter 0/429 - loss 1.16699719 - samples/sec: 17411.92\n",
      "2020-05-17 15:45:51,275 epoch 6 - iter 42/429 - loss 1.10928702 - samples/sec: 408.01\n",
      "2020-05-17 15:45:54,549 epoch 6 - iter 84/429 - loss 1.09958918 - samples/sec: 412.55\n",
      "2020-05-17 15:45:57,876 epoch 6 - iter 126/429 - loss 1.10652212 - samples/sec: 405.80\n",
      "2020-05-17 15:46:01,166 epoch 6 - iter 168/429 - loss 1.11119821 - samples/sec: 410.14\n",
      "2020-05-17 15:46:04,756 epoch 6 - iter 210/429 - loss 1.10275921 - samples/sec: 376.21\n",
      "2020-05-17 15:46:08,310 epoch 6 - iter 252/429 - loss 1.10632965 - samples/sec: 379.68\n",
      "2020-05-17 15:46:11,794 epoch 6 - iter 294/429 - loss 1.10490416 - samples/sec: 387.29\n",
      "2020-05-17 15:46:15,353 epoch 6 - iter 336/429 - loss 1.10233722 - samples/sec: 379.08\n",
      "2020-05-17 15:46:18,906 epoch 6 - iter 378/429 - loss 1.10022679 - samples/sec: 379.99\n",
      "2020-05-17 15:46:22,485 epoch 6 - iter 420/429 - loss 1.10269667 - samples/sec: 377.05\n",
      "2020-05-17 15:46:23,173 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:46:23,174 EPOCH 6 done: loss 1.1031 - lr 0.1000\n",
      "2020-05-17 15:46:24,183 DEV : loss 1.116001009941101 - score 0.556\n",
      "2020-05-17 15:46:24,246 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:46:24,521 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:46:24,615 epoch 7 - iter 0/429 - loss 1.17711794 - samples/sec: 14863.69\n",
      "2020-05-17 15:46:28,153 epoch 7 - iter 42/429 - loss 1.08914554 - samples/sec: 381.24\n",
      "2020-05-17 15:46:31,759 epoch 7 - iter 84/429 - loss 1.08886287 - samples/sec: 374.68\n",
      "2020-05-17 15:46:35,182 epoch 7 - iter 126/429 - loss 1.08427262 - samples/sec: 395.09\n",
      "2020-05-17 15:46:38,634 epoch 7 - iter 168/429 - loss 1.08885223 - samples/sec: 391.08\n",
      "2020-05-17 15:46:42,366 epoch 7 - iter 210/429 - loss 1.09339520 - samples/sec: 361.95\n",
      "2020-05-17 15:46:46,006 epoch 7 - iter 252/429 - loss 1.09102508 - samples/sec: 370.91\n",
      "2020-05-17 15:46:49,660 epoch 7 - iter 294/429 - loss 1.09078605 - samples/sec: 369.34\n",
      "2020-05-17 15:46:53,162 epoch 7 - iter 336/429 - loss 1.09207234 - samples/sec: 385.88\n",
      "2020-05-17 15:46:56,637 epoch 7 - iter 378/429 - loss 1.09192700 - samples/sec: 388.52\n",
      "2020-05-17 15:47:00,228 epoch 7 - iter 420/429 - loss 1.09122190 - samples/sec: 375.76\n",
      "2020-05-17 15:47:00,925 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:47:00,927 EPOCH 7 done: loss 1.0918 - lr 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:47:02,017 DEV : loss 1.0649515390396118 - score 0.572\n",
      "2020-05-17 15:47:02,085 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:47:02,334 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:47:02,428 epoch 8 - iter 0/429 - loss 1.14055955 - samples/sec: 14670.25\n",
      "2020-05-17 15:47:05,983 epoch 8 - iter 42/429 - loss 1.10108181 - samples/sec: 379.64\n",
      "2020-05-17 15:47:09,284 epoch 8 - iter 84/429 - loss 1.09338141 - samples/sec: 408.76\n",
      "2020-05-17 15:47:12,632 epoch 8 - iter 126/429 - loss 1.09076137 - samples/sec: 403.73\n",
      "2020-05-17 15:47:15,979 epoch 8 - iter 168/429 - loss 1.09054697 - samples/sec: 403.36\n",
      "2020-05-17 15:47:19,355 epoch 8 - iter 210/429 - loss 1.08356123 - samples/sec: 400.42\n",
      "2020-05-17 15:47:22,672 epoch 8 - iter 252/429 - loss 1.07893989 - samples/sec: 407.37\n",
      "2020-05-17 15:47:25,918 epoch 8 - iter 294/429 - loss 1.07537267 - samples/sec: 415.96\n",
      "2020-05-17 15:47:29,310 epoch 8 - iter 336/429 - loss 1.07245946 - samples/sec: 398.26\n",
      "2020-05-17 15:47:32,496 epoch 8 - iter 378/429 - loss 1.07364544 - samples/sec: 423.97\n",
      "2020-05-17 15:47:35,723 epoch 8 - iter 420/429 - loss 1.07081640 - samples/sec: 418.45\n",
      "2020-05-17 15:47:36,334 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:47:36,335 EPOCH 8 done: loss 1.0702 - lr 0.1000\n",
      "2020-05-17 15:47:37,189 DEV : loss 1.044983983039856 - score 0.582\n",
      "2020-05-17 15:47:37,248 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:47:37,519 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:47:37,604 epoch 9 - iter 0/429 - loss 1.17073095 - samples/sec: 16580.37\n",
      "2020-05-17 15:47:40,884 epoch 9 - iter 42/429 - loss 1.06448444 - samples/sec: 411.49\n",
      "2020-05-17 15:47:44,298 epoch 9 - iter 84/429 - loss 1.05638025 - samples/sec: 395.47\n",
      "2020-05-17 15:47:47,601 epoch 9 - iter 126/429 - loss 1.05663418 - samples/sec: 408.42\n",
      "2020-05-17 15:47:50,817 epoch 9 - iter 168/429 - loss 1.05540832 - samples/sec: 419.61\n",
      "2020-05-17 15:47:54,201 epoch 9 - iter 210/429 - loss 1.04873058 - samples/sec: 398.73\n",
      "2020-05-17 15:47:57,585 epoch 9 - iter 252/429 - loss 1.05845612 - samples/sec: 398.94\n",
      "2020-05-17 15:48:00,839 epoch 9 - iter 294/429 - loss 1.06159272 - samples/sec: 414.93\n",
      "2020-05-17 15:48:04,153 epoch 9 - iter 336/429 - loss 1.06252400 - samples/sec: 407.17\n",
      "2020-05-17 15:48:07,392 epoch 9 - iter 378/429 - loss 1.06140083 - samples/sec: 416.92\n",
      "2020-05-17 15:48:10,689 epoch 9 - iter 420/429 - loss 1.05921464 - samples/sec: 409.68\n",
      "2020-05-17 15:48:11,379 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:48:11,381 EPOCH 9 done: loss 1.0601 - lr 0.1000\n",
      "2020-05-17 15:48:12,339 DEV : loss 1.0609323978424072 - score 0.544\n",
      "2020-05-17 15:48:12,405 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:48:12,407 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:48:12,498 epoch 10 - iter 0/429 - loss 1.14948845 - samples/sec: 15161.64\n",
      "2020-05-17 15:48:15,954 epoch 10 - iter 42/429 - loss 1.03620688 - samples/sec: 390.42\n",
      "2020-05-17 15:48:19,286 epoch 10 - iter 84/429 - loss 1.02351401 - samples/sec: 405.62\n",
      "2020-05-17 15:48:22,527 epoch 10 - iter 126/429 - loss 1.03536478 - samples/sec: 417.41\n",
      "2020-05-17 15:48:25,827 epoch 10 - iter 168/429 - loss 1.03820150 - samples/sec: 408.84\n",
      "2020-05-17 15:48:29,103 epoch 10 - iter 210/429 - loss 1.05113838 - samples/sec: 412.16\n",
      "2020-05-17 15:48:32,307 epoch 10 - iter 252/429 - loss 1.05116351 - samples/sec: 421.85\n",
      "2020-05-17 15:48:35,470 epoch 10 - iter 294/429 - loss 1.05062905 - samples/sec: 426.72\n",
      "2020-05-17 15:48:38,582 epoch 10 - iter 336/429 - loss 1.04516844 - samples/sec: 433.91\n",
      "2020-05-17 15:48:41,864 epoch 10 - iter 378/429 - loss 1.04578352 - samples/sec: 411.35\n",
      "2020-05-17 15:48:45,079 epoch 10 - iter 420/429 - loss 1.04436734 - samples/sec: 420.06\n",
      "2020-05-17 15:48:45,688 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:48:45,689 EPOCH 10 done: loss 1.0458 - lr 0.1000\n",
      "2020-05-17 15:48:46,610 DEV : loss 1.0498026609420776 - score 0.588\n",
      "2020-05-17 15:48:46,673 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:48:46,933 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:48:47,016 epoch 11 - iter 0/429 - loss 0.90296257 - samples/sec: 16635.37\n",
      "2020-05-17 15:48:50,262 epoch 11 - iter 42/429 - loss 1.03865019 - samples/sec: 415.85\n",
      "2020-05-17 15:48:53,543 epoch 11 - iter 84/429 - loss 1.04001364 - samples/sec: 411.31\n",
      "2020-05-17 15:48:56,767 epoch 11 - iter 126/429 - loss 1.03965575 - samples/sec: 418.59\n",
      "2020-05-17 15:49:00,126 epoch 11 - iter 168/429 - loss 1.05248978 - samples/sec: 401.77\n",
      "2020-05-17 15:49:03,456 epoch 11 - iter 210/429 - loss 1.04819126 - samples/sec: 405.44\n",
      "2020-05-17 15:49:06,761 epoch 11 - iter 252/429 - loss 1.04334693 - samples/sec: 408.39\n",
      "2020-05-17 15:49:10,035 epoch 11 - iter 294/429 - loss 1.03946266 - samples/sec: 412.49\n",
      "2020-05-17 15:49:13,256 epoch 11 - iter 336/429 - loss 1.03754558 - samples/sec: 419.18\n",
      "2020-05-17 15:49:16,533 epoch 11 - iter 378/429 - loss 1.03696103 - samples/sec: 412.09\n",
      "2020-05-17 15:49:19,962 epoch 11 - iter 420/429 - loss 1.03332376 - samples/sec: 393.50\n",
      "2020-05-17 15:49:20,588 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:49:20,589 EPOCH 11 done: loss 1.0341 - lr 0.1000\n",
      "2020-05-17 15:49:21,484 DEV : loss 1.0344321727752686 - score 0.568\n",
      "2020-05-17 15:49:21,546 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:49:21,548 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:49:21,630 epoch 12 - iter 0/429 - loss 0.94682717 - samples/sec: 16723.76\n",
      "2020-05-17 15:49:25,019 epoch 12 - iter 42/429 - loss 1.00529833 - samples/sec: 398.05\n",
      "2020-05-17 15:49:28,333 epoch 12 - iter 84/429 - loss 1.01290582 - samples/sec: 407.26\n",
      "2020-05-17 15:49:31,616 epoch 12 - iter 126/429 - loss 1.02958709 - samples/sec: 411.18\n",
      "2020-05-17 15:49:34,939 epoch 12 - iter 168/429 - loss 1.03088973 - samples/sec: 406.65\n",
      "2020-05-17 15:49:38,267 epoch 12 - iter 210/429 - loss 1.02576109 - samples/sec: 405.69\n",
      "2020-05-17 15:49:41,621 epoch 12 - iter 252/429 - loss 1.02360562 - samples/sec: 402.51\n",
      "2020-05-17 15:49:44,955 epoch 12 - iter 294/429 - loss 1.02424152 - samples/sec: 406.07\n",
      "2020-05-17 15:49:48,262 epoch 12 - iter 336/429 - loss 1.02358162 - samples/sec: 408.23\n",
      "2020-05-17 15:49:51,574 epoch 12 - iter 378/429 - loss 1.02341445 - samples/sec: 408.21\n",
      "2020-05-17 15:49:54,927 epoch 12 - iter 420/429 - loss 1.02450043 - samples/sec: 402.60\n",
      "2020-05-17 15:49:55,548 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:49:55,549 EPOCH 12 done: loss 1.0263 - lr 0.1000\n",
      "2020-05-17 15:49:56,435 DEV : loss 1.0047144889831543 - score 0.592\n",
      "2020-05-17 15:49:56,496 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 15:49:56,756 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:49:56,843 epoch 13 - iter 0/429 - loss 0.96608472 - samples/sec: 16038.08\n",
      "2020-05-17 15:50:00,150 epoch 13 - iter 42/429 - loss 1.02063011 - samples/sec: 408.17\n",
      "2020-05-17 15:50:03,608 epoch 13 - iter 84/429 - loss 1.02440186 - samples/sec: 390.29\n",
      "2020-05-17 15:50:06,998 epoch 13 - iter 126/429 - loss 1.02084530 - samples/sec: 398.18\n",
      "2020-05-17 15:50:10,344 epoch 13 - iter 168/429 - loss 1.02281874 - samples/sec: 403.52\n",
      "2020-05-17 15:50:13,688 epoch 13 - iter 210/429 - loss 1.02270237 - samples/sec: 403.77\n",
      "2020-05-17 15:50:16,954 epoch 13 - iter 252/429 - loss 1.01983984 - samples/sec: 413.35\n",
      "2020-05-17 15:50:20,264 epoch 13 - iter 294/429 - loss 1.02768134 - samples/sec: 407.94\n",
      "2020-05-17 15:50:23,553 epoch 13 - iter 336/429 - loss 1.03059876 - samples/sec: 410.98\n",
      "2020-05-17 15:50:26,774 epoch 13 - iter 378/429 - loss 1.02934855 - samples/sec: 419.34\n",
      "2020-05-17 15:50:30,072 epoch 13 - iter 420/429 - loss 1.02690597 - samples/sec: 409.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 15:50:30,671 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:50:30,672 EPOCH 13 done: loss 1.0246 - lr 0.1000\n",
      "2020-05-17 15:50:31,542 DEV : loss 1.0257632732391357 - score 0.568\n",
      "2020-05-17 15:50:31,604 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 15:50:31,605 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:50:31,688 epoch 14 - iter 0/429 - loss 0.69253856 - samples/sec: 16634.39\n",
      "2020-05-17 15:50:34,926 epoch 14 - iter 42/429 - loss 1.00138802 - samples/sec: 416.96\n",
      "2020-05-17 15:50:38,198 epoch 14 - iter 84/429 - loss 0.98482730 - samples/sec: 412.65\n",
      "2020-05-17 15:50:41,427 epoch 14 - iter 126/429 - loss 0.99109571 - samples/sec: 418.44\n",
      "2020-05-17 15:50:44,643 epoch 14 - iter 168/429 - loss 1.00574006 - samples/sec: 419.76\n",
      "2020-05-17 15:50:47,890 epoch 14 - iter 210/429 - loss 1.00676128 - samples/sec: 415.69\n",
      "2020-05-17 15:50:51,153 epoch 14 - iter 252/429 - loss 1.00377148 - samples/sec: 414.22\n",
      "2020-05-17 15:50:54,552 epoch 14 - iter 294/429 - loss 1.00624119 - samples/sec: 396.97\n",
      "2020-05-17 15:50:57,910 epoch 14 - iter 336/429 - loss 1.00936455 - samples/sec: 401.92\n",
      "2020-05-17 15:51:01,298 epoch 14 - iter 378/429 - loss 1.01103904 - samples/sec: 398.38\n",
      "2020-05-17 15:51:04,781 epoch 14 - iter 420/429 - loss 1.01508581 - samples/sec: 387.47\n",
      "2020-05-17 15:51:05,451 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:51:05,453 EPOCH 14 done: loss 1.0148 - lr 0.1000\n",
      "2020-05-17 15:51:06,391 DEV : loss 0.9994961023330688 - score 0.58\n",
      "2020-05-17 15:51:06,452 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 15:51:06,453 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:51:06,535 epoch 15 - iter 0/429 - loss 1.06696439 - samples/sec: 16691.62\n",
      "2020-05-17 15:51:09,942 epoch 15 - iter 42/429 - loss 0.98462005 - samples/sec: 396.14\n",
      "2020-05-17 15:51:13,413 epoch 15 - iter 84/429 - loss 0.99413483 - samples/sec: 388.80\n",
      "2020-05-17 15:51:16,842 epoch 15 - iter 126/429 - loss 0.98541906 - samples/sec: 393.73\n",
      "2020-05-17 15:51:20,216 epoch 15 - iter 168/429 - loss 0.98626018 - samples/sec: 400.01\n",
      "2020-05-17 15:51:23,541 epoch 15 - iter 210/429 - loss 0.98790202 - samples/sec: 406.46\n",
      "2020-05-17 15:51:26,866 epoch 15 - iter 252/429 - loss 0.99087873 - samples/sec: 405.99\n",
      "2020-05-17 15:51:30,163 epoch 15 - iter 294/429 - loss 0.99165944 - samples/sec: 409.48\n",
      "2020-05-17 15:51:33,476 epoch 15 - iter 336/429 - loss 0.99568567 - samples/sec: 407.37\n",
      "2020-05-17 15:51:36,785 epoch 15 - iter 378/429 - loss 0.99635318 - samples/sec: 408.79\n",
      "2020-05-17 15:51:40,267 epoch 15 - iter 420/429 - loss 0.99964537 - samples/sec: 387.75\n",
      "2020-05-17 15:51:40,943 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:51:40,944 EPOCH 15 done: loss 0.9999 - lr 0.1000\n",
      "2020-05-17 15:51:41,918 DEV : loss 1.2764537334442139 - score 0.498\n",
      "2020-05-17 15:51:41,980 BAD EPOCHS (no improvement): 3\n",
      "2020-05-17 15:51:42,254 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 15:51:42,255 Testing using best model ...\n",
      "2020-05-17 15:51:42,256 loading file best-model.pt\n",
      "2020-05-17 15:51:44,664 0.642\t0.642\t0.642\n",
      "2020-05-17 15:51:44,665 \n",
      "MICRO_AVG: acc 0.4728 - f1-score 0.642\n",
      "MACRO_AVG: acc 0.4174 - f1-score 0.5764799999999999\n",
      "0          tp: 112 - fp: 39 - fn: 34 - tn: 315 - precision: 0.7417 - recall: 0.7671 - accuracy: 0.6054 - f1-score: 0.7542\n",
      "1          tp: 26 - fp: 10 - fn: 62 - tn: 402 - precision: 0.7222 - recall: 0.2955 - accuracy: 0.2653 - f1-score: 0.4194\n",
      "2          tp: 3 - fp: 0 - fn: 7 - tn: 490 - precision: 1.0000 - recall: 0.3000 - accuracy: 0.3000 - f1-score: 0.4615\n",
      "3          tp: 115 - fp: 54 - fn: 43 - tn: 288 - precision: 0.6805 - recall: 0.7278 - accuracy: 0.5425 - f1-score: 0.7034\n",
      "4          tp: 65 - fp: 76 - fn: 33 - tn: 326 - precision: 0.4610 - recall: 0.6633 - accuracy: 0.3736 - f1-score: 0.5439\n",
      "2020-05-17 15:51:44,666 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "624.0140006542206\n"
     ]
    }
   ],
   "source": [
    "# Flair\n",
    "# https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/FLAIR_EMBEDDINGS.md\n",
    "total_time = time.time()\n",
    "word_embeddings = [ # FlairEmbeddings('multi-forward'), # this is 300 languge, gave very low score\n",
    "                  # FlairEmbeddings('multi-backward'), \n",
    "                   FlairEmbeddings('news-forward'),  #  \tEnglish \tTrained with 1 billion word corpus   \n",
    "                  ]\n",
    "#modelname = 'Flair-news-fwd'\n",
    "modelname = 'Flair'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "# 3k and over, OOM, -> changed setting embedding to cpu instead of gpu. \n",
    "#train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS, batch_size=8 )\n",
    "\n",
    "print(time.time() - total_time)\n",
    "\n",
    "# training times 3K char long datafields\n",
    "# 2280 sec\n",
    "\n",
    "# 1,5K char,  100 test-set, 51 s\n",
    "\n",
    "\n",
    "# older\n",
    "# 167s in 100 train\n",
    "# 620s for 18k\n",
    "\n",
    "# tiny - 500char, 500 test-set:  33 sec\n",
    "\n",
    "# large, 624 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-cased\n",
      "2020-05-17 16:03:39,687 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 16:03:39,687 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 16:03:39,688 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 16:03:39,688 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:03:54,150 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 251258.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:03:54,207 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 16:03:54,208 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 250388.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:03:54,266 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 16:03:54,271 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:03:54,274 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): BertEmbeddings(\n",
      "        (model): BertModel(\n",
      "          (embeddings): BertEmbeddings(\n",
      "            (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "            (position_embeddings): Embedding(512, 768)\n",
      "            (token_type_embeddings): Embedding(2, 768)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (encoder): BertEncoder(\n",
      "            (layer): ModuleList(\n",
      "              (0): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (1): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (2): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (3): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (4): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (5): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (6): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (7): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (8): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (9): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (10): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (11): BertLayer(\n",
      "                (attention): BertAttention(\n",
      "                  (self): BertSelfAttention(\n",
      "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (output): BertSelfOutput(\n",
      "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                    (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                )\n",
      "                (intermediate): BertIntermediate(\n",
      "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                )\n",
      "                (output): BertOutput(\n",
      "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (pooler): BertPooler(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (activation): Tanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=3072, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:03:54,276 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:03:54,277 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 16:03:54,278 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:03:54,279 Parameters:\n",
      "2020-05-17 16:03:54,281  - learning_rate: \"0.1\"\n",
      "2020-05-17 16:03:54,282  - mini_batch_size: \"8\"\n",
      "2020-05-17 16:03:54,282  - patience: \"5\"\n",
      "2020-05-17 16:03:54,283  - anneal_factor: \"0.5\"\n",
      "2020-05-17 16:03:54,283  - max_epochs: \"15\"\n",
      "2020-05-17 16:03:54,284  - shuffle: \"True\"\n",
      "2020-05-17 16:03:54,285  - train_with_dev: \"False\"\n",
      "2020-05-17 16:03:54,285  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 16:03:54,286 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:03:54,286 Model training base path: \".\"\n",
      "2020-05-17 16:03:54,287 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:03:54,288 Device: cuda:0\n",
      "2020-05-17 16:03:54,288 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:03:54,289 Embeddings storage mode: cpu\n",
      "2020-05-17 16:03:54,293 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:03:55,221 epoch 1 - iter 0/1715 - loss 1.57973135 - samples/sec: 1478.86\n",
      "2020-05-17 16:06:22,164 epoch 1 - iter 171/1715 - loss 1.59164723 - samples/sec: 9.32\n",
      "2020-05-17 16:08:48,237 epoch 1 - iter 342/1715 - loss 1.50371604 - samples/sec: 9.38\n",
      "2020-05-17 16:11:17,432 epoch 1 - iter 513/1715 - loss 1.44562274 - samples/sec: 9.18\n",
      "2020-05-17 16:13:42,869 epoch 1 - iter 684/1715 - loss 1.40248368 - samples/sec: 9.42\n",
      "2020-05-17 16:16:08,003 epoch 1 - iter 855/1715 - loss 1.37099723 - samples/sec: 9.44\n",
      "2020-05-17 16:18:36,399 epoch 1 - iter 1026/1715 - loss 1.33394253 - samples/sec: 9.23\n",
      "2020-05-17 16:21:02,087 epoch 1 - iter 1197/1715 - loss 1.31195148 - samples/sec: 9.40\n",
      "2020-05-17 16:23:26,930 epoch 1 - iter 1368/1715 - loss 1.30067147 - samples/sec: 9.46\n",
      "2020-05-17 16:25:50,898 epoch 1 - iter 1539/1715 - loss 1.28161208 - samples/sec: 9.51\n",
      "2020-05-17 16:28:19,444 epoch 1 - iter 1710/1715 - loss 1.26349621 - samples/sec: 9.22\n",
      "2020-05-17 16:28:22,639 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:28:22,640 EPOCH 1 done: loss 1.2632 - lr 0.1000\n",
      "2020-05-17 16:29:15,060 DEV : loss 1.1570374965667725 - score 0.534\n",
      "2020-05-17 16:29:15,125 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertEncoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertSelfOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertIntermediate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertOutput. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BertPooler. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Tanh. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:29:16,363 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:29:16,396 epoch 2 - iter 0/1715 - loss 1.15191483 - samples/sec: 48307.40\n",
      "2020-05-17 16:29:21,776 epoch 2 - iter 171/1715 - loss 1.15310769 - samples/sec: 261.02\n",
      "2020-05-17 16:29:27,139 epoch 2 - iter 342/1715 - loss 1.15644752 - samples/sec: 262.76\n",
      "2020-05-17 16:29:32,296 epoch 2 - iter 513/1715 - loss 1.15017900 - samples/sec: 274.59\n",
      "2020-05-17 16:29:37,757 epoch 2 - iter 684/1715 - loss 1.15244119 - samples/sec: 257.79\n",
      "2020-05-17 16:29:43,231 epoch 2 - iter 855/1715 - loss 1.15782246 - samples/sec: 257.65\n",
      "2020-05-17 16:29:48,496 epoch 2 - iter 1026/1715 - loss 1.15163452 - samples/sec: 268.07\n",
      "2020-05-17 16:29:54,049 epoch 2 - iter 1197/1715 - loss 1.15500254 - samples/sec: 253.45\n",
      "2020-05-17 16:29:59,356 epoch 2 - iter 1368/1715 - loss 1.15963339 - samples/sec: 265.65\n",
      "2020-05-17 16:30:05,113 epoch 2 - iter 1539/1715 - loss 1.16189792 - samples/sec: 244.84\n",
      "2020-05-17 16:30:10,900 epoch 2 - iter 1710/1715 - loss 1.16092661 - samples/sec: 243.21\n",
      "2020-05-17 16:30:11,163 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:30:11,164 EPOCH 2 done: loss 1.1608 - lr 0.1000\n",
      "2020-05-17 16:30:12,227 DEV : loss 1.1916718482971191 - score 0.472\n",
      "2020-05-17 16:30:12,293 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 16:30:12,294 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:30:12,328 epoch 3 - iter 0/1715 - loss 1.37508273 - samples/sec: 43794.04\n",
      "2020-05-17 16:30:17,824 epoch 3 - iter 171/1715 - loss 1.14165961 - samples/sec: 255.25\n",
      "2020-05-17 16:30:23,339 epoch 3 - iter 342/1715 - loss 1.15526263 - samples/sec: 254.79\n",
      "2020-05-17 16:30:28,836 epoch 3 - iter 513/1715 - loss 1.15655414 - samples/sec: 256.50\n",
      "2020-05-17 16:30:33,954 epoch 3 - iter 684/1715 - loss 1.16173394 - samples/sec: 275.73\n",
      "2020-05-17 16:30:39,456 epoch 3 - iter 855/1715 - loss 1.16074595 - samples/sec: 256.11\n",
      "2020-05-17 16:30:44,520 epoch 3 - iter 1026/1715 - loss 1.14990166 - samples/sec: 277.92\n",
      "2020-05-17 16:30:49,872 epoch 3 - iter 1197/1715 - loss 1.14383671 - samples/sec: 262.72\n",
      "2020-05-17 16:30:55,368 epoch 3 - iter 1368/1715 - loss 1.15049888 - samples/sec: 255.35\n",
      "2020-05-17 16:31:00,903 epoch 3 - iter 1539/1715 - loss 1.14694478 - samples/sec: 253.34\n",
      "2020-05-17 16:31:06,365 epoch 3 - iter 1710/1715 - loss 1.14443369 - samples/sec: 257.66\n",
      "2020-05-17 16:31:06,648 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:31:06,649 EPOCH 3 done: loss 1.1441 - lr 0.1000\n",
      "2020-05-17 16:31:07,725 DEV : loss 1.0566000938415527 - score 0.558\n",
      "2020-05-17 16:31:07,791 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:31:09,147 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:31:09,185 epoch 4 - iter 0/1715 - loss 1.14303219 - samples/sec: 41540.99\n",
      "2020-05-17 16:31:14,595 epoch 4 - iter 171/1715 - loss 1.15277347 - samples/sec: 261.56\n",
      "2020-05-17 16:31:19,772 epoch 4 - iter 342/1715 - loss 1.11605687 - samples/sec: 272.14\n",
      "2020-05-17 16:31:25,244 epoch 4 - iter 513/1715 - loss 1.10113259 - samples/sec: 257.06\n",
      "2020-05-17 16:31:30,730 epoch 4 - iter 684/1715 - loss 1.10587914 - samples/sec: 255.89\n",
      "2020-05-17 16:31:36,219 epoch 4 - iter 855/1715 - loss 1.12249779 - samples/sec: 256.43\n",
      "2020-05-17 16:31:41,571 epoch 4 - iter 1026/1715 - loss 1.12812695 - samples/sec: 263.57\n",
      "2020-05-17 16:31:47,114 epoch 4 - iter 1197/1715 - loss 1.12611091 - samples/sec: 253.90\n",
      "2020-05-17 16:31:52,420 epoch 4 - iter 1368/1715 - loss 1.12211573 - samples/sec: 266.97\n",
      "2020-05-17 16:31:57,891 epoch 4 - iter 1539/1715 - loss 1.12165119 - samples/sec: 258.28\n",
      "2020-05-17 16:32:03,395 epoch 4 - iter 1710/1715 - loss 1.12058474 - samples/sec: 256.33\n",
      "2020-05-17 16:32:03,692 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:32:03,694 EPOCH 4 done: loss 1.1212 - lr 0.1000\n",
      "2020-05-17 16:32:04,742 DEV : loss 1.1027226448059082 - score 0.59\n",
      "2020-05-17 16:32:04,808 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:32:06,138 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:32:06,170 epoch 5 - iter 0/1715 - loss 0.93899530 - samples/sec: 46989.61\n",
      "2020-05-17 16:32:11,819 epoch 5 - iter 171/1715 - loss 1.12315859 - samples/sec: 248.85\n",
      "2020-05-17 16:32:17,540 epoch 5 - iter 342/1715 - loss 1.11679892 - samples/sec: 245.46\n",
      "2020-05-17 16:32:23,176 epoch 5 - iter 513/1715 - loss 1.10903978 - samples/sec: 250.06\n",
      "2020-05-17 16:32:28,737 epoch 5 - iter 684/1715 - loss 1.11243394 - samples/sec: 253.58\n",
      "2020-05-17 16:32:34,417 epoch 5 - iter 855/1715 - loss 1.10795271 - samples/sec: 248.72\n",
      "2020-05-17 16:32:39,854 epoch 5 - iter 1026/1715 - loss 1.10787062 - samples/sec: 259.52\n",
      "2020-05-17 16:32:45,497 epoch 5 - iter 1197/1715 - loss 1.11482187 - samples/sec: 249.78\n",
      "2020-05-17 16:32:50,991 epoch 5 - iter 1368/1715 - loss 1.11778900 - samples/sec: 256.79\n",
      "2020-05-17 16:32:56,579 epoch 5 - iter 1539/1715 - loss 1.11777219 - samples/sec: 252.29\n",
      "2020-05-17 16:33:02,385 epoch 5 - iter 1710/1715 - loss 1.11871635 - samples/sec: 242.75\n",
      "2020-05-17 16:33:02,685 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:33:02,686 EPOCH 5 done: loss 1.1181 - lr 0.1000\n",
      "2020-05-17 16:33:03,893 DEV : loss 1.0527948141098022 - score 0.558\n",
      "2020-05-17 16:33:03,958 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 16:33:03,960 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:33:03,997 epoch 6 - iter 0/1715 - loss 0.77304530 - samples/sec: 40433.01\n",
      "2020-05-17 16:33:09,695 epoch 6 - iter 171/1715 - loss 1.12524671 - samples/sec: 247.12\n",
      "2020-05-17 16:33:15,351 epoch 6 - iter 342/1715 - loss 1.12249831 - samples/sec: 249.23\n",
      "2020-05-17 16:33:20,971 epoch 6 - iter 513/1715 - loss 1.12036239 - samples/sec: 250.81\n",
      "2020-05-17 16:33:26,785 epoch 6 - iter 684/1715 - loss 1.12379713 - samples/sec: 242.05\n",
      "2020-05-17 16:33:32,396 epoch 6 - iter 855/1715 - loss 1.11962206 - samples/sec: 250.81\n",
      "2020-05-17 16:33:38,346 epoch 6 - iter 1026/1715 - loss 1.12338936 - samples/sec: 236.10\n",
      "2020-05-17 16:33:43,534 epoch 6 - iter 1197/1715 - loss 1.11880649 - samples/sec: 271.83\n",
      "2020-05-17 16:33:49,096 epoch 6 - iter 1368/1715 - loss 1.11743843 - samples/sec: 253.49\n",
      "2020-05-17 16:33:54,915 epoch 6 - iter 1539/1715 - loss 1.11535896 - samples/sec: 242.47\n",
      "2020-05-17 16:34:00,417 epoch 6 - iter 1710/1715 - loss 1.11499734 - samples/sec: 256.74\n",
      "2020-05-17 16:34:00,722 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:34:00,723 EPOCH 6 done: loss 1.1151 - lr 0.1000\n",
      "2020-05-17 16:34:01,883 DEV : loss 1.0433908700942993 - score 0.544\n",
      "2020-05-17 16:34:01,948 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 16:34:01,950 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:34:01,983 epoch 7 - iter 0/1715 - loss 0.78184879 - samples/sec: 44666.80\n",
      "2020-05-17 16:34:07,806 epoch 7 - iter 171/1715 - loss 1.09083251 - samples/sec: 241.01\n",
      "2020-05-17 16:34:13,272 epoch 7 - iter 342/1715 - loss 1.09735546 - samples/sec: 258.23\n",
      "2020-05-17 16:34:18,968 epoch 7 - iter 513/1715 - loss 1.08093336 - samples/sec: 247.33\n",
      "2020-05-17 16:34:24,855 epoch 7 - iter 684/1715 - loss 1.08426785 - samples/sec: 238.93\n",
      "2020-05-17 16:34:30,654 epoch 7 - iter 855/1715 - loss 1.08533365 - samples/sec: 243.41\n",
      "2020-05-17 16:34:36,288 epoch 7 - iter 1026/1715 - loss 1.08738570 - samples/sec: 250.59\n",
      "2020-05-17 16:34:42,029 epoch 7 - iter 1197/1715 - loss 1.08952090 - samples/sec: 245.31\n",
      "2020-05-17 16:34:47,619 epoch 7 - iter 1368/1715 - loss 1.10258889 - samples/sec: 251.57\n",
      "2020-05-17 16:34:53,300 epoch 7 - iter 1539/1715 - loss 1.10908372 - samples/sec: 247.43\n",
      "2020-05-17 16:34:58,800 epoch 7 - iter 1710/1715 - loss 1.11096750 - samples/sec: 256.85\n",
      "2020-05-17 16:34:59,083 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:34:59,084 EPOCH 7 done: loss 1.1108 - lr 0.1000\n",
      "2020-05-17 16:35:00,215 DEV : loss 1.0914437770843506 - score 0.528\n",
      "2020-05-17 16:35:00,281 BAD EPOCHS (no improvement): 3\n",
      "2020-05-17 16:35:00,282 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:35:00,326 epoch 8 - iter 0/1715 - loss 0.92333120 - samples/sec: 36885.80\n",
      "2020-05-17 16:35:05,784 epoch 8 - iter 171/1715 - loss 1.11660788 - samples/sec: 257.47\n",
      "2020-05-17 16:35:11,286 epoch 8 - iter 342/1715 - loss 1.12041234 - samples/sec: 257.58\n",
      "2020-05-17 16:35:17,084 epoch 8 - iter 513/1715 - loss 1.12835039 - samples/sec: 243.57\n",
      "2020-05-17 16:35:22,812 epoch 8 - iter 684/1715 - loss 1.11371967 - samples/sec: 245.75\n",
      "2020-05-17 16:35:28,588 epoch 8 - iter 855/1715 - loss 1.11134972 - samples/sec: 244.32\n",
      "2020-05-17 16:35:34,294 epoch 8 - iter 1026/1715 - loss 1.10909714 - samples/sec: 247.34\n",
      "2020-05-17 16:35:39,662 epoch 8 - iter 1197/1715 - loss 1.11494113 - samples/sec: 263.01\n",
      "2020-05-17 16:35:45,295 epoch 8 - iter 1368/1715 - loss 1.11620069 - samples/sec: 250.35\n",
      "2020-05-17 16:35:50,833 epoch 8 - iter 1539/1715 - loss 1.12035521 - samples/sec: 255.56\n",
      "2020-05-17 16:35:56,140 epoch 8 - iter 1710/1715 - loss 1.12001609 - samples/sec: 266.10\n",
      "2020-05-17 16:35:56,443 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:35:56,444 EPOCH 8 done: loss 1.1198 - lr 0.1000\n",
      "2020-05-17 16:35:57,570 DEV : loss 1.144406795501709 - score 0.444\n",
      "2020-05-17 16:35:57,633 BAD EPOCHS (no improvement): 4\n",
      "2020-05-17 16:35:57,634 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:35:57,664 epoch 9 - iter 0/1715 - loss 1.31447875 - samples/sec: 49408.91\n",
      "2020-05-17 16:36:03,117 epoch 9 - iter 171/1715 - loss 1.13661559 - samples/sec: 258.49\n",
      "2020-05-17 16:36:08,883 epoch 9 - iter 342/1715 - loss 1.11829556 - samples/sec: 243.69\n",
      "2020-05-17 16:36:14,279 epoch 9 - iter 513/1715 - loss 1.12329175 - samples/sec: 261.23\n",
      "2020-05-17 16:36:19,835 epoch 9 - iter 684/1715 - loss 1.11995141 - samples/sec: 253.37\n",
      "2020-05-17 16:36:25,257 epoch 9 - iter 855/1715 - loss 1.10939910 - samples/sec: 260.08\n",
      "2020-05-17 16:36:30,512 epoch 9 - iter 1026/1715 - loss 1.12316859 - samples/sec: 269.44\n",
      "2020-05-17 16:36:35,868 epoch 9 - iter 1197/1715 - loss 1.12815677 - samples/sec: 263.19\n",
      "2020-05-17 16:36:41,375 epoch 9 - iter 1368/1715 - loss 1.12054721 - samples/sec: 255.24\n",
      "2020-05-17 16:36:46,866 epoch 9 - iter 1539/1715 - loss 1.12146308 - samples/sec: 255.82\n",
      "2020-05-17 16:36:52,429 epoch 9 - iter 1710/1715 - loss 1.11926845 - samples/sec: 253.48\n",
      "2020-05-17 16:36:52,682 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:36:52,683 EPOCH 9 done: loss 1.1192 - lr 0.1000\n",
      "2020-05-17 16:36:53,745 DEV : loss 1.0802748203277588 - score 0.546\n",
      "2020-05-17 16:36:53,809 BAD EPOCHS (no improvement): 5\n",
      "2020-05-17 16:36:53,811 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:36:53,843 epoch 10 - iter 0/1715 - loss 1.29123425 - samples/sec: 47235.64\n",
      "2020-05-17 16:36:59,364 epoch 10 - iter 171/1715 - loss 1.11673466 - samples/sec: 254.46\n",
      "2020-05-17 16:37:04,913 epoch 10 - iter 342/1715 - loss 1.10088742 - samples/sec: 253.85\n",
      "2020-05-17 16:37:10,305 epoch 10 - iter 513/1715 - loss 1.12287962 - samples/sec: 261.79\n",
      "2020-05-17 16:37:15,842 epoch 10 - iter 684/1715 - loss 1.12739680 - samples/sec: 253.79\n",
      "2020-05-17 16:37:21,263 epoch 10 - iter 855/1715 - loss 1.12916102 - samples/sec: 259.43\n",
      "2020-05-17 16:37:26,581 epoch 10 - iter 1026/1715 - loss 1.13444298 - samples/sec: 264.91\n",
      "2020-05-17 16:37:31,777 epoch 10 - iter 1197/1715 - loss 1.13239297 - samples/sec: 271.42\n",
      "2020-05-17 16:37:37,103 epoch 10 - iter 1368/1715 - loss 1.12441601 - samples/sec: 263.92\n",
      "2020-05-17 16:37:42,279 epoch 10 - iter 1539/1715 - loss 1.11843248 - samples/sec: 271.56\n",
      "2020-05-17 16:37:47,818 epoch 10 - iter 1710/1715 - loss 1.11705821 - samples/sec: 255.98\n",
      "2020-05-17 16:37:48,134 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:37:48,136 EPOCH 10 done: loss 1.1177 - lr 0.1000\n",
      "2020-05-17 16:37:49,221 DEV : loss 1.068002700805664 - score 0.526\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-05-17 16:37:49,283 BAD EPOCHS (no improvement): 6\n",
      "2020-05-17 16:37:49,285 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:37:49,316 epoch 11 - iter 0/1715 - loss 1.35179746 - samples/sec: 48569.51\n",
      "2020-05-17 16:37:54,546 epoch 11 - iter 171/1715 - loss 1.05834452 - samples/sec: 269.85\n",
      "2020-05-17 16:37:59,928 epoch 11 - iter 342/1715 - loss 1.05577902 - samples/sec: 262.05\n",
      "2020-05-17 16:38:05,406 epoch 11 - iter 513/1715 - loss 1.05324337 - samples/sec: 256.77\n",
      "2020-05-17 16:38:10,796 epoch 11 - iter 684/1715 - loss 1.05274332 - samples/sec: 261.34\n",
      "2020-05-17 16:38:15,961 epoch 11 - iter 855/1715 - loss 1.04804833 - samples/sec: 273.44\n",
      "2020-05-17 16:38:21,325 epoch 11 - iter 1026/1715 - loss 1.04376822 - samples/sec: 262.90\n",
      "2020-05-17 16:38:26,746 epoch 11 - iter 1197/1715 - loss 1.04559640 - samples/sec: 259.06\n",
      "2020-05-17 16:38:32,230 epoch 11 - iter 1368/1715 - loss 1.04068622 - samples/sec: 257.02\n",
      "2020-05-17 16:38:37,649 epoch 11 - iter 1539/1715 - loss 1.04331814 - samples/sec: 260.32\n",
      "2020-05-17 16:38:43,018 epoch 11 - iter 1710/1715 - loss 1.04128251 - samples/sec: 262.00\n",
      "2020-05-17 16:38:43,303 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:38:43,305 EPOCH 11 done: loss 1.0413 - lr 0.0500\n",
      "2020-05-17 16:38:44,332 DEV : loss 0.9815093278884888 - score 0.588\n",
      "2020-05-17 16:38:44,395 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 16:38:44,397 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:38:44,432 epoch 12 - iter 0/1715 - loss 1.10778248 - samples/sec: 42986.60\n",
      "2020-05-17 16:38:49,960 epoch 12 - iter 171/1715 - loss 1.01465526 - samples/sec: 254.54\n",
      "2020-05-17 16:38:54,400 epoch 12 - iter 342/1715 - loss 1.04464819 - samples/sec: 319.27\n",
      "2020-05-17 16:38:59,164 epoch 12 - iter 513/1715 - loss 1.03462980 - samples/sec: 298.01\n",
      "2020-05-17 16:39:04,700 epoch 12 - iter 684/1715 - loss 1.03751488 - samples/sec: 254.34\n",
      "2020-05-17 16:39:10,059 epoch 12 - iter 855/1715 - loss 1.02466713 - samples/sec: 262.33\n",
      "2020-05-17 16:39:15,360 epoch 12 - iter 1026/1715 - loss 1.03499184 - samples/sec: 265.80\n",
      "2020-05-17 16:39:20,947 epoch 12 - iter 1197/1715 - loss 1.03147025 - samples/sec: 251.54\n",
      "2020-05-17 16:39:26,483 epoch 12 - iter 1368/1715 - loss 1.03003720 - samples/sec: 255.12\n",
      "2020-05-17 16:39:31,963 epoch 12 - iter 1539/1715 - loss 1.02631493 - samples/sec: 257.89\n",
      "2020-05-17 16:39:37,367 epoch 12 - iter 1710/1715 - loss 1.02576787 - samples/sec: 262.08\n",
      "2020-05-17 16:39:37,630 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:39:37,632 EPOCH 12 done: loss 1.0255 - lr 0.0500\n",
      "2020-05-17 16:39:38,651 DEV : loss 1.0044078826904297 - score 0.574\n",
      "2020-05-17 16:39:38,715 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 16:39:38,716 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:39:38,746 epoch 13 - iter 0/1715 - loss 1.56136131 - samples/sec: 50142.95\n",
      "2020-05-17 16:39:43,944 epoch 13 - iter 171/1715 - loss 0.99329153 - samples/sec: 270.62\n",
      "2020-05-17 16:39:49,023 epoch 13 - iter 342/1715 - loss 1.00726313 - samples/sec: 278.50\n",
      "2020-05-17 16:39:54,527 epoch 13 - iter 513/1715 - loss 1.00652020 - samples/sec: 256.34\n",
      "2020-05-17 16:39:59,984 epoch 13 - iter 684/1715 - loss 1.01719648 - samples/sec: 258.41\n",
      "2020-05-17 16:40:05,456 epoch 13 - iter 855/1715 - loss 1.01497615 - samples/sec: 258.01\n",
      "2020-05-17 16:40:10,777 epoch 13 - iter 1026/1715 - loss 1.01702314 - samples/sec: 266.05\n",
      "2020-05-17 16:40:16,232 epoch 13 - iter 1197/1715 - loss 1.01912087 - samples/sec: 257.98\n",
      "2020-05-17 16:40:21,628 epoch 13 - iter 1368/1715 - loss 1.01849038 - samples/sec: 260.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:40:27,100 epoch 13 - iter 1539/1715 - loss 1.01898701 - samples/sec: 257.34\n",
      "2020-05-17 16:40:31,601 epoch 13 - iter 1710/1715 - loss 1.01477844 - samples/sec: 313.38\n",
      "2020-05-17 16:40:31,849 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:40:31,850 EPOCH 13 done: loss 1.0142 - lr 0.0500\n",
      "2020-05-17 16:40:32,879 DEV : loss 0.9682843089103699 - score 0.594\n",
      "2020-05-17 16:40:32,942 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:40:34,216 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:40:34,246 epoch 14 - iter 0/1715 - loss 0.94932169 - samples/sec: 53737.37\n",
      "2020-05-17 16:40:39,012 epoch 14 - iter 171/1715 - loss 0.97430299 - samples/sec: 295.50\n",
      "2020-05-17 16:40:44,592 epoch 14 - iter 342/1715 - loss 0.97538048 - samples/sec: 252.52\n",
      "2020-05-17 16:40:49,738 epoch 14 - iter 513/1715 - loss 0.97889644 - samples/sec: 273.89\n",
      "2020-05-17 16:40:54,856 epoch 14 - iter 684/1715 - loss 0.99351751 - samples/sec: 276.14\n",
      "2020-05-17 16:40:59,342 epoch 14 - iter 855/1715 - loss 1.00438438 - samples/sec: 315.75\n",
      "2020-05-17 16:41:04,693 epoch 14 - iter 1026/1715 - loss 1.00002690 - samples/sec: 262.87\n",
      "2020-05-17 16:41:10,292 epoch 14 - iter 1197/1715 - loss 1.00381650 - samples/sec: 250.97\n",
      "2020-05-17 16:41:15,769 epoch 14 - iter 1368/1715 - loss 1.00789668 - samples/sec: 257.92\n",
      "2020-05-17 16:41:21,190 epoch 14 - iter 1539/1715 - loss 1.00704044 - samples/sec: 261.27\n",
      "2020-05-17 16:41:26,628 epoch 14 - iter 1710/1715 - loss 1.00480287 - samples/sec: 258.07\n",
      "2020-05-17 16:41:26,899 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:41:26,900 EPOCH 14 done: loss 1.0051 - lr 0.0500\n",
      "2020-05-17 16:41:27,920 DEV : loss 0.9619385004043579 - score 0.582\n",
      "2020-05-17 16:41:27,981 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 16:41:27,982 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:41:28,012 epoch 15 - iter 0/1715 - loss 1.09615564 - samples/sec: 50187.69\n",
      "2020-05-17 16:41:33,335 epoch 15 - iter 171/1715 - loss 1.00403400 - samples/sec: 264.66\n",
      "2020-05-17 16:41:38,732 epoch 15 - iter 342/1715 - loss 1.00056291 - samples/sec: 260.16\n",
      "2020-05-17 16:41:44,086 epoch 15 - iter 513/1715 - loss 0.98653528 - samples/sec: 262.68\n",
      "2020-05-17 16:41:49,477 epoch 15 - iter 684/1715 - loss 0.99569674 - samples/sec: 260.65\n",
      "2020-05-17 16:41:54,803 epoch 15 - iter 855/1715 - loss 0.98533570 - samples/sec: 264.89\n",
      "2020-05-17 16:42:00,077 epoch 15 - iter 1026/1715 - loss 0.98642202 - samples/sec: 266.86\n",
      "2020-05-17 16:42:05,488 epoch 15 - iter 1197/1715 - loss 0.98971687 - samples/sec: 260.13\n",
      "2020-05-17 16:42:10,708 epoch 15 - iter 1368/1715 - loss 0.99277365 - samples/sec: 270.92\n",
      "2020-05-17 16:42:16,224 epoch 15 - iter 1539/1715 - loss 0.99623620 - samples/sec: 255.63\n",
      "2020-05-17 16:42:21,670 epoch 15 - iter 1710/1715 - loss 0.99877498 - samples/sec: 258.69\n",
      "2020-05-17 16:42:21,946 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:42:21,948 EPOCH 15 done: loss 0.9992 - lr 0.0500\n",
      "2020-05-17 16:42:23,033 DEV : loss 0.9644497036933899 - score 0.604\n",
      "2020-05-17 16:42:23,098 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:42:25,671 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:42:25,672 Testing using best model ...\n",
      "2020-05-17 16:42:25,675 loading file best-model.pt\n",
      "2020-05-17 16:43:16,219 0.642\t0.642\t0.642\n",
      "2020-05-17 16:43:16,220 \n",
      "MICRO_AVG: acc 0.4728 - f1-score 0.642\n",
      "MACRO_AVG: acc 0.3611 - f1-score 0.48722000000000004\n",
      "0          tp: 103 - fp: 22 - fn: 43 - tn: 332 - precision: 0.8240 - recall: 0.7055 - accuracy: 0.6131 - f1-score: 0.7602\n",
      "1          tp: 57 - fp: 58 - fn: 31 - tn: 354 - precision: 0.4957 - recall: 0.6477 - accuracy: 0.3904 - f1-score: 0.5616\n",
      "2          tp: 0 - fp: 0 - fn: 10 - tn: 490 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "3          tp: 132 - fp: 84 - fn: 26 - tn: 258 - precision: 0.6111 - recall: 0.8354 - accuracy: 0.5455 - f1-score: 0.7059\n",
      "4          tp: 29 - fp: 15 - fn: 69 - tn: 387 - precision: 0.6591 - recall: 0.2959 - accuracy: 0.2566 - f1-score: 0.4084\n",
      "2020-05-17 16:43:16,221 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "2401.1212911605835\n"
     ]
    }
   ],
   "source": [
    "# BERT OOMs on 32 batch, use 8\n",
    "total_time = time.time()\n",
    "\n",
    "# Bert Cased - separating lower and upper case, uncased - ignoring case.\n",
    "# Use cased\n",
    "\n",
    "word_embeddings = [ BertEmbeddings('bert-base-cased'),                ]\n",
    "modelname = 'bert-base-cased'\n",
    "train_and_predict_single(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=15, batch_size=8)\n",
    "\n",
    "print(time.time() - total_time)\n",
    "\n",
    "#word_embeddings = [ BertEmbeddings('bert-base-uncased'),                ]\n",
    "#modelname = 'bert-base-uncased'\n",
    "#train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS, batch_size=8)\n",
    "\n",
    "\n",
    "# 19:30 atleast was started\n",
    "# 20:03 still doing\n",
    "# \n",
    "\n",
    "# 450 s 18k\n",
    "\n",
    "\n",
    "# on batch run: RuntimeError: CUDA error: device-side assert triggered\n",
    "# prediction, with embedding sentences.\n",
    "#\n",
    "#   for embedding in self.embeddings:\n",
    "#              embedding.embed(sentences)\n",
    "#\n",
    "# Possibly text too long for Bert embedding, length of the text the flair does not check beforehand\n",
    "\n",
    "# 13k -> 2400 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BytePairEmbedding\n",
      "2020-05-17 16:47:04,556 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 16:47:04,557 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 16:47:04,558 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 16:47:04,558 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:47:21,424 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 234207.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:47:21,486 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 16:47:21,487 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 257069.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:47:21,544 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 16:47:21,547 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:47:21,548 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): BytePairEmbeddings(model=0-bpe-en-100000-50)\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 16:47:21,550 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:47:21,550 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 16:47:21,551 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:47:21,552 Parameters:\n",
      "2020-05-17 16:47:21,552  - learning_rate: \"0.1\"\n",
      "2020-05-17 16:47:21,553  - mini_batch_size: \"8\"\n",
      "2020-05-17 16:47:21,554  - patience: \"5\"\n",
      "2020-05-17 16:47:21,554  - anneal_factor: \"0.5\"\n",
      "2020-05-17 16:47:21,554  - max_epochs: \"15\"\n",
      "2020-05-17 16:47:21,556  - shuffle: \"True\"\n",
      "2020-05-17 16:47:21,556  - train_with_dev: \"False\"\n",
      "2020-05-17 16:47:21,556  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 16:47:21,557 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:47:21,557 Model training base path: \".\"\n",
      "2020-05-17 16:47:21,557 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:47:21,558 Device: cuda:0\n",
      "2020-05-17 16:47:21,558 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:47:21,558 Embeddings storage mode: cpu\n",
      "2020-05-17 16:47:21,567 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:47:21,639 epoch 1 - iter 0/1715 - loss 1.64689314 - samples/sec: 19620.26\n",
      "2020-05-17 16:47:32,675 epoch 1 - iter 171/1715 - loss 1.46176034 - samples/sec: 124.08\n",
      "2020-05-17 16:47:43,392 epoch 1 - iter 342/1715 - loss 1.45667674 - samples/sec: 127.86\n",
      "2020-05-17 16:47:54,166 epoch 1 - iter 513/1715 - loss 1.44526867 - samples/sec: 127.09\n",
      "2020-05-17 16:48:04,864 epoch 1 - iter 684/1715 - loss 1.43354224 - samples/sec: 127.99\n",
      "2020-05-17 16:48:15,315 epoch 1 - iter 855/1715 - loss 1.42067421 - samples/sec: 131.03\n",
      "2020-05-17 16:48:25,977 epoch 1 - iter 1026/1715 - loss 1.40796098 - samples/sec: 128.43\n",
      "2020-05-17 16:48:36,519 epoch 1 - iter 1197/1715 - loss 1.39630480 - samples/sec: 129.91\n",
      "2020-05-17 16:48:49,584 epoch 1 - iter 1368/1715 - loss 1.38928959 - samples/sec: 104.80\n",
      "2020-05-17 16:49:00,150 epoch 1 - iter 1539/1715 - loss 1.38341093 - samples/sec: 129.61\n",
      "2020-05-17 16:49:10,785 epoch 1 - iter 1710/1715 - loss 1.37521932 - samples/sec: 128.76\n",
      "2020-05-17 16:49:11,032 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:49:11,033 EPOCH 1 done: loss 1.3751 - lr 0.1000\n",
      "2020-05-17 16:49:14,165 DEV : loss 1.230200171470642 - score 0.496\n",
      "2020-05-17 16:49:14,231 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BytePairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:49:15,020 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:49:15,059 epoch 2 - iter 0/1715 - loss 1.63396847 - samples/sec: 39174.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:49:19,629 epoch 2 - iter 171/1715 - loss 1.31060433 - samples/sec: 300.14\n",
      "2020-05-17 16:49:24,242 epoch 2 - iter 342/1715 - loss 1.31338758 - samples/sec: 297.29\n",
      "2020-05-17 16:49:28,819 epoch 2 - iter 513/1715 - loss 1.31107140 - samples/sec: 299.74\n",
      "2020-05-17 16:49:33,402 epoch 2 - iter 684/1715 - loss 1.31032169 - samples/sec: 299.55\n",
      "2020-05-17 16:49:37,960 epoch 2 - iter 855/1715 - loss 1.30592586 - samples/sec: 301.06\n",
      "2020-05-17 16:49:42,609 epoch 2 - iter 1026/1715 - loss 1.30149488 - samples/sec: 295.33\n",
      "2020-05-17 16:49:46,390 epoch 2 - iter 1197/1715 - loss 1.30320098 - samples/sec: 363.33\n",
      "2020-05-17 16:49:50,987 epoch 2 - iter 1368/1715 - loss 1.30870206 - samples/sec: 298.55\n",
      "2020-05-17 16:49:55,607 epoch 2 - iter 1539/1715 - loss 1.30752952 - samples/sec: 297.11\n",
      "2020-05-17 16:50:00,276 epoch 2 - iter 1710/1715 - loss 1.30771399 - samples/sec: 293.82\n",
      "2020-05-17 16:50:00,401 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:50:00,402 EPOCH 2 done: loss 1.3079 - lr 0.1000\n",
      "2020-05-17 16:50:01,315 DEV : loss 1.2255460023880005 - score 0.504\n",
      "2020-05-17 16:50:01,382 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:50:02,118 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:50:02,152 epoch 3 - iter 0/1715 - loss 1.24532342 - samples/sec: 43530.57\n",
      "2020-05-17 16:50:06,752 epoch 3 - iter 171/1715 - loss 1.29794801 - samples/sec: 298.33\n",
      "2020-05-17 16:50:11,337 epoch 3 - iter 342/1715 - loss 1.29980787 - samples/sec: 299.41\n",
      "2020-05-17 16:50:15,966 epoch 3 - iter 513/1715 - loss 1.28388946 - samples/sec: 296.60\n",
      "2020-05-17 16:50:20,507 epoch 3 - iter 684/1715 - loss 1.28530199 - samples/sec: 302.11\n",
      "2020-05-17 16:50:25,102 epoch 3 - iter 855/1715 - loss 1.28250144 - samples/sec: 298.71\n",
      "2020-05-17 16:50:29,846 epoch 3 - iter 1026/1715 - loss 1.27203670 - samples/sec: 289.05\n",
      "2020-05-17 16:50:34,572 epoch 3 - iter 1197/1715 - loss 1.26372273 - samples/sec: 290.43\n",
      "2020-05-17 16:50:39,134 epoch 3 - iter 1368/1715 - loss 1.26920823 - samples/sec: 300.96\n",
      "2020-05-17 16:50:43,742 epoch 3 - iter 1539/1715 - loss 1.26437081 - samples/sec: 297.91\n",
      "2020-05-17 16:50:47,841 epoch 3 - iter 1710/1715 - loss 1.25896041 - samples/sec: 334.54\n",
      "2020-05-17 16:50:47,931 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:50:47,932 EPOCH 3 done: loss 1.2586 - lr 0.1000\n",
      "2020-05-17 16:50:48,856 DEV : loss 1.2602218389511108 - score 0.508\n",
      "2020-05-17 16:50:48,921 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:50:49,640 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:50:49,674 epoch 4 - iter 0/1715 - loss 1.55691731 - samples/sec: 44566.19\n",
      "2020-05-17 16:50:53,339 epoch 4 - iter 171/1715 - loss 1.24106836 - samples/sec: 374.28\n",
      "2020-05-17 16:50:57,326 epoch 4 - iter 342/1715 - loss 1.21081071 - samples/sec: 344.36\n",
      "2020-05-17 16:51:01,934 epoch 4 - iter 513/1715 - loss 1.20053451 - samples/sec: 297.85\n",
      "2020-05-17 16:51:05,756 epoch 4 - iter 684/1715 - loss 1.19752267 - samples/sec: 359.33\n",
      "2020-05-17 16:51:10,203 epoch 4 - iter 855/1715 - loss 1.20528043 - samples/sec: 308.71\n",
      "2020-05-17 16:51:14,780 epoch 4 - iter 1026/1715 - loss 1.20583201 - samples/sec: 299.85\n",
      "2020-05-17 16:51:19,356 epoch 4 - iter 1197/1715 - loss 1.20363036 - samples/sec: 299.94\n",
      "2020-05-17 16:51:23,937 epoch 4 - iter 1368/1715 - loss 1.19886953 - samples/sec: 299.73\n",
      "2020-05-17 16:51:28,601 epoch 4 - iter 1539/1715 - loss 1.19530046 - samples/sec: 293.97\n",
      "2020-05-17 16:51:33,142 epoch 4 - iter 1710/1715 - loss 1.19240744 - samples/sec: 302.48\n",
      "2020-05-17 16:51:33,257 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:51:33,258 EPOCH 4 done: loss 1.1930 - lr 0.1000\n",
      "2020-05-17 16:51:34,175 DEV : loss 1.118142008781433 - score 0.528\n",
      "2020-05-17 16:51:34,241 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:51:34,969 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:51:35,001 epoch 5 - iter 0/1715 - loss 1.03845382 - samples/sec: 48355.03\n",
      "2020-05-17 16:51:39,554 epoch 5 - iter 171/1715 - loss 1.14453258 - samples/sec: 301.38\n",
      "2020-05-17 16:51:44,194 epoch 5 - iter 342/1715 - loss 1.15623271 - samples/sec: 295.83\n",
      "2020-05-17 16:51:48,739 epoch 5 - iter 513/1715 - loss 1.14851358 - samples/sec: 301.64\n",
      "2020-05-17 16:51:53,257 epoch 5 - iter 684/1715 - loss 1.15113220 - samples/sec: 303.80\n",
      "2020-05-17 16:51:56,940 epoch 5 - iter 855/1715 - loss 1.14918958 - samples/sec: 373.03\n",
      "2020-05-17 16:52:01,572 epoch 5 - iter 1026/1715 - loss 1.14395546 - samples/sec: 296.04\n",
      "2020-05-17 16:52:05,518 epoch 5 - iter 1197/1715 - loss 1.13949500 - samples/sec: 348.00\n",
      "2020-05-17 16:52:10,066 epoch 5 - iter 1368/1715 - loss 1.14128642 - samples/sec: 301.86\n",
      "2020-05-17 16:52:13,755 epoch 5 - iter 1539/1715 - loss 1.13697871 - samples/sec: 372.43\n",
      "2020-05-17 16:52:17,458 epoch 5 - iter 1710/1715 - loss 1.13641702 - samples/sec: 370.58\n",
      "2020-05-17 16:52:17,553 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:52:17,554 EPOCH 5 done: loss 1.1360 - lr 0.1000\n",
      "2020-05-17 16:52:18,475 DEV : loss 1.1424779891967773 - score 0.534\n",
      "2020-05-17 16:52:18,541 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:52:19,262 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:52:19,291 epoch 6 - iter 0/1715 - loss 0.57256770 - samples/sec: 52249.76\n",
      "2020-05-17 16:52:23,894 epoch 6 - iter 171/1715 - loss 1.10159691 - samples/sec: 298.07\n",
      "2020-05-17 16:52:28,499 epoch 6 - iter 342/1715 - loss 1.10085693 - samples/sec: 297.72\n",
      "2020-05-17 16:52:33,348 epoch 6 - iter 513/1715 - loss 1.09800331 - samples/sec: 283.04\n",
      "2020-05-17 16:52:38,071 epoch 6 - iter 684/1715 - loss 1.09844660 - samples/sec: 290.55\n",
      "2020-05-17 16:52:42,603 epoch 6 - iter 855/1715 - loss 1.09023019 - samples/sec: 302.85\n",
      "2020-05-17 16:52:47,140 epoch 6 - iter 1026/1715 - loss 1.09498249 - samples/sec: 302.56\n",
      "2020-05-17 16:52:51,648 epoch 6 - iter 1197/1715 - loss 1.09164745 - samples/sec: 304.61\n",
      "2020-05-17 16:52:56,200 epoch 6 - iter 1368/1715 - loss 1.09058479 - samples/sec: 301.51\n",
      "2020-05-17 16:53:00,720 epoch 6 - iter 1539/1715 - loss 1.08968996 - samples/sec: 303.76\n",
      "2020-05-17 16:53:05,345 epoch 6 - iter 1710/1715 - loss 1.08789339 - samples/sec: 296.44\n",
      "2020-05-17 16:53:05,467 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:53:05,469 EPOCH 6 done: loss 1.0879 - lr 0.1000\n",
      "2020-05-17 16:53:06,382 DEV : loss 1.0556714534759521 - score 0.588\n",
      "2020-05-17 16:53:06,448 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:53:07,160 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:53:07,191 epoch 7 - iter 0/1715 - loss 0.92515761 - samples/sec: 48928.60\n",
      "2020-05-17 16:53:11,729 epoch 7 - iter 171/1715 - loss 1.08362340 - samples/sec: 302.26\n",
      "2020-05-17 16:53:16,219 epoch 7 - iter 342/1715 - loss 1.08230991 - samples/sec: 305.84\n",
      "2020-05-17 16:53:20,725 epoch 7 - iter 513/1715 - loss 1.06739744 - samples/sec: 304.25\n",
      "2020-05-17 16:53:25,199 epoch 7 - iter 684/1715 - loss 1.06878501 - samples/sec: 306.93\n",
      "2020-05-17 16:53:29,729 epoch 7 - iter 855/1715 - loss 1.07185125 - samples/sec: 302.98\n",
      "2020-05-17 16:53:34,279 epoch 7 - iter 1026/1715 - loss 1.06787174 - samples/sec: 301.41\n",
      "2020-05-17 16:53:38,832 epoch 7 - iter 1197/1715 - loss 1.06209301 - samples/sec: 301.48\n",
      "2020-05-17 16:53:43,370 epoch 7 - iter 1368/1715 - loss 1.06124370 - samples/sec: 302.43\n",
      "2020-05-17 16:53:47,654 epoch 7 - iter 1539/1715 - loss 1.06131933 - samples/sec: 320.08\n",
      "2020-05-17 16:53:51,318 epoch 7 - iter 1710/1715 - loss 1.05831742 - samples/sec: 374.36\n",
      "2020-05-17 16:53:51,433 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:53:51,434 EPOCH 7 done: loss 1.0583 - lr 0.1000\n",
      "2020-05-17 16:53:52,350 DEV : loss 0.9696139097213745 - score 0.626\n",
      "2020-05-17 16:53:52,416 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:53:53,137 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:53:53,168 epoch 8 - iter 0/1715 - loss 0.82208282 - samples/sec: 48532.54\n",
      "2020-05-17 16:53:57,776 epoch 8 - iter 171/1715 - loss 1.02148490 - samples/sec: 297.99\n",
      "2020-05-17 16:54:02,325 epoch 8 - iter 342/1715 - loss 1.01442451 - samples/sec: 301.63\n",
      "2020-05-17 16:54:06,907 epoch 8 - iter 513/1715 - loss 1.03322960 - samples/sec: 299.28\n",
      "2020-05-17 16:54:10,521 epoch 8 - iter 684/1715 - loss 1.02058364 - samples/sec: 380.03\n",
      "2020-05-17 16:54:14,717 epoch 8 - iter 855/1715 - loss 1.02355808 - samples/sec: 326.73\n",
      "2020-05-17 16:54:19,210 epoch 8 - iter 1026/1715 - loss 1.01847311 - samples/sec: 305.39\n",
      "2020-05-17 16:54:23,744 epoch 8 - iter 1197/1715 - loss 1.01613042 - samples/sec: 302.80\n",
      "2020-05-17 16:54:28,365 epoch 8 - iter 1368/1715 - loss 1.01305997 - samples/sec: 297.09\n",
      "2020-05-17 16:54:32,978 epoch 8 - iter 1539/1715 - loss 1.01232175 - samples/sec: 297.59\n",
      "2020-05-17 16:54:37,586 epoch 8 - iter 1710/1715 - loss 1.00726659 - samples/sec: 297.72\n",
      "2020-05-17 16:54:37,683 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:54:37,684 EPOCH 8 done: loss 1.0070 - lr 0.1000\n",
      "2020-05-17 16:54:38,596 DEV : loss 0.9353408217430115 - score 0.632\n",
      "2020-05-17 16:54:38,662 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:54:39,384 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:54:39,415 epoch 9 - iter 0/1715 - loss 1.06408501 - samples/sec: 47613.50\n",
      "2020-05-17 16:54:43,929 epoch 9 - iter 171/1715 - loss 1.00573541 - samples/sec: 304.10\n",
      "2020-05-17 16:54:48,453 epoch 9 - iter 342/1715 - loss 0.98245716 - samples/sec: 303.34\n",
      "2020-05-17 16:54:52,960 epoch 9 - iter 513/1715 - loss 0.97767099 - samples/sec: 304.58\n",
      "2020-05-17 16:54:56,576 epoch 9 - iter 684/1715 - loss 0.96605589 - samples/sec: 380.00\n",
      "2020-05-17 16:55:00,914 epoch 9 - iter 855/1715 - loss 0.96765406 - samples/sec: 316.14\n",
      "2020-05-17 16:55:05,172 epoch 9 - iter 1026/1715 - loss 0.97311436 - samples/sec: 322.51\n",
      "2020-05-17 16:55:09,688 epoch 9 - iter 1197/1715 - loss 0.97469130 - samples/sec: 303.97\n",
      "2020-05-17 16:55:14,247 epoch 9 - iter 1368/1715 - loss 0.97125541 - samples/sec: 301.02\n",
      "2020-05-17 16:55:18,816 epoch 9 - iter 1539/1715 - loss 0.97036314 - samples/sec: 300.43\n",
      "2020-05-17 16:55:23,416 epoch 9 - iter 1710/1715 - loss 0.96937481 - samples/sec: 298.40\n",
      "2020-05-17 16:55:23,529 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:55:23,530 EPOCH 9 done: loss 0.9697 - lr 0.1000\n",
      "2020-05-17 16:55:24,442 DEV : loss 0.9267056584358215 - score 0.622\n",
      "2020-05-17 16:55:24,507 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 16:55:24,509 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:55:24,534 epoch 10 - iter 0/1715 - loss 1.20338368 - samples/sec: 58331.21\n",
      "2020-05-17 16:55:29,052 epoch 10 - iter 171/1715 - loss 0.95376356 - samples/sec: 303.76\n",
      "2020-05-17 16:55:33,580 epoch 10 - iter 342/1715 - loss 0.92942945 - samples/sec: 302.82\n",
      "2020-05-17 16:55:38,114 epoch 10 - iter 513/1715 - loss 0.92796238 - samples/sec: 302.66\n",
      "2020-05-17 16:55:42,595 epoch 10 - iter 684/1715 - loss 0.94109380 - samples/sec: 305.98\n",
      "2020-05-17 16:55:47,199 epoch 10 - iter 855/1715 - loss 0.94822124 - samples/sec: 298.06\n",
      "2020-05-17 16:55:51,768 epoch 10 - iter 1026/1715 - loss 0.94479819 - samples/sec: 300.40\n",
      "2020-05-17 16:55:56,304 epoch 10 - iter 1197/1715 - loss 0.94497905 - samples/sec: 302.72\n",
      "2020-05-17 16:56:00,856 epoch 10 - iter 1368/1715 - loss 0.94005718 - samples/sec: 301.48\n",
      "2020-05-17 16:56:05,443 epoch 10 - iter 1539/1715 - loss 0.93717212 - samples/sec: 299.37\n",
      "2020-05-17 16:56:10,000 epoch 10 - iter 1710/1715 - loss 0.93712999 - samples/sec: 301.15\n",
      "2020-05-17 16:56:10,123 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:56:10,124 EPOCH 10 done: loss 0.9378 - lr 0.1000\n",
      "2020-05-17 16:56:11,040 DEV : loss 0.9416190981864929 - score 0.65\n",
      "2020-05-17 16:56:11,104 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:56:11,827 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:56:11,858 epoch 11 - iter 0/1715 - loss 1.13874114 - samples/sec: 48363.59\n",
      "2020-05-17 16:56:16,383 epoch 11 - iter 171/1715 - loss 0.88464000 - samples/sec: 303.21\n",
      "2020-05-17 16:56:20,904 epoch 11 - iter 342/1715 - loss 0.89957091 - samples/sec: 303.82\n",
      "2020-05-17 16:56:25,409 epoch 11 - iter 513/1715 - loss 0.89846460 - samples/sec: 304.56\n",
      "2020-05-17 16:56:29,886 epoch 11 - iter 684/1715 - loss 0.91528347 - samples/sec: 306.70\n",
      "2020-05-17 16:56:34,416 epoch 11 - iter 855/1715 - loss 0.91471955 - samples/sec: 302.84\n",
      "2020-05-17 16:56:38,953 epoch 11 - iter 1026/1715 - loss 0.90826512 - samples/sec: 302.67\n",
      "2020-05-17 16:56:43,502 epoch 11 - iter 1197/1715 - loss 0.91001122 - samples/sec: 301.72\n",
      "2020-05-17 16:56:48,044 epoch 11 - iter 1368/1715 - loss 0.90672836 - samples/sec: 301.87\n",
      "2020-05-17 16:56:52,637 epoch 11 - iter 1539/1715 - loss 0.90688910 - samples/sec: 298.77\n",
      "2020-05-17 16:56:57,247 epoch 11 - iter 1710/1715 - loss 0.90729592 - samples/sec: 297.76\n",
      "2020-05-17 16:56:57,365 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:56:57,366 EPOCH 11 done: loss 0.9079 - lr 0.1000\n",
      "2020-05-17 16:56:58,278 DEV : loss 0.8749749660491943 - score 0.64\n",
      "2020-05-17 16:56:58,345 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 16:56:58,347 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:56:58,373 epoch 12 - iter 0/1715 - loss 0.95192909 - samples/sec: 55906.07\n",
      "2020-05-17 16:57:02,829 epoch 12 - iter 171/1715 - loss 0.86984039 - samples/sec: 307.98\n",
      "2020-05-17 16:57:07,353 epoch 12 - iter 342/1715 - loss 0.86622075 - samples/sec: 303.26\n",
      "2020-05-17 16:57:11,899 epoch 12 - iter 513/1715 - loss 0.87119925 - samples/sec: 301.77\n",
      "2020-05-17 16:57:16,425 epoch 12 - iter 684/1715 - loss 0.88378386 - samples/sec: 303.20\n",
      "2020-05-17 16:57:20,922 epoch 12 - iter 855/1715 - loss 0.87682684 - samples/sec: 305.11\n",
      "2020-05-17 16:57:25,394 epoch 12 - iter 1026/1715 - loss 0.88829559 - samples/sec: 306.80\n",
      "2020-05-17 16:57:29,929 epoch 12 - iter 1197/1715 - loss 0.88781045 - samples/sec: 302.76\n",
      "2020-05-17 16:57:34,482 epoch 12 - iter 1368/1715 - loss 0.88504322 - samples/sec: 301.16\n",
      "2020-05-17 16:57:39,032 epoch 12 - iter 1539/1715 - loss 0.87844490 - samples/sec: 301.76\n",
      "2020-05-17 16:57:43,632 epoch 12 - iter 1710/1715 - loss 0.87750214 - samples/sec: 298.30\n",
      "2020-05-17 16:57:43,750 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:57:43,751 EPOCH 12 done: loss 0.8771 - lr 0.1000\n",
      "2020-05-17 16:57:44,667 DEV : loss 0.854022204875946 - score 0.65\n",
      "2020-05-17 16:57:44,732 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 16:57:45,454 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:57:45,487 epoch 13 - iter 0/1715 - loss 1.22931302 - samples/sec: 46491.23\n",
      "2020-05-17 16:57:50,020 epoch 13 - iter 171/1715 - loss 0.82525581 - samples/sec: 302.59\n",
      "2020-05-17 16:57:54,535 epoch 13 - iter 342/1715 - loss 0.84732745 - samples/sec: 303.96\n",
      "2020-05-17 16:57:59,041 epoch 13 - iter 513/1715 - loss 0.84665378 - samples/sec: 304.59\n",
      "2020-05-17 16:58:03,552 epoch 13 - iter 684/1715 - loss 0.84677296 - samples/sec: 304.16\n",
      "2020-05-17 16:58:08,095 epoch 13 - iter 855/1715 - loss 0.84555318 - samples/sec: 302.03\n",
      "2020-05-17 16:58:12,502 epoch 13 - iter 1026/1715 - loss 0.85203172 - samples/sec: 311.47\n",
      "2020-05-17 16:58:17,035 epoch 13 - iter 1197/1715 - loss 0.85916213 - samples/sec: 302.45\n",
      "2020-05-17 16:58:21,589 epoch 13 - iter 1368/1715 - loss 0.85687795 - samples/sec: 301.32\n",
      "2020-05-17 16:58:26,140 epoch 13 - iter 1539/1715 - loss 0.85521003 - samples/sec: 301.45\n",
      "2020-05-17 16:58:30,712 epoch 13 - iter 1710/1715 - loss 0.85695585 - samples/sec: 300.25\n",
      "2020-05-17 16:58:30,823 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 16:58:30,824 EPOCH 13 done: loss 0.8560 - lr 0.1000\n",
      "2020-05-17 16:58:31,735 DEV : loss 0.8043615818023682 - score 0.692\n",
      "2020-05-17 16:58:31,801 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:58:32,522 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:58:32,550 epoch 14 - iter 0/1715 - loss 0.56504428 - samples/sec: 54411.56\n",
      "2020-05-17 16:58:36,511 epoch 14 - iter 171/1715 - loss 0.77782936 - samples/sec: 346.64\n",
      "2020-05-17 16:58:41,052 epoch 14 - iter 342/1715 - loss 0.81480094 - samples/sec: 302.35\n",
      "2020-05-17 16:58:45,578 epoch 14 - iter 513/1715 - loss 0.80179396 - samples/sec: 303.18\n",
      "2020-05-17 16:58:50,121 epoch 14 - iter 684/1715 - loss 0.81738869 - samples/sec: 301.96\n",
      "2020-05-17 16:58:54,656 epoch 14 - iter 855/1715 - loss 0.81996810 - samples/sec: 302.53\n",
      "2020-05-17 16:58:59,144 epoch 14 - iter 1026/1715 - loss 0.82458848 - samples/sec: 306.05\n",
      "2020-05-17 16:59:03,694 epoch 14 - iter 1197/1715 - loss 0.82887917 - samples/sec: 301.62\n",
      "2020-05-17 16:59:07,668 epoch 14 - iter 1368/1715 - loss 0.82966173 - samples/sec: 345.47\n",
      "2020-05-17 16:59:11,455 epoch 14 - iter 1539/1715 - loss 0.82839213 - samples/sec: 362.16\n",
      "2020-05-17 16:59:16,039 epoch 14 - iter 1710/1715 - loss 0.82772308 - samples/sec: 299.62\n",
      "2020-05-17 16:59:16,154 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:59:16,155 EPOCH 14 done: loss 0.8278 - lr 0.1000\n",
      "2020-05-17 16:59:17,068 DEV : loss 0.7702049612998962 - score 0.696\n",
      "2020-05-17 16:59:17,133 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 16:59:17,857 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 16:59:17,890 epoch 15 - iter 0/1715 - loss 0.63694662 - samples/sec: 45445.46\n",
      "2020-05-17 16:59:22,431 epoch 15 - iter 171/1715 - loss 0.77916013 - samples/sec: 302.28\n",
      "2020-05-17 16:59:26,964 epoch 15 - iter 342/1715 - loss 0.78990134 - samples/sec: 302.48\n",
      "2020-05-17 16:59:31,518 epoch 15 - iter 513/1715 - loss 0.78853297 - samples/sec: 301.54\n",
      "2020-05-17 16:59:36,029 epoch 15 - iter 684/1715 - loss 0.79452832 - samples/sec: 304.16\n",
      "2020-05-17 16:59:40,518 epoch 15 - iter 855/1715 - loss 0.79706196 - samples/sec: 305.82\n",
      "2020-05-17 16:59:45,019 epoch 15 - iter 1026/1715 - loss 0.79455352 - samples/sec: 305.07\n",
      "2020-05-17 16:59:49,612 epoch 15 - iter 1197/1715 - loss 0.80434622 - samples/sec: 298.85\n",
      "2020-05-17 16:59:54,075 epoch 15 - iter 1368/1715 - loss 0.80658026 - samples/sec: 307.56\n",
      "2020-05-17 16:59:58,633 epoch 15 - iter 1539/1715 - loss 0.80878263 - samples/sec: 301.10\n",
      "2020-05-17 17:00:02,675 epoch 15 - iter 1710/1715 - loss 0.81524833 - samples/sec: 339.68\n",
      "2020-05-17 17:00:02,770 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:00:02,771 EPOCH 15 done: loss 0.8155 - lr 0.1000\n",
      "2020-05-17 17:00:03,683 DEV : loss 0.7656854391098022 - score 0.706\n",
      "2020-05-17 17:00:03,749 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:00:05,247 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:00:05,248 Testing using best model ...\n",
      "2020-05-17 17:00:05,250 loading file best-model.pt\n",
      "2020-05-17 17:00:07,838 0.75\t0.75\t0.75\n",
      "2020-05-17 17:00:07,839 \n",
      "MICRO_AVG: acc 0.6 - f1-score 0.75\n",
      "MACRO_AVG: acc 0.5084 - f1-score 0.6541600000000001\n",
      "0          tp: 136 - fp: 46 - fn: 10 - tn: 308 - precision: 0.7473 - recall: 0.9315 - accuracy: 0.7083 - f1-score: 0.8293\n",
      "1          tp: 51 - fp: 22 - fn: 37 - tn: 390 - precision: 0.6986 - recall: 0.5795 - accuracy: 0.4636 - f1-score: 0.6335\n",
      "2          tp: 2 - fp: 0 - fn: 8 - tn: 490 - precision: 1.0000 - recall: 0.2000 - accuracy: 0.2000 - f1-score: 0.3333\n",
      "3          tp: 121 - fp: 36 - fn: 37 - tn: 306 - precision: 0.7707 - recall: 0.7658 - accuracy: 0.6237 - f1-score: 0.7682\n",
      "4          tp: 65 - fp: 21 - fn: 33 - tn: 381 - precision: 0.7558 - recall: 0.6633 - accuracy: 0.5462 - f1-score: 0.7065\n",
      "2020-05-17 17:00:07,840 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "788.3204953670502\n"
     ]
    }
   ],
   "source": [
    "#BPE - takes memory - reduce batch size radically!\n",
    "total_time = time.time()\n",
    "\n",
    "word_embeddings = [ BytePairEmbeddings('en'),   ]\n",
    "modelname = 'BytePairEmbedding'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS, batch_size=8)               \n",
    "\n",
    "print(time.time() - total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-1\n",
      "2020-05-18 16:17:10,310 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-18 16:17:10,312 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-18 16:17:10,312 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-18 16:17:10,313 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:17:14,455 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 90972.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:17:14,461 [b'1', b'0', b'4', b'3', b'2']\n",
      "2020-05-18 16:17:14,462 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:00<00:00, 248994.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:17:14,467 [b'1', b'0', b'4', b'3', b'2']\n",
      "2020-05-18 16:17:14,473 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:17:14,476 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): OpenAIGPTEmbeddings(\n",
      "        model=0-openai-gpt\n",
      "        (model): OpenAIGPTModel(\n",
      "          (tokens_embed): Embedding(40478, 768)\n",
      "          (positions_embed): Embedding(512, 768)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "          (h): ModuleList(\n",
      "            (0): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (1): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (3): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (4): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (5): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (6): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (7): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (8): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (9): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (10): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (11): Block(\n",
      "              (attn): Attention(\n",
      "                (c_attn): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "                (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): MLP(\n",
      "                (c_fc): Conv1D()\n",
      "                (c_proj): Conv1D()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=1536, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-18 16:17:14,477 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:17:14,478 Corpus: \"Corpus: 200 train + 500 dev + 500 test sentences\"\n",
      "2020-05-18 16:17:14,478 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:17:14,479 Parameters:\n",
      "2020-05-18 16:17:14,479  - learning_rate: \"0.1\"\n",
      "2020-05-18 16:17:14,480  - mini_batch_size: \"4\"\n",
      "2020-05-18 16:17:14,481  - patience: \"5\"\n",
      "2020-05-18 16:17:14,481  - anneal_factor: \"0.5\"\n",
      "2020-05-18 16:17:14,482  - max_epochs: \"15\"\n",
      "2020-05-18 16:17:14,483  - shuffle: \"True\"\n",
      "2020-05-18 16:17:14,484  - train_with_dev: \"False\"\n",
      "2020-05-18 16:17:14,485  - batch_growth_annealing: \"False\"\n",
      "2020-05-18 16:17:14,485 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:17:14,486 Model training base path: \".\"\n",
      "2020-05-18 16:17:14,487 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:17:14,490 Device: cuda:0\n",
      "2020-05-18 16:17:14,491 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:17:14,492 Embeddings storage mode: cpu\n",
      "2020-05-18 16:17:14,496 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:17:15,023 epoch 1 - iter 0/50 - loss 1.57646501 - samples/sec: 38.11\n",
      "2020-05-18 16:17:17,764 epoch 1 - iter 5/50 - loss 1.66154005 - samples/sec: 7.60\n",
      "2020-05-18 16:17:20,372 epoch 1 - iter 10/50 - loss 1.65476380 - samples/sec: 7.96\n",
      "2020-05-18 16:17:22,956 epoch 1 - iter 15/50 - loss 1.61488535 - samples/sec: 8.02\n",
      "2020-05-18 16:17:25,502 epoch 1 - iter 20/50 - loss 1.59133152 - samples/sec: 8.15\n",
      "2020-05-18 16:17:27,999 epoch 1 - iter 25/50 - loss 1.59074516 - samples/sec: 8.31\n",
      "2020-05-18 16:17:30,742 epoch 1 - iter 30/50 - loss 1.60192063 - samples/sec: 7.57\n",
      "2020-05-18 16:17:33,309 epoch 1 - iter 35/50 - loss 1.58490951 - samples/sec: 8.09\n",
      "2020-05-18 16:17:35,824 epoch 1 - iter 40/50 - loss 1.62698720 - samples/sec: 8.24\n",
      "2020-05-18 16:17:38,355 epoch 1 - iter 45/50 - loss 1.61725956 - samples/sec: 8.19\n",
      "2020-05-18 16:17:41,058 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:17:41,059 EPOCH 1 done: loss 1.6236 - lr 0.1000\n",
      "2020-05-18 16:18:41,842 DEV : loss 1.4604296684265137 - score 0.288\n",
      "2020-05-18 16:18:42,137 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type OpenAIGPTEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type OpenAIGPTModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ModuleList. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Block. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv1D. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MLP. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:18:43,890 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:18:43,951 epoch 2 - iter 0/50 - loss 1.22715783 - samples/sec: 342.27\n",
      "2020-05-18 16:18:44,350 epoch 2 - iter 5/50 - loss 1.27280040 - samples/sec: 67.04\n",
      "2020-05-18 16:18:44,714 epoch 2 - iter 10/50 - loss 1.41183447 - samples/sec: 74.33\n",
      "2020-05-18 16:18:45,090 epoch 2 - iter 15/50 - loss 1.42460554 - samples/sec: 71.58\n",
      "2020-05-18 16:18:45,450 epoch 2 - iter 20/50 - loss 1.44614340 - samples/sec: 73.86\n",
      "2020-05-18 16:18:45,829 epoch 2 - iter 25/50 - loss 1.42678155 - samples/sec: 70.07\n",
      "2020-05-18 16:18:46,244 epoch 2 - iter 30/50 - loss 1.43389569 - samples/sec: 62.48\n",
      "2020-05-18 16:18:46,621 epoch 2 - iter 35/50 - loss 1.41338287 - samples/sec: 69.91\n",
      "2020-05-18 16:18:46,981 epoch 2 - iter 40/50 - loss 1.38628011 - samples/sec: 73.72\n",
      "2020-05-18 16:18:47,375 epoch 2 - iter 45/50 - loss 1.36595527 - samples/sec: 66.40\n",
      "2020-05-18 16:18:47,725 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:18:47,726 EPOCH 2 done: loss 1.3821 - lr 0.1000\n",
      "2020-05-18 16:18:52,292 DEV : loss 1.660223364830017 - score 0.336\n",
      "2020-05-18 16:18:52,569 BAD EPOCHS (no improvement): 0\n",
      "2020-05-18 16:18:54,354 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:18:54,417 epoch 3 - iter 0/50 - loss 1.92387533 - samples/sec: 338.81\n",
      "2020-05-18 16:18:54,795 epoch 3 - iter 5/50 - loss 1.14247303 - samples/sec: 69.17\n",
      "2020-05-18 16:18:55,172 epoch 3 - iter 10/50 - loss 1.22670809 - samples/sec: 69.59\n",
      "2020-05-18 16:18:55,537 epoch 3 - iter 15/50 - loss 1.12809183 - samples/sec: 74.81\n",
      "2020-05-18 16:18:55,917 epoch 3 - iter 20/50 - loss 1.12012815 - samples/sec: 69.83\n",
      "2020-05-18 16:18:56,291 epoch 3 - iter 25/50 - loss 1.14528209 - samples/sec: 71.19\n",
      "2020-05-18 16:18:56,677 epoch 3 - iter 30/50 - loss 1.15635279 - samples/sec: 69.47\n",
      "2020-05-18 16:18:57,054 epoch 3 - iter 35/50 - loss 1.16250913 - samples/sec: 70.02\n",
      "2020-05-18 16:18:57,458 epoch 3 - iter 40/50 - loss 1.17707449 - samples/sec: 64.41\n",
      "2020-05-18 16:18:57,838 epoch 3 - iter 45/50 - loss 1.18033744 - samples/sec: 70.42\n",
      "2020-05-18 16:18:58,153 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:18:58,154 EPOCH 3 done: loss 1.1738 - lr 0.1000\n",
      "2020-05-18 16:19:02,703 DEV : loss 2.0344388484954834 - score 0.306\n",
      "2020-05-18 16:19:02,995 BAD EPOCHS (no improvement): 1\n",
      "2020-05-18 16:19:02,996 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:03,053 epoch 4 - iter 0/50 - loss 0.94077408 - samples/sec: 362.80\n",
      "2020-05-18 16:19:03,436 epoch 4 - iter 5/50 - loss 0.87055765 - samples/sec: 68.28\n",
      "2020-05-18 16:19:03,834 epoch 4 - iter 10/50 - loss 0.79641318 - samples/sec: 65.77\n",
      "2020-05-18 16:19:04,221 epoch 4 - iter 15/50 - loss 0.86036747 - samples/sec: 68.56\n",
      "2020-05-18 16:19:04,601 epoch 4 - iter 20/50 - loss 0.88853143 - samples/sec: 70.60\n",
      "2020-05-18 16:19:05,012 epoch 4 - iter 25/50 - loss 0.92489548 - samples/sec: 65.55\n",
      "2020-05-18 16:19:05,431 epoch 4 - iter 30/50 - loss 0.93738039 - samples/sec: 62.76\n",
      "2020-05-18 16:19:05,810 epoch 4 - iter 35/50 - loss 0.92857026 - samples/sec: 70.15\n",
      "2020-05-18 16:19:06,223 epoch 4 - iter 40/50 - loss 0.95900211 - samples/sec: 64.98\n",
      "2020-05-18 16:19:06,603 epoch 4 - iter 45/50 - loss 0.92528792 - samples/sec: 71.93\n",
      "2020-05-18 16:19:06,953 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:06,954 EPOCH 4 done: loss 0.9526 - lr 0.1000\n",
      "2020-05-18 16:19:11,367 DEV : loss 1.69606351852417 - score 0.264\n",
      "2020-05-18 16:19:11,647 BAD EPOCHS (no improvement): 2\n",
      "2020-05-18 16:19:11,648 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:11,707 epoch 5 - iter 0/50 - loss 0.27461830 - samples/sec: 350.40\n",
      "2020-05-18 16:19:12,083 epoch 5 - iter 5/50 - loss 0.69137332 - samples/sec: 70.38\n",
      "2020-05-18 16:19:12,466 epoch 5 - iter 10/50 - loss 0.74233958 - samples/sec: 69.07\n",
      "2020-05-18 16:19:12,837 epoch 5 - iter 15/50 - loss 0.79864739 - samples/sec: 71.24\n",
      "2020-05-18 16:19:13,209 epoch 5 - iter 20/50 - loss 0.79832262 - samples/sec: 72.82\n",
      "2020-05-18 16:19:13,572 epoch 5 - iter 25/50 - loss 0.81750142 - samples/sec: 74.45\n",
      "2020-05-18 16:19:13,936 epoch 5 - iter 30/50 - loss 0.80492968 - samples/sec: 72.81\n",
      "2020-05-18 16:19:14,309 epoch 5 - iter 35/50 - loss 0.76806039 - samples/sec: 70.72\n",
      "2020-05-18 16:19:14,700 epoch 5 - iter 40/50 - loss 0.81112125 - samples/sec: 67.27\n",
      "2020-05-18 16:19:15,093 epoch 5 - iter 45/50 - loss 0.83906712 - samples/sec: 68.47\n",
      "2020-05-18 16:19:15,409 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:15,410 EPOCH 5 done: loss 0.8829 - lr 0.1000\n",
      "2020-05-18 16:19:19,877 DEV : loss 2.0209808349609375 - score 0.28\n",
      "2020-05-18 16:19:20,151 BAD EPOCHS (no improvement): 3\n",
      "2020-05-18 16:19:20,152 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:20,211 epoch 6 - iter 0/50 - loss 0.62986070 - samples/sec: 354.53\n",
      "2020-05-18 16:19:20,568 epoch 6 - iter 5/50 - loss 0.48550550 - samples/sec: 74.41\n",
      "2020-05-18 16:19:20,943 epoch 6 - iter 10/50 - loss 0.48284115 - samples/sec: 70.38\n",
      "2020-05-18 16:19:21,346 epoch 6 - iter 15/50 - loss 0.55483983 - samples/sec: 64.65\n",
      "2020-05-18 16:19:21,751 epoch 6 - iter 20/50 - loss 0.60168591 - samples/sec: 64.00\n",
      "2020-05-18 16:19:22,145 epoch 6 - iter 25/50 - loss 0.64188034 - samples/sec: 67.47\n",
      "2020-05-18 16:19:22,535 epoch 6 - iter 30/50 - loss 0.66658501 - samples/sec: 68.34\n",
      "2020-05-18 16:19:22,947 epoch 6 - iter 35/50 - loss 0.68604324 - samples/sec: 66.27\n",
      "2020-05-18 16:19:23,365 epoch 6 - iter 40/50 - loss 0.74157041 - samples/sec: 64.63\n",
      "2020-05-18 16:19:23,804 epoch 6 - iter 45/50 - loss 0.73774722 - samples/sec: 61.99\n",
      "2020-05-18 16:19:24,151 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:24,153 EPOCH 6 done: loss 0.7222 - lr 0.1000\n",
      "2020-05-18 16:19:28,933 DEV : loss 2.2832698822021484 - score 0.294\n",
      "2020-05-18 16:19:29,212 BAD EPOCHS (no improvement): 4\n",
      "2020-05-18 16:19:29,214 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:29,268 epoch 7 - iter 0/50 - loss 0.34120196 - samples/sec: 381.39\n",
      "2020-05-18 16:19:29,654 epoch 7 - iter 5/50 - loss 0.64788717 - samples/sec: 68.43\n",
      "2020-05-18 16:19:30,032 epoch 7 - iter 10/50 - loss 0.61730008 - samples/sec: 70.40\n",
      "2020-05-18 16:19:30,453 epoch 7 - iter 15/50 - loss 0.52210494 - samples/sec: 62.76\n",
      "2020-05-18 16:19:30,858 epoch 7 - iter 20/50 - loss 0.49983862 - samples/sec: 65.26\n",
      "2020-05-18 16:19:31,249 epoch 7 - iter 25/50 - loss 0.55046278 - samples/sec: 68.16\n",
      "2020-05-18 16:19:31,662 epoch 7 - iter 30/50 - loss 0.53656319 - samples/sec: 65.35\n",
      "2020-05-18 16:19:32,062 epoch 7 - iter 35/50 - loss 0.50486417 - samples/sec: 67.05\n",
      "2020-05-18 16:19:32,470 epoch 7 - iter 40/50 - loss 0.53887534 - samples/sec: 64.75\n",
      "2020-05-18 16:19:32,863 epoch 7 - iter 45/50 - loss 0.57122473 - samples/sec: 67.46\n",
      "2020-05-18 16:19:33,214 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:33,215 EPOCH 7 done: loss 0.5956 - lr 0.1000\n",
      "2020-05-18 16:19:38,102 DEV : loss 2.4585444927215576 - score 0.334\n",
      "2020-05-18 16:19:38,394 BAD EPOCHS (no improvement): 5\n",
      "2020-05-18 16:19:38,395 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:38,457 epoch 8 - iter 0/50 - loss 0.37300971 - samples/sec: 332.03\n",
      "2020-05-18 16:19:38,809 epoch 8 - iter 5/50 - loss 0.49186773 - samples/sec: 77.29\n",
      "2020-05-18 16:19:39,172 epoch 8 - iter 10/50 - loss 0.52757528 - samples/sec: 74.12\n",
      "2020-05-18 16:19:39,558 epoch 8 - iter 15/50 - loss 0.54901117 - samples/sec: 68.68\n",
      "2020-05-18 16:19:39,949 epoch 8 - iter 20/50 - loss 0.55735021 - samples/sec: 67.65\n",
      "2020-05-18 16:19:40,336 epoch 8 - iter 25/50 - loss 0.52904573 - samples/sec: 69.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:19:40,709 epoch 8 - iter 30/50 - loss 0.55062598 - samples/sec: 70.29\n",
      "2020-05-18 16:19:41,082 epoch 8 - iter 35/50 - loss 0.54324865 - samples/sec: 70.83\n",
      "2020-05-18 16:19:41,465 epoch 8 - iter 40/50 - loss 0.49572363 - samples/sec: 69.94\n",
      "2020-05-18 16:19:41,860 epoch 8 - iter 45/50 - loss 0.49190628 - samples/sec: 67.94\n",
      "2020-05-18 16:19:42,185 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:42,186 EPOCH 8 done: loss 0.4756 - lr 0.1000\n",
      "2020-05-18 16:19:46,662 DEV : loss 2.42663311958313 - score 0.296\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2020-05-18 16:19:46,936 BAD EPOCHS (no improvement): 6\n",
      "2020-05-18 16:19:46,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:46,992 epoch 9 - iter 0/50 - loss 0.02202588 - samples/sec: 386.82\n",
      "2020-05-18 16:19:47,369 epoch 9 - iter 5/50 - loss 0.28313484 - samples/sec: 70.01\n",
      "2020-05-18 16:19:47,743 epoch 9 - iter 10/50 - loss 0.22769804 - samples/sec: 69.97\n",
      "2020-05-18 16:19:48,120 epoch 9 - iter 15/50 - loss 0.29459747 - samples/sec: 69.50\n",
      "2020-05-18 16:19:48,504 epoch 9 - iter 20/50 - loss 0.30512534 - samples/sec: 69.50\n",
      "2020-05-18 16:19:48,882 epoch 9 - iter 25/50 - loss 0.29459905 - samples/sec: 70.55\n",
      "2020-05-18 16:19:49,261 epoch 9 - iter 30/50 - loss 0.30651337 - samples/sec: 69.90\n",
      "2020-05-18 16:19:49,646 epoch 9 - iter 35/50 - loss 0.32776411 - samples/sec: 68.25\n",
      "2020-05-18 16:19:50,032 epoch 9 - iter 40/50 - loss 0.32998774 - samples/sec: 68.33\n",
      "2020-05-18 16:19:50,413 epoch 9 - iter 45/50 - loss 0.33648075 - samples/sec: 69.46\n",
      "2020-05-18 16:19:50,733 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:50,735 EPOCH 9 done: loss 0.3411 - lr 0.0500\n",
      "2020-05-18 16:19:55,099 DEV : loss 2.470357656478882 - score 0.338\n",
      "2020-05-18 16:19:55,373 BAD EPOCHS (no improvement): 0\n",
      "2020-05-18 16:19:57,138 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:19:57,201 epoch 10 - iter 0/50 - loss 0.02486861 - samples/sec: 332.13\n",
      "2020-05-18 16:19:57,581 epoch 10 - iter 5/50 - loss 0.06062614 - samples/sec: 69.34\n",
      "2020-05-18 16:19:58,003 epoch 10 - iter 10/50 - loss 0.17006867 - samples/sec: 60.85\n",
      "2020-05-18 16:19:58,381 epoch 10 - iter 15/50 - loss 0.20309079 - samples/sec: 71.54\n",
      "2020-05-18 16:19:58,765 epoch 10 - iter 20/50 - loss 0.20180264 - samples/sec: 68.79\n",
      "2020-05-18 16:19:59,139 epoch 10 - iter 25/50 - loss 0.19596438 - samples/sec: 71.00\n",
      "2020-05-18 16:19:59,518 epoch 10 - iter 30/50 - loss 0.18760826 - samples/sec: 70.49\n",
      "2020-05-18 16:19:59,903 epoch 10 - iter 35/50 - loss 0.20346662 - samples/sec: 68.71\n",
      "2020-05-18 16:20:00,284 epoch 10 - iter 40/50 - loss 0.22494172 - samples/sec: 69.05\n",
      "2020-05-18 16:20:00,661 epoch 10 - iter 45/50 - loss 0.23280105 - samples/sec: 70.05\n",
      "2020-05-18 16:20:00,979 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:00,980 EPOCH 10 done: loss 0.2640 - lr 0.0500\n",
      "2020-05-18 16:20:05,307 DEV : loss 2.527432441711426 - score 0.302\n",
      "2020-05-18 16:20:05,581 BAD EPOCHS (no improvement): 1\n",
      "2020-05-18 16:20:05,582 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:05,642 epoch 11 - iter 0/50 - loss 0.11469287 - samples/sec: 348.78\n",
      "2020-05-18 16:20:06,016 epoch 11 - iter 5/50 - loss 0.35701452 - samples/sec: 70.67\n",
      "2020-05-18 16:20:06,389 epoch 11 - iter 10/50 - loss 0.24948892 - samples/sec: 70.76\n",
      "2020-05-18 16:20:06,762 epoch 11 - iter 15/50 - loss 0.26977213 - samples/sec: 71.17\n",
      "2020-05-18 16:20:07,147 epoch 11 - iter 20/50 - loss 0.23509681 - samples/sec: 67.84\n",
      "2020-05-18 16:20:07,513 epoch 11 - iter 25/50 - loss 0.26150576 - samples/sec: 73.06\n",
      "2020-05-18 16:20:07,878 epoch 11 - iter 30/50 - loss 0.26487728 - samples/sec: 73.23\n",
      "2020-05-18 16:20:08,236 epoch 11 - iter 35/50 - loss 0.25987423 - samples/sec: 76.01\n",
      "2020-05-18 16:20:08,584 epoch 11 - iter 40/50 - loss 0.25924290 - samples/sec: 77.57\n",
      "2020-05-18 16:20:08,934 epoch 11 - iter 45/50 - loss 0.24112032 - samples/sec: 76.93\n",
      "2020-05-18 16:20:09,233 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:09,234 EPOCH 11 done: loss 0.2394 - lr 0.0500\n",
      "2020-05-18 16:20:13,722 DEV : loss 2.558734178543091 - score 0.322\n",
      "2020-05-18 16:20:14,000 BAD EPOCHS (no improvement): 2\n",
      "2020-05-18 16:20:14,001 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:14,059 epoch 12 - iter 0/50 - loss 0.11969811 - samples/sec: 360.40\n",
      "2020-05-18 16:20:14,538 epoch 12 - iter 5/50 - loss 0.13205759 - samples/sec: 52.42\n",
      "2020-05-18 16:20:15,026 epoch 12 - iter 10/50 - loss 0.13408770 - samples/sec: 50.78\n",
      "2020-05-18 16:20:15,403 epoch 12 - iter 15/50 - loss 0.16589566 - samples/sec: 70.38\n",
      "2020-05-18 16:20:15,778 epoch 12 - iter 20/50 - loss 0.21222283 - samples/sec: 70.72\n",
      "2020-05-18 16:20:16,163 epoch 12 - iter 25/50 - loss 0.22405188 - samples/sec: 69.04\n",
      "2020-05-18 16:20:16,550 epoch 12 - iter 30/50 - loss 0.22172907 - samples/sec: 69.31\n",
      "2020-05-18 16:20:17,054 epoch 12 - iter 35/50 - loss 0.23108838 - samples/sec: 49.05\n",
      "2020-05-18 16:20:17,477 epoch 12 - iter 40/50 - loss 0.21742467 - samples/sec: 61.30\n",
      "2020-05-18 16:20:17,848 epoch 12 - iter 45/50 - loss 0.23300149 - samples/sec: 71.86\n",
      "2020-05-18 16:20:18,208 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:18,209 EPOCH 12 done: loss 0.2446 - lr 0.0500\n",
      "2020-05-18 16:20:22,825 DEV : loss 2.5711169242858887 - score 0.322\n",
      "2020-05-18 16:20:23,102 BAD EPOCHS (no improvement): 3\n",
      "2020-05-18 16:20:23,103 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:23,154 epoch 13 - iter 0/50 - loss 0.11084366 - samples/sec: 416.00\n",
      "2020-05-18 16:20:23,623 epoch 13 - iter 5/50 - loss 0.30970727 - samples/sec: 53.59\n",
      "2020-05-18 16:20:23,973 epoch 13 - iter 10/50 - loss 0.23036626 - samples/sec: 77.60\n",
      "2020-05-18 16:20:24,333 epoch 13 - iter 15/50 - loss 0.21914038 - samples/sec: 74.25\n",
      "2020-05-18 16:20:24,768 epoch 13 - iter 20/50 - loss 0.21038164 - samples/sec: 58.15\n",
      "2020-05-18 16:20:25,167 epoch 13 - iter 25/50 - loss 0.19928724 - samples/sec: 65.96\n",
      "2020-05-18 16:20:25,541 epoch 13 - iter 30/50 - loss 0.21334009 - samples/sec: 71.04\n",
      "2020-05-18 16:20:25,933 epoch 13 - iter 35/50 - loss 0.20603181 - samples/sec: 67.07\n",
      "2020-05-18 16:20:26,304 epoch 13 - iter 40/50 - loss 0.19074917 - samples/sec: 71.31\n",
      "2020-05-18 16:20:26,688 epoch 13 - iter 45/50 - loss 0.19304740 - samples/sec: 68.59\n",
      "2020-05-18 16:20:27,014 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:27,015 EPOCH 13 done: loss 0.2015 - lr 0.0500\n",
      "2020-05-18 16:20:31,445 DEV : loss 2.7278926372528076 - score 0.294\n",
      "2020-05-18 16:20:31,724 BAD EPOCHS (no improvement): 4\n",
      "2020-05-18 16:20:31,725 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:31,786 epoch 14 - iter 0/50 - loss 0.05330229 - samples/sec: 344.49\n",
      "2020-05-18 16:20:32,161 epoch 14 - iter 5/50 - loss 0.05548704 - samples/sec: 70.65\n",
      "2020-05-18 16:20:32,535 epoch 14 - iter 10/50 - loss 0.06704220 - samples/sec: 71.75\n",
      "2020-05-18 16:20:32,919 epoch 14 - iter 15/50 - loss 0.07289904 - samples/sec: 69.05\n",
      "2020-05-18 16:20:33,289 epoch 14 - iter 20/50 - loss 0.07524887 - samples/sec: 71.51\n",
      "2020-05-18 16:20:33,670 epoch 14 - iter 25/50 - loss 0.09918636 - samples/sec: 69.36\n",
      "2020-05-18 16:20:34,049 epoch 14 - iter 30/50 - loss 0.10208142 - samples/sec: 69.49\n",
      "2020-05-18 16:20:34,425 epoch 14 - iter 35/50 - loss 0.11137152 - samples/sec: 70.35\n",
      "2020-05-18 16:20:34,804 epoch 14 - iter 40/50 - loss 0.10617982 - samples/sec: 69.66\n",
      "2020-05-18 16:20:35,183 epoch 14 - iter 45/50 - loss 0.10324826 - samples/sec: 70.40\n",
      "2020-05-18 16:20:35,509 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-18 16:20:35,510 EPOCH 14 done: loss 0.1435 - lr 0.0500\n",
      "2020-05-18 16:20:39,853 DEV : loss 2.82846999168396 - score 0.276\n",
      "2020-05-18 16:20:40,131 BAD EPOCHS (no improvement): 5\n",
      "2020-05-18 16:20:40,133 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:40,193 epoch 15 - iter 0/50 - loss 0.06993622 - samples/sec: 349.11\n",
      "2020-05-18 16:20:40,559 epoch 15 - iter 5/50 - loss 0.25170111 - samples/sec: 72.84\n",
      "2020-05-18 16:20:40,933 epoch 15 - iter 10/50 - loss 0.16812468 - samples/sec: 70.76\n",
      "2020-05-18 16:20:41,309 epoch 15 - iter 15/50 - loss 0.16616407 - samples/sec: 71.31\n",
      "2020-05-18 16:20:41,685 epoch 15 - iter 20/50 - loss 0.18981475 - samples/sec: 69.75\n",
      "2020-05-18 16:20:42,058 epoch 15 - iter 25/50 - loss 0.20163059 - samples/sec: 71.23\n",
      "2020-05-18 16:20:42,425 epoch 15 - iter 30/50 - loss 0.18205608 - samples/sec: 73.01\n",
      "2020-05-18 16:20:42,792 epoch 15 - iter 35/50 - loss 0.17685768 - samples/sec: 72.19\n",
      "2020-05-18 16:20:43,158 epoch 15 - iter 40/50 - loss 0.16026146 - samples/sec: 73.89\n",
      "2020-05-18 16:20:43,511 epoch 15 - iter 45/50 - loss 0.14841766 - samples/sec: 76.48\n",
      "2020-05-18 16:20:43,809 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:43,810 EPOCH 15 done: loss 0.1584 - lr 0.0500\n",
      "2020-05-18 16:20:48,135 DEV : loss 3.0393199920654297 - score 0.324\n",
      "Epoch    14: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2020-05-18 16:20:48,419 BAD EPOCHS (no improvement): 6\n",
      "2020-05-18 16:20:50,132 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-18 16:20:50,134 Testing using best model ...\n",
      "2020-05-18 16:20:50,136 loading file best-model.pt\n",
      "2020-05-18 16:21:42,068 0.314\t0.314\t0.314\n",
      "2020-05-18 16:21:42,069 \n",
      "MICRO_AVG: acc 0.1862 - f1-score 0.314\n",
      "MACRO_AVG: acc 0.126 - f1-score 0.2109\n",
      "0          tp: 79 - fp: 161 - fn: 67 - tn: 193 - precision: 0.3292 - recall: 0.5411 - accuracy: 0.2573 - f1-score: 0.4094\n",
      "1          tp: 6 - fp: 22 - fn: 82 - tn: 390 - precision: 0.2143 - recall: 0.0682 - accuracy: 0.0545 - f1-score: 0.1035\n",
      "2          tp: 0 - fp: 1 - fn: 10 - tn: 489 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "3          tp: 56 - fp: 105 - fn: 102 - tn: 237 - precision: 0.3478 - recall: 0.3544 - accuracy: 0.2129 - f1-score: 0.3511\n",
      "4          tp: 16 - fp: 54 - fn: 82 - tn: 348 - precision: 0.2286 - recall: 0.1633 - accuracy: 0.1053 - f1-score: 0.1905\n",
      "2020-05-18 16:21:42,070 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "331.52660489082336\n"
     ]
    }
   ],
   "source": [
    "# GPT-1\n",
    "\n",
    "total_time = time.time()\n",
    "#Do we need batchsize 8 here?\n",
    "\n",
    "word_embeddings = [ OpenAIGPTEmbeddings(),                ]\n",
    "modelname = 'gpt-1'\n",
    "# train_and_predict_single(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS, batch_size=8)\n",
    "train_and_predict_single(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS, batch_size=4)\n",
    "\n",
    "print(time.time() - total_time)\n",
    "\n",
    "# 302 sec 18k\n",
    "\n",
    "# on batch mode gave: IndexError: index 0 is out of bounds for dimension 0 with size 0\n",
    "\n",
    "# tiny 500,500 94 sec\n",
    "\n",
    "# single mode also\n",
    "# size: 1000, 200, 500   IndexError: index 0 is out of bounds for dimension 0 with size 0\n",
    "#\n",
    "# possible error in flair tokenization\n",
    "# https://github.com/flairNLP/flair/issues/1366\n",
    "#\n",
    "# or unrecognized character given empty embedding instead of unknown-token\n",
    "# https://github.com/flairNLP/flair/issues/1221\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-1\n",
      "2020-05-17 17:00:11,377 Reading data from /home/max/git/newcombined/dataset_businessnews/input\n",
      "2020-05-17 17:00:11,380 Train: /home/max/git/newcombined/dataset_businessnews/input/flair_train.csv\n",
      "2020-05-17 17:00:11,383 Dev: /home/max/git/newcombined/dataset_businessnews/input/flair_dev.csv\n",
      "2020-05-17 17:00:11,385 Test: /home/max/git/newcombined/dataset_businessnews/input/flair_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 17:00:26,508 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13718/13718 [00:00<00:00, 247933.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 17:00:26,567 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 17:00:26,568 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13718/13718 [00:00<00:00, 258815.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 17:00:26,624 [b'3', b'0', b'4', b'1', b'2']\n",
      "2020-05-17 17:00:26,627 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:00:26,628 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): LSTM(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=5, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2020-05-17 17:00:26,629 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:00:26,630 Corpus: \"Corpus: 13718 train + 500 dev + 500 test sentences\"\n",
      "2020-05-17 17:00:26,631 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:00:26,632 Parameters:\n",
      "2020-05-17 17:00:26,632  - learning_rate: \"0.1\"\n",
      "2020-05-17 17:00:26,633  - mini_batch_size: \"32\"\n",
      "2020-05-17 17:00:26,635  - patience: \"5\"\n",
      "2020-05-17 17:00:26,635  - anneal_factor: \"0.5\"\n",
      "2020-05-17 17:00:26,636  - max_epochs: \"15\"\n",
      "2020-05-17 17:00:26,637  - shuffle: \"True\"\n",
      "2020-05-17 17:00:26,637  - train_with_dev: \"False\"\n",
      "2020-05-17 17:00:26,638  - batch_growth_annealing: \"False\"\n",
      "2020-05-17 17:00:26,638 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:00:26,639 Model training base path: \".\"\n",
      "2020-05-17 17:00:26,640 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:00:26,641 Device: cuda:0\n",
      "2020-05-17 17:00:26,641 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:00:26,642 Embeddings storage mode: cpu\n",
      "2020-05-17 17:00:26,643 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 17:00:26,775 epoch 1 - iter 0/429 - loss 1.65062249 - samples/sec: 10297.96\n",
      "2020-05-17 17:00:31,272 epoch 1 - iter 42/429 - loss 1.46980667 - samples/sec: 299.43\n",
      "2020-05-17 17:00:35,642 epoch 1 - iter 84/429 - loss 1.46700921 - samples/sec: 308.15\n",
      "2020-05-17 17:00:39,770 epoch 1 - iter 126/429 - loss 1.46125768 - samples/sec: 326.19\n",
      "2020-05-17 17:00:45,454 epoch 1 - iter 168/429 - loss 1.45774611 - samples/sec: 236.80\n",
      "2020-05-17 17:00:49,555 epoch 1 - iter 210/429 - loss 1.45048466 - samples/sec: 328.38\n",
      "2020-05-17 17:00:53,619 epoch 1 - iter 252/429 - loss 1.44441523 - samples/sec: 331.45\n",
      "2020-05-17 17:00:57,674 epoch 1 - iter 294/429 - loss 1.44080300 - samples/sec: 332.23\n",
      "2020-05-17 17:01:01,719 epoch 1 - iter 336/429 - loss 1.43433913 - samples/sec: 332.90\n",
      "2020-05-17 17:01:05,813 epoch 1 - iter 378/429 - loss 1.42742018 - samples/sec: 328.98\n",
      "2020-05-17 17:01:09,878 epoch 1 - iter 420/429 - loss 1.42145558 - samples/sec: 331.26\n",
      "2020-05-17 17:01:10,612 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:01:10,613 EPOCH 1 done: loss 1.4213 - lr 0.1000\n",
      "2020-05-17 17:01:11,810 DEV : loss 1.3921153545379639 - score 0.37\n",
      "2020-05-17 17:01:11,877 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/max/anaconda3/envs/tf-hub/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 17:01:14,939 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:01:15,014 epoch 2 - iter 0/429 - loss 1.27847493 - samples/sec: 18661.16\n",
      "2020-05-17 17:01:17,882 epoch 2 - iter 42/429 - loss 1.36794381 - samples/sec: 470.18\n",
      "2020-05-17 17:01:20,782 epoch 2 - iter 84/429 - loss 1.37524241 - samples/sec: 464.71\n",
      "2020-05-17 17:01:23,712 epoch 2 - iter 126/429 - loss 1.36403941 - samples/sec: 460.42\n",
      "2020-05-17 17:01:26,614 epoch 2 - iter 168/429 - loss 1.35945516 - samples/sec: 464.46\n",
      "2020-05-17 17:01:29,549 epoch 2 - iter 210/429 - loss 1.35797206 - samples/sec: 459.35\n",
      "2020-05-17 17:01:32,495 epoch 2 - iter 252/429 - loss 1.35003504 - samples/sec: 457.62\n",
      "2020-05-17 17:01:35,374 epoch 2 - iter 294/429 - loss 1.35093566 - samples/sec: 468.26\n",
      "2020-05-17 17:01:40,221 epoch 2 - iter 336/429 - loss 1.35778247 - samples/sec: 277.84\n",
      "2020-05-17 17:01:43,174 epoch 2 - iter 378/429 - loss 1.36515168 - samples/sec: 456.37\n",
      "2020-05-17 17:01:46,142 epoch 2 - iter 420/429 - loss 1.36092385 - samples/sec: 454.36\n",
      "2020-05-17 17:01:46,704 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:01:46,705 EPOCH 2 done: loss 1.3602 - lr 0.1000\n",
      "2020-05-17 17:01:47,499 DEV : loss 1.2031581401824951 - score 0.486\n",
      "2020-05-17 17:01:47,564 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:01:50,726 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:01:50,805 epoch 3 - iter 0/429 - loss 1.12324178 - samples/sec: 17794.86\n",
      "2020-05-17 17:01:53,762 epoch 3 - iter 42/429 - loss 1.33084188 - samples/sec: 456.02\n",
      "2020-05-17 17:01:56,717 epoch 3 - iter 84/429 - loss 1.33944655 - samples/sec: 456.07\n",
      "2020-05-17 17:01:59,675 epoch 3 - iter 126/429 - loss 1.33254251 - samples/sec: 455.90\n",
      "2020-05-17 17:02:02,634 epoch 3 - iter 168/429 - loss 1.33121081 - samples/sec: 456.03\n",
      "2020-05-17 17:02:05,554 epoch 3 - iter 210/429 - loss 1.33967755 - samples/sec: 461.62\n",
      "2020-05-17 17:02:08,540 epoch 3 - iter 252/429 - loss 1.33098436 - samples/sec: 451.28\n",
      "2020-05-17 17:02:11,470 epoch 3 - iter 294/429 - loss 1.32448443 - samples/sec: 460.11\n",
      "2020-05-17 17:02:14,421 epoch 3 - iter 336/429 - loss 1.32330239 - samples/sec: 456.92\n",
      "2020-05-17 17:02:17,366 epoch 3 - iter 378/429 - loss 1.31499705 - samples/sec: 458.05\n",
      "2020-05-17 17:02:20,330 epoch 3 - iter 420/429 - loss 1.30990260 - samples/sec: 454.74\n",
      "2020-05-17 17:02:20,899 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:02:20,901 EPOCH 3 done: loss 1.3138 - lr 0.1000\n",
      "2020-05-17 17:02:21,684 DEV : loss 1.4142372608184814 - score 0.336\n",
      "2020-05-17 17:02:21,749 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 17:02:21,751 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:02:21,829 epoch 4 - iter 0/429 - loss 1.27058589 - samples/sec: 17585.36\n",
      "2020-05-17 17:02:24,786 epoch 4 - iter 42/429 - loss 1.41348018 - samples/sec: 455.86\n",
      "2020-05-17 17:02:27,758 epoch 4 - iter 84/429 - loss 1.34929866 - samples/sec: 453.60\n",
      "2020-05-17 17:02:30,739 epoch 4 - iter 126/429 - loss 1.31158177 - samples/sec: 452.32\n",
      "2020-05-17 17:02:33,708 epoch 4 - iter 168/429 - loss 1.29913019 - samples/sec: 454.19\n",
      "2020-05-17 17:02:36,701 epoch 4 - iter 210/429 - loss 1.29835491 - samples/sec: 451.15\n",
      "2020-05-17 17:02:39,661 epoch 4 - iter 252/429 - loss 1.29578865 - samples/sec: 455.34\n",
      "2020-05-17 17:02:42,621 epoch 4 - iter 294/429 - loss 1.28931301 - samples/sec: 455.57\n",
      "2020-05-17 17:02:45,590 epoch 4 - iter 336/429 - loss 1.28319697 - samples/sec: 454.07\n",
      "2020-05-17 17:02:48,570 epoch 4 - iter 378/429 - loss 1.27574623 - samples/sec: 452.43\n",
      "2020-05-17 17:02:51,553 epoch 4 - iter 420/429 - loss 1.27261743 - samples/sec: 451.91\n",
      "2020-05-17 17:02:52,078 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:02:52,080 EPOCH 4 done: loss 1.2738 - lr 0.1000\n",
      "2020-05-17 17:02:52,867 DEV : loss 1.2252405881881714 - score 0.504\n",
      "2020-05-17 17:02:52,933 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:02:56,118 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:02:56,199 epoch 5 - iter 0/429 - loss 1.32802916 - samples/sec: 17494.49\n",
      "2020-05-17 17:02:59,122 epoch 5 - iter 42/429 - loss 1.24394411 - samples/sec: 461.05\n",
      "2020-05-17 17:03:02,107 epoch 5 - iter 84/429 - loss 1.22970338 - samples/sec: 451.74\n",
      "2020-05-17 17:03:05,103 epoch 5 - iter 126/429 - loss 1.23313520 - samples/sec: 450.83\n",
      "2020-05-17 17:03:08,055 epoch 5 - iter 168/429 - loss 1.23587686 - samples/sec: 456.60\n",
      "2020-05-17 17:03:11,035 epoch 5 - iter 210/429 - loss 1.22801207 - samples/sec: 452.30\n",
      "2020-05-17 17:03:13,929 epoch 5 - iter 252/429 - loss 1.22333919 - samples/sec: 465.72\n",
      "2020-05-17 17:03:16,887 epoch 5 - iter 294/429 - loss 1.21581262 - samples/sec: 455.83\n",
      "2020-05-17 17:03:19,864 epoch 5 - iter 336/429 - loss 1.21822558 - samples/sec: 453.01\n",
      "2020-05-17 17:03:22,839 epoch 5 - iter 378/429 - loss 1.21557764 - samples/sec: 453.35\n",
      "2020-05-17 17:03:25,839 epoch 5 - iter 420/429 - loss 1.21726546 - samples/sec: 449.25\n",
      "2020-05-17 17:03:26,400 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:03:26,402 EPOCH 5 done: loss 1.2165 - lr 0.1000\n",
      "2020-05-17 17:03:27,191 DEV : loss 1.2168759107589722 - score 0.504\n",
      "2020-05-17 17:03:27,256 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 17:03:30,417 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:03:30,498 epoch 6 - iter 0/429 - loss 1.26973474 - samples/sec: 17263.36\n",
      "2020-05-17 17:03:33,427 epoch 6 - iter 42/429 - loss 1.19057467 - samples/sec: 460.75\n",
      "2020-05-17 17:03:36,371 epoch 6 - iter 84/429 - loss 1.20391299 - samples/sec: 457.94\n",
      "2020-05-17 17:03:39,351 epoch 6 - iter 126/429 - loss 1.20938312 - samples/sec: 452.79\n",
      "2020-05-17 17:03:42,233 epoch 6 - iter 168/429 - loss 1.20504607 - samples/sec: 467.76\n",
      "2020-05-17 17:03:45,214 epoch 6 - iter 210/429 - loss 1.19331287 - samples/sec: 452.84\n",
      "2020-05-17 17:03:48,201 epoch 6 - iter 252/429 - loss 1.19541726 - samples/sec: 451.36\n",
      "2020-05-17 17:03:51,154 epoch 6 - iter 294/429 - loss 1.19229616 - samples/sec: 456.33\n",
      "2020-05-17 17:03:54,132 epoch 6 - iter 336/429 - loss 1.19247419 - samples/sec: 452.66\n",
      "2020-05-17 17:03:57,118 epoch 6 - iter 378/429 - loss 1.19030166 - samples/sec: 451.64\n",
      "2020-05-17 17:04:00,092 epoch 6 - iter 420/429 - loss 1.18815537 - samples/sec: 453.25\n",
      "2020-05-17 17:04:00,662 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:04:00,663 EPOCH 6 done: loss 1.1888 - lr 0.1000\n",
      "2020-05-17 17:04:01,453 DEV : loss 1.2205569744110107 - score 0.522\n",
      "2020-05-17 17:04:01,519 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:04:04,627 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:04:04,707 epoch 7 - iter 0/429 - loss 0.99752313 - samples/sec: 17656.02\n",
      "2020-05-17 17:04:07,663 epoch 7 - iter 42/429 - loss 1.17488796 - samples/sec: 455.88\n",
      "2020-05-17 17:04:10,562 epoch 7 - iter 84/429 - loss 1.16726218 - samples/sec: 465.55\n",
      "2020-05-17 17:04:13,519 epoch 7 - iter 126/429 - loss 1.15429193 - samples/sec: 456.11\n",
      "2020-05-17 17:04:16,467 epoch 7 - iter 168/429 - loss 1.16121193 - samples/sec: 457.44\n",
      "2020-05-17 17:04:19,422 epoch 7 - iter 210/429 - loss 1.16580232 - samples/sec: 456.08\n",
      "2020-05-17 17:04:22,372 epoch 7 - iter 252/429 - loss 1.16260199 - samples/sec: 457.24\n",
      "2020-05-17 17:04:25,348 epoch 7 - iter 294/429 - loss 1.16278401 - samples/sec: 452.89\n",
      "2020-05-17 17:04:28,306 epoch 7 - iter 336/429 - loss 1.16417368 - samples/sec: 455.95\n",
      "2020-05-17 17:04:31,275 epoch 7 - iter 378/429 - loss 1.15977652 - samples/sec: 454.10\n",
      "2020-05-17 17:04:34,273 epoch 7 - iter 420/429 - loss 1.15662175 - samples/sec: 449.79\n",
      "2020-05-17 17:04:34,848 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:04:34,849 EPOCH 7 done: loss 1.1565 - lr 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 17:04:35,638 DEV : loss 1.166002869606018 - score 0.508\n",
      "2020-05-17 17:04:35,705 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 17:04:35,706 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:04:35,779 epoch 8 - iter 0/429 - loss 0.96752071 - samples/sec: 18927.52\n",
      "2020-05-17 17:04:38,742 epoch 8 - iter 42/429 - loss 1.14836320 - samples/sec: 454.97\n",
      "2020-05-17 17:04:41,696 epoch 8 - iter 84/429 - loss 1.15324045 - samples/sec: 456.23\n",
      "2020-05-17 17:04:44,674 epoch 8 - iter 126/429 - loss 1.15512529 - samples/sec: 452.77\n",
      "2020-05-17 17:04:47,643 epoch 8 - iter 168/429 - loss 1.15131626 - samples/sec: 454.06\n",
      "2020-05-17 17:04:50,632 epoch 8 - iter 210/429 - loss 1.15033506 - samples/sec: 451.05\n",
      "2020-05-17 17:04:53,588 epoch 8 - iter 252/429 - loss 1.14472843 - samples/sec: 456.38\n",
      "2020-05-17 17:04:56,523 epoch 8 - iter 294/429 - loss 1.14182044 - samples/sec: 459.24\n",
      "2020-05-17 17:04:59,473 epoch 8 - iter 336/429 - loss 1.13685058 - samples/sec: 456.84\n",
      "2020-05-17 17:05:02,426 epoch 8 - iter 378/429 - loss 1.13704706 - samples/sec: 456.57\n",
      "2020-05-17 17:05:05,398 epoch 8 - iter 420/429 - loss 1.13305340 - samples/sec: 453.64\n",
      "2020-05-17 17:05:05,961 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:05:05,962 EPOCH 8 done: loss 1.1326 - lr 0.1000\n",
      "2020-05-17 17:05:06,753 DEV : loss 1.1794711351394653 - score 0.526\n",
      "2020-05-17 17:05:06,819 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:05:09,917 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:05:09,995 epoch 9 - iter 0/429 - loss 1.35838604 - samples/sec: 17953.43\n",
      "2020-05-17 17:05:12,959 epoch 9 - iter 42/429 - loss 1.16083586 - samples/sec: 454.69\n",
      "2020-05-17 17:05:15,959 epoch 9 - iter 84/429 - loss 1.14445854 - samples/sec: 449.63\n",
      "2020-05-17 17:05:18,955 epoch 9 - iter 126/429 - loss 1.12956920 - samples/sec: 449.99\n",
      "2020-05-17 17:05:21,946 epoch 9 - iter 168/429 - loss 1.11653636 - samples/sec: 450.69\n",
      "2020-05-17 17:05:24,944 epoch 9 - iter 210/429 - loss 1.11648020 - samples/sec: 450.49\n",
      "2020-05-17 17:05:27,963 epoch 9 - iter 252/429 - loss 1.12347209 - samples/sec: 446.90\n",
      "2020-05-17 17:05:30,904 epoch 9 - iter 294/429 - loss 1.12554144 - samples/sec: 458.28\n",
      "2020-05-17 17:05:33,895 epoch 9 - iter 336/429 - loss 1.12874659 - samples/sec: 450.68\n",
      "2020-05-17 17:05:36,878 epoch 9 - iter 378/429 - loss 1.12320499 - samples/sec: 451.85\n",
      "2020-05-17 17:05:39,907 epoch 9 - iter 420/429 - loss 1.11555019 - samples/sec: 445.61\n",
      "2020-05-17 17:05:40,484 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:05:40,486 EPOCH 9 done: loss 1.1150 - lr 0.1000\n",
      "2020-05-17 17:05:41,277 DEV : loss 1.1591323614120483 - score 0.546\n",
      "2020-05-17 17:05:41,342 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:05:44,497 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:05:44,578 epoch 10 - iter 0/429 - loss 1.10554397 - samples/sec: 17311.24\n",
      "2020-05-17 17:05:47,538 epoch 10 - iter 42/429 - loss 1.10328753 - samples/sec: 455.58\n",
      "2020-05-17 17:05:50,425 epoch 10 - iter 84/429 - loss 1.08805781 - samples/sec: 466.95\n",
      "2020-05-17 17:05:53,401 epoch 10 - iter 126/429 - loss 1.08396559 - samples/sec: 453.11\n",
      "2020-05-17 17:05:56,358 epoch 10 - iter 168/429 - loss 1.08087280 - samples/sec: 456.01\n",
      "2020-05-17 17:05:59,329 epoch 10 - iter 210/429 - loss 1.09081154 - samples/sec: 453.75\n",
      "2020-05-17 17:06:02,319 epoch 10 - iter 252/429 - loss 1.08974015 - samples/sec: 451.11\n",
      "2020-05-17 17:06:05,038 epoch 10 - iter 294/429 - loss 1.09074324 - samples/sec: 496.25\n",
      "2020-05-17 17:06:07,900 epoch 10 - iter 336/429 - loss 1.08703063 - samples/sec: 471.42\n",
      "2020-05-17 17:06:10,826 epoch 10 - iter 378/429 - loss 1.08573137 - samples/sec: 460.60\n",
      "2020-05-17 17:06:13,858 epoch 10 - iter 420/429 - loss 1.08326088 - samples/sec: 444.45\n",
      "2020-05-17 17:06:14,425 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:06:14,426 EPOCH 10 done: loss 1.0844 - lr 0.1000\n",
      "2020-05-17 17:06:15,217 DEV : loss 1.046693205833435 - score 0.576\n",
      "2020-05-17 17:06:15,284 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:06:18,388 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:06:18,466 epoch 11 - iter 0/429 - loss 1.18411005 - samples/sec: 17989.41\n",
      "2020-05-17 17:06:21,463 epoch 11 - iter 42/429 - loss 1.10421370 - samples/sec: 449.86\n",
      "2020-05-17 17:06:24,418 epoch 11 - iter 84/429 - loss 1.08081606 - samples/sec: 456.17\n",
      "2020-05-17 17:06:27,390 epoch 11 - iter 126/429 - loss 1.07250704 - samples/sec: 453.99\n",
      "2020-05-17 17:06:30,350 epoch 11 - iter 168/429 - loss 1.08713127 - samples/sec: 455.47\n",
      "2020-05-17 17:06:33,329 epoch 11 - iter 210/429 - loss 1.07915435 - samples/sec: 452.50\n",
      "2020-05-17 17:06:36,306 epoch 11 - iter 252/429 - loss 1.07860139 - samples/sec: 453.19\n",
      "2020-05-17 17:06:39,296 epoch 11 - iter 294/429 - loss 1.07612030 - samples/sec: 450.89\n",
      "2020-05-17 17:06:42,253 epoch 11 - iter 336/429 - loss 1.07397339 - samples/sec: 456.00\n",
      "2020-05-17 17:06:45,206 epoch 11 - iter 378/429 - loss 1.07377359 - samples/sec: 456.68\n",
      "2020-05-17 17:06:48,195 epoch 11 - iter 420/429 - loss 1.07145321 - samples/sec: 450.96\n",
      "2020-05-17 17:06:48,756 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:06:48,758 EPOCH 11 done: loss 1.0722 - lr 0.1000\n",
      "2020-05-17 17:06:49,553 DEV : loss 1.2008771896362305 - score 0.552\n",
      "2020-05-17 17:06:49,617 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 17:06:49,618 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:06:49,692 epoch 12 - iter 0/429 - loss 1.11532640 - samples/sec: 18955.90\n",
      "2020-05-17 17:06:52,425 epoch 12 - iter 42/429 - loss 1.05286308 - samples/sec: 493.23\n",
      "2020-05-17 17:06:55,390 epoch 12 - iter 84/429 - loss 1.04812099 - samples/sec: 454.93\n",
      "2020-05-17 17:06:58,366 epoch 12 - iter 126/429 - loss 1.04901528 - samples/sec: 452.96\n",
      "2020-05-17 17:07:01,343 epoch 12 - iter 168/429 - loss 1.05466919 - samples/sec: 453.05\n",
      "2020-05-17 17:07:04,289 epoch 12 - iter 210/429 - loss 1.04594762 - samples/sec: 457.55\n",
      "2020-05-17 17:07:07,283 epoch 12 - iter 252/429 - loss 1.04659457 - samples/sec: 450.53\n",
      "2020-05-17 17:07:10,279 epoch 12 - iter 294/429 - loss 1.04827687 - samples/sec: 449.87\n",
      "2020-05-17 17:07:13,176 epoch 12 - iter 336/429 - loss 1.04718686 - samples/sec: 465.31\n",
      "2020-05-17 17:07:16,161 epoch 12 - iter 378/429 - loss 1.04375963 - samples/sec: 451.88\n",
      "2020-05-17 17:07:19,155 epoch 12 - iter 420/429 - loss 1.04173693 - samples/sec: 450.25\n",
      "2020-05-17 17:07:19,721 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:07:19,722 EPOCH 12 done: loss 1.0425 - lr 0.1000\n",
      "2020-05-17 17:07:20,515 DEV : loss 1.0762773752212524 - score 0.604\n",
      "2020-05-17 17:07:20,580 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:07:23,659 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:07:23,735 epoch 13 - iter 0/429 - loss 0.98731434 - samples/sec: 18546.47\n",
      "2020-05-17 17:07:26,745 epoch 13 - iter 42/429 - loss 1.03907599 - samples/sec: 447.85\n",
      "2020-05-17 17:07:29,730 epoch 13 - iter 84/429 - loss 1.03954137 - samples/sec: 451.70\n",
      "2020-05-17 17:07:32,742 epoch 13 - iter 126/429 - loss 1.03184766 - samples/sec: 447.55\n",
      "2020-05-17 17:07:35,746 epoch 13 - iter 168/429 - loss 1.02536478 - samples/sec: 448.68\n",
      "2020-05-17 17:07:38,759 epoch 13 - iter 210/429 - loss 1.03246474 - samples/sec: 447.64\n",
      "2020-05-17 17:07:41,753 epoch 13 - iter 252/429 - loss 1.03347128 - samples/sec: 450.40\n",
      "2020-05-17 17:07:44,774 epoch 13 - iter 294/429 - loss 1.03355484 - samples/sec: 446.16\n",
      "2020-05-17 17:07:47,809 epoch 13 - iter 336/429 - loss 1.03275915 - samples/sec: 444.30\n",
      "2020-05-17 17:07:50,799 epoch 13 - iter 378/429 - loss 1.03087324 - samples/sec: 451.23\n",
      "2020-05-17 17:07:53,818 epoch 13 - iter 420/429 - loss 1.02679414 - samples/sec: 446.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-17 17:07:54,367 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:07:54,367 EPOCH 13 done: loss 1.0234 - lr 0.1000\n",
      "2020-05-17 17:07:55,165 DEV : loss 0.9866554141044617 - score 0.612\n",
      "2020-05-17 17:07:55,231 BAD EPOCHS (no improvement): 0\n",
      "2020-05-17 17:07:58,302 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:07:58,380 epoch 14 - iter 0/429 - loss 0.70325166 - samples/sec: 17978.86\n",
      "2020-05-17 17:08:01,386 epoch 14 - iter 42/429 - loss 1.00515173 - samples/sec: 448.51\n",
      "2020-05-17 17:08:04,415 epoch 14 - iter 84/429 - loss 0.98868121 - samples/sec: 445.46\n",
      "2020-05-17 17:08:07,379 epoch 14 - iter 126/429 - loss 0.99210523 - samples/sec: 455.14\n",
      "2020-05-17 17:08:10,391 epoch 14 - iter 168/429 - loss 0.99926491 - samples/sec: 447.41\n",
      "2020-05-17 17:08:13,421 epoch 14 - iter 210/429 - loss 1.00353137 - samples/sec: 444.87\n",
      "2020-05-17 17:08:16,408 epoch 14 - iter 252/429 - loss 1.00070600 - samples/sec: 451.70\n",
      "2020-05-17 17:08:19,413 epoch 14 - iter 294/429 - loss 0.99876128 - samples/sec: 448.92\n",
      "2020-05-17 17:08:22,315 epoch 14 - iter 336/429 - loss 0.99868060 - samples/sec: 464.58\n",
      "2020-05-17 17:08:25,297 epoch 14 - iter 378/429 - loss 1.00039816 - samples/sec: 452.28\n",
      "2020-05-17 17:08:28,318 epoch 14 - iter 420/429 - loss 0.99704749 - samples/sec: 446.55\n",
      "2020-05-17 17:08:28,890 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:08:28,891 EPOCH 14 done: loss 0.9969 - lr 0.1000\n",
      "2020-05-17 17:08:29,685 DEV : loss 0.9993017315864563 - score 0.578\n",
      "2020-05-17 17:08:29,750 BAD EPOCHS (no improvement): 1\n",
      "2020-05-17 17:08:29,752 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:08:29,826 epoch 15 - iter 0/429 - loss 0.98268497 - samples/sec: 18690.55\n",
      "2020-05-17 17:08:34,687 epoch 15 - iter 42/429 - loss 0.97819082 - samples/sec: 277.01\n",
      "2020-05-17 17:08:37,672 epoch 15 - iter 84/429 - loss 0.98291948 - samples/sec: 451.77\n",
      "2020-05-17 17:08:40,697 epoch 15 - iter 126/429 - loss 0.97631924 - samples/sec: 445.67\n",
      "2020-05-17 17:08:43,722 epoch 15 - iter 168/429 - loss 0.97193389 - samples/sec: 445.74\n",
      "2020-05-17 17:08:46,731 epoch 15 - iter 210/429 - loss 0.97684267 - samples/sec: 448.32\n",
      "2020-05-17 17:08:49,711 epoch 15 - iter 252/429 - loss 0.97370764 - samples/sec: 452.43\n",
      "2020-05-17 17:08:52,712 epoch 15 - iter 294/429 - loss 0.97394035 - samples/sec: 449.26\n",
      "2020-05-17 17:08:55,685 epoch 15 - iter 336/429 - loss 0.97609059 - samples/sec: 453.54\n",
      "2020-05-17 17:08:58,690 epoch 15 - iter 378/429 - loss 0.97813726 - samples/sec: 448.93\n",
      "2020-05-17 17:09:01,666 epoch 15 - iter 420/429 - loss 0.98281502 - samples/sec: 453.02\n",
      "2020-05-17 17:09:02,237 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:09:02,239 EPOCH 15 done: loss 0.9838 - lr 0.1000\n",
      "2020-05-17 17:09:03,041 DEV : loss 1.00974702835083 - score 0.6\n",
      "2020-05-17 17:09:03,107 BAD EPOCHS (no improvement): 2\n",
      "2020-05-17 17:09:06,238 ----------------------------------------------------------------------------------------------------\n",
      "2020-05-17 17:09:06,240 Testing using best model ...\n",
      "2020-05-17 17:09:06,241 loading file best-model.pt\n",
      "2020-05-17 17:09:07,241 0.652\t0.652\t0.652\n",
      "2020-05-17 17:09:07,243 \n",
      "MICRO_AVG: acc 0.4837 - f1-score 0.652\n",
      "MACRO_AVG: acc 0.3694 - f1-score 0.49307999999999996\n",
      "0          tp: 121 - fp: 34 - fn: 25 - tn: 320 - precision: 0.7806 - recall: 0.8288 - accuracy: 0.6722 - f1-score: 0.8040\n",
      "1          tp: 28 - fp: 10 - fn: 60 - tn: 402 - precision: 0.7368 - recall: 0.3182 - accuracy: 0.2857 - f1-score: 0.4445\n",
      "2          tp: 0 - fp: 0 - fn: 10 - tn: 490 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "3          tp: 120 - fp: 61 - fn: 38 - tn: 281 - precision: 0.6630 - recall: 0.7595 - accuracy: 0.5479 - f1-score: 0.7080\n",
      "4          tp: 57 - fp: 69 - fn: 41 - tn: 333 - precision: 0.4524 - recall: 0.5816 - accuracy: 0.3413 - f1-score: 0.5089\n",
      "2020-05-17 17:09:07,243 ----------------------------------------------------------------------------------------------------\n",
      "starting prediction\n",
      "537.4678893089294\n"
     ]
    }
   ],
   "source": [
    "# Mock UP - replace failing GPT-1\n",
    "total_time = time.time()\n",
    "\n",
    "word_embeddings = [ WordEmbeddings('glove'),              ]\n",
    "modelname = 'gpt-1'\n",
    "train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "# word_embeddings = [ ELMoEmbeddings('original')              ]\n",
    "# modelname = 'elmo'\n",
    "# train_and_predict(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS)\n",
    "\n",
    "\n",
    "print(time.time() - total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For info about model, load the module, then type ?? to end of name\n",
    "# OpenAIGPT2Embeddings??"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# GPT-2 skipped due to bug\n",
    "# GPT-2 in flair gives error:  IndexError: index 0 is out of bounds for dimension 0 with size 0\n",
    "#\n",
    "# possibly similar to this https://github.com/flairNLP/flair/issues/1221\n",
    "#  \"issue was with some of the unicode characters. XLNetTokenizer returns an empty list for the unicode\n",
    "# character ˜ (U+02DC).This means that the length of subwords for the corresponding token in \n",
    "# token_subwords_mapping is zero\"\n",
    "\n",
    "# model options\n",
    "# https://huggingface.co/transformers/v2.3.0/pretrained_models.html\n",
    "# gpt2 - close to gpt1 in size: 12-layer, 768-hidden, 12-heads, 117M parameters.\n",
    "# gpt2-medium - default,  size: 24-layer, 1024-hidden, 16-heads, 345M parameters.\n",
    "\n",
    "total_time = time.time()\n",
    "\n",
    "word_embeddings = [ OpenAIGPT2Embeddings('gpt2'),                ]\n",
    "modelname = 'gpt-2'\n",
    "train_and_predict_single(word_embeddings, modelname, modeldesc, savelist=savelist, epochs=EPOCHS, \n",
    "                         batch_size=8, embeddings_storage_mode='none')\n",
    "\n",
    "print(time.time() - total_time) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#name='all_flair_512LSTM_15ep_8model'\n",
    "name='FINAL_flair_all_trainsz_'+str(trainsize)\n",
    "print(len(savelist))\n",
    "saveResults(savelist, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(savelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13718"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for combining results from 2 training times into 1 list etc."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import shelve\n",
    "def saveResults(savelist, name='all_default'):\n",
    "    filename= name+'.shlf'\n",
    "    shelf = shelve.open(outfolder+filename)\n",
    "    # serializing\n",
    "    #shelf[\"all_flair\"] = all_flair\n",
    "    shelf[name] = savelist\n",
    "    shelf.close() # you must close the shelve file!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 2 last\n",
    "name='all_flair_512LSTM_15ep_model'\n",
    "name = 'FINAL_flair_all_trainsz_'+str(trainsize)\n",
    "te = loadResults(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#newlist = te+savelist\n",
    "newlist = te\n",
    "len(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut doubles away\n",
    "# newlist = newlist[5:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# save combined\n",
    "name='FINAL_flair_all_trainsz_'+str(trainsize)\n",
    "print(len(newlist))\n",
    "saveResults(newlist, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move list item 5 to end\n",
    "# te[5]\n",
    "# te.append(te.pop(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(savelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = savelist[0:5] + [savelist[9]] + savelist[6:9]\n",
    "len(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove\n",
      "fasttext web-crawl\n",
      "fasttext news/wiki\n",
      "en-twitter\n",
      "elmo\n",
      "Flair\n",
      "bert-base-cased\n",
      "BytePairEmbedding\n",
      "gpt-1\n"
     ]
    }
   ],
   "source": [
    "for i in savelist:\n",
    "    print(i['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove list item 0 from list\n",
    "savelist.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-1', 'labels': 0      3\n",
       " 1      0\n",
       " 2      0\n",
       " 3      3\n",
       " 4      3\n",
       "       ..\n",
       " 495    3\n",
       " 496    4\n",
       " 497    0\n",
       " 498    3\n",
       " 499    3\n",
       " Name: label, Length: 500, dtype: int64, 'confidence': 0      0.998186\n",
       " 1      0.914472\n",
       " 2      0.928485\n",
       " 3      0.959929\n",
       " 4      0.650925\n",
       "          ...   \n",
       " 495    0.963905\n",
       " 496    0.890513\n",
       " 497    0.797013\n",
       " 498    0.586767\n",
       " 499    0.941501\n",
       " Name: confidence, Length: 500, dtype: float64, 'traintime': 199.73805332183838, 'predtime3k': 3.4320037364959717, 'modeldesc': '512LSTM_15epoch_non-bi'}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove list item n from list\n",
    "savelist.pop(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove\n",
      "fasttext web-crawl\n",
      "fasttext news/wiki\n",
      "en-twitter\n",
      "elmo\n",
      "Flair\n",
      "bert-base-uncased\n",
      "BytePairEmbedding\n",
      "gpt-1\n"
     ]
    }
   ],
   "source": [
    "for i in te:\n",
    "    print(i['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-1', 'labels': 0      3\n",
       " 1      0\n",
       " 2      0\n",
       " 3      3\n",
       " 4      3\n",
       "       ..\n",
       " 495    3\n",
       " 496    4\n",
       " 497    0\n",
       " 498    3\n",
       " 499    3\n",
       " Name: label, Length: 500, dtype: int64, 'confidence': 0      0.998186\n",
       " 1      0.914472\n",
       " 2      0.928485\n",
       " 3      0.959929\n",
       " 4      0.650925\n",
       "          ...   \n",
       " 495    0.963905\n",
       " 496    0.890513\n",
       " 497    0.797013\n",
       " 498    0.586767\n",
       " 499    0.941501\n",
       " Name: confidence, Length: 500, dtype: float64, 'traintime': 199.73805332183838, 'predtime3k': 3.4320037364959717, 'modeldesc': '512LSTM_15epoch_non-bi'}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savelist[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "savelist[8]['model']='gpt-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in savelist:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'Flair', 'labels': 0       1\n",
       " 1       1\n",
       " 2       1\n",
       " 3       1\n",
       " 4       1\n",
       "        ..\n",
       " 2995    1\n",
       " 2996    1\n",
       " 2997    1\n",
       " 2998    1\n",
       " 2999    1\n",
       " Name: label, Length: 3000, dtype: int64, 'confidence': 0       0.805744\n",
       " 1       0.546344\n",
       " 2       0.802081\n",
       " 3       0.714745\n",
       " 4       0.753530\n",
       "           ...   \n",
       " 2995    0.759887\n",
       " 2996    0.893057\n",
       " 2997    0.859725\n",
       " 2998    0.813483\n",
       " 2999    0.864573\n",
       " Name: confidence, Length: 3000, dtype: float64, 'traintime': 81.63569831848145, 'predtime3k': 1589378399.4414687, 'modeldesc': '512LSTM_15epoch_non-bi'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "te[5] = savelist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "te[6] = savelist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove\n",
      "fasttext web-crawl\n",
      "fasttext news/wiki\n",
      "en-twitter\n",
      "elmo\n",
      "Flair\n",
      "bert-base-uncased\n",
      "BytePairEmbedding\n",
      "gpt-1\n"
     ]
    }
   ],
   "source": [
    "for i in newlist:\n",
    "    print(i['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savelist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
